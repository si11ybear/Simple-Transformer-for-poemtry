{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import random\n",
    "\n",
    "# 深度学习库pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "# 用于绘制损失函数下降曲线\n",
    "from matplotlib import pyplot as plt\n",
    "# %pdb off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建\n",
    "\n",
    "## 数据集导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单行诗最大长度\n",
    "MAX_LEN = 64\n",
    "MIN_LEN = 5\n",
    "# 禁用的字符，拥有以下符号的诗将被忽略\n",
    "DISALLOWED_WORDS = ['（', '）', '(', ')', '__', '《', '》', '【', '】', '[', ']', '？', '；']\n",
    "\n",
    "# 一首诗（一行）对应一个列表的元素\n",
    "poetry = []\n",
    "\n",
    "# 按行读取数据 poetry.txt\n",
    "with open('./data/poetry.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "# 遍历处理每一条数据    \n",
    "for line in lines:\n",
    "    # 利用正则表达式拆分 标题 和 内容\n",
    "    fields = line.split(\":\")\n",
    "    # 跳过异常数据\n",
    "    if len(fields) != 2:\n",
    "        continue\n",
    "    # 得到诗词内容（后面不需要标题）\n",
    "    content = fields[1]\n",
    "    # 过滤数据：跳过内容过长、过短、存在禁用符的诗词\n",
    "    if len(content) > MAX_LEN - 2 or len(content) < MIN_LEN:\n",
    "        continue\n",
    "    if any(word in content for word in DISALLOWED_WORDS):\n",
    "        continue\n",
    "        \n",
    "    poetry.append(content.replace('\\n', '')) # 最后要记得删除换行符\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寒随穷律变，春逐鸟声开。初风飘带柳，晚雪间花梅。碧林青旧竹，绿沼翠新苔。芝田初雁去，绮树巧莺来。\n",
      "晚霞聊自怡，初晴弥可喜。日晃百花色，风动千林翠。池鱼跃不同，园鸟声还异。寄言博通者，知予物外志。\n",
      "夏律昨留灰，秋箭今移晷。峨嵋岫初出，洞庭波渐起。桂白发幽岩，菊黄开灞涘。运流方可叹，含毫属微理。\n",
      "寒惊蓟门叶，秋发小山枝。松阴背日转，竹影避风移。提壶菊花岸，高兴芙蓉池。欲知凉气早，巢空燕不窥。\n",
      "山亭秋色满，岩牖凉风度。疏兰尚染烟，残菊犹承露。古石衣新苔，新巢封古树。历览情无极，咫尺轮光暮。\n",
      "慨然抚长剑，济世岂邀名。星旗纷电举，日羽肃天行。遍野屯万骑，临原驻五营。登山麾武节，背水纵神兵。在昔戎戈动，今来宇宙平。\n",
      "翠野驻戎轩，卢龙转征旆。遥山丽如绮，长流萦似带。海气百重楼，岩松千丈盖。兹焉可游赏，何必襄城外。\n",
      "玄兔月初明，澄辉照辽碣。映云光暂隐，隔树花如缀。魄满桂枝圆，轮亏镜彩缺。临城却影散，带晕重围结。驻跸俯九都，停观妖氛灭。\n",
      "碧原开雾隰，绮岭峻霞城。烟峰高下翠，日浪浅深明。斑红妆蕊树，圆青压溜荆。迹岩劳傅想，窥野访莘情。巨川何以济，舟楫伫时英。\n",
      "春蒐驰骏骨，总辔俯长河。霞处流萦锦，风前漾卷罗。水花翻照树，堤兰倒插波。岂必汾阴曲，秋云发棹歌。\n",
      "current_line_count = 24375\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(poetry[i])\n",
    "    \n",
    "print(f\"current_line_count = {len(poetry)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寒 -> 2612\n",
      "随 -> 1036\n",
      "穷 -> 482\n",
      "律 -> 118\n",
      "变 -> 286\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# 最小词频\n",
    "MIN_WORD_FREQUENCY = 8\n",
    "\n",
    "# 统计词频，利用Counter可以直接按单个字符进行统计词频\n",
    "counter = Counter()\n",
    "for line in poetry:\n",
    "    counter.update(line)\n",
    "# 过滤掉低词频的词\n",
    "tokens = [token for token, count in counter.items() if count >= MIN_WORD_FREQUENCY]\n",
    "# 打印一下出现次数前5的字\n",
    "for i, (token, count) in enumerate(counter.items()):\n",
    "    print(token, \"->\",count)\n",
    "    if i >= 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类定义\n",
    "\n",
    "需要注意的是，本部分类定义应当使用import导入，但为了展示相关信息，我们将类定义的代码重新给出。在后续训练中，对部分类定义做了修改，请以./classes.py中的类定义为准。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \"\"\"\n",
    "    词典编码器\n",
    "    \"\"\"\n",
    "    UNKNOWN = \"<unknown>\"\n",
    "    PAD = \"<pad>\"\n",
    "    BOS = \"<bos>\" \n",
    "    EOS = \"<eos>\" \n",
    "\n",
    "    def __init__(self, tokens):\n",
    "        # 补上特殊词标记：未知词标记、填充字符标记、开始标记、结束标记\n",
    "        tokens = [Tokenizer.UNKNOWN, Tokenizer.PAD, Tokenizer.BOS, Tokenizer.EOS] + tokens\n",
    "        # 词汇表大小\n",
    "        self.dict_size = len(tokens)\n",
    "        # 生成映射关系\n",
    "        self.token_id = {} # 映射: 词 -> 编号\n",
    "        self.id_token = {} # 映射: 编号 -> 词\n",
    "        for idx, word in enumerate(tokens):\n",
    "            self.token_id[word] = idx\n",
    "            self.id_token[idx] = word\n",
    "        \n",
    "        # 各个特殊标记的编号id，方便其他地方使用\n",
    "        self.unknown_id = self.token_id[Tokenizer.UNKNOWN]\n",
    "        self.pad_id = self.token_id[Tokenizer.PAD]\n",
    "        self.bos_id = self.token_id[Tokenizer.BOS]\n",
    "        self.eos_id = self.token_id[Tokenizer.EOS]\n",
    "    \n",
    "    def id_to_token(self, token_id):\n",
    "        \"\"\"\n",
    "        编号 -> 词\n",
    "        \"\"\"\n",
    "        return self.id_token.get(token_id)\n",
    "\n",
    "    def token_to_id(self, token):\n",
    "        \"\"\"\n",
    "        词 -> 编号，取不到时给 UNKNOWN\n",
    "        \"\"\"\n",
    "        return self.token_id.get(token, self.unknown_id)\n",
    "\n",
    "    def encode(self, tokens):\n",
    "        \"\"\"\n",
    "        词列表 -> <bos>编号 + 编号列表 + <eos>编号\n",
    "        \"\"\"\n",
    "        token_ids = [self.bos_id, ] # 起始标记\n",
    "        # 遍历，词转编号\n",
    "        for token in tokens:\n",
    "            token_ids.append(self.token_to_id(token))\n",
    "        token_ids.append(self.eos_id) # 结束标记\n",
    "        return token_ids\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        \"\"\"\n",
    "        编号列表 -> 词列表(去掉起始、结束标记)\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        for idx in token_ids:\n",
    "            # 跳过起始、结束标记\n",
    "            if idx != self.bos_id and idx != self.eos_id:\n",
    "                tokens.append(self.id_to_token(idx))\n",
    "        return tokens\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dict_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index和独热向量互化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2onehot(word_ids, vocab_size):\n",
    "    r\"\"\"\n",
    "    由索引转化为独热编码\n",
    "    Args:\n",
    "        word_ids (torch.Tensor): \n",
    "            A 1D or 2D tensor containing word indices. \n",
    "            (seq_len, ) or (batch_size, seq_len)\n",
    "\n",
    "        vocab_size (int): \n",
    "            The size of the vocabulary.\n",
    "\n",
    "    Returns: \n",
    "        torch.Tensor: \n",
    "            A tensor containing one-hot encoded vectors.\n",
    "            (seq_len, vocab_size) or (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `word_ids` is not a 1D or 2D tensor.\n",
    "    \"\"\"\n",
    "    if word_ids.dim() == 1:\n",
    "        # 一维情况：(seq_len,)\n",
    "        onehot_tensor = torch.zeros(len(word_ids), vocab_size)\n",
    "        for i, s in enumerate(word_ids): \n",
    "            onehot_tensor[i, s] = 1\n",
    "    elif word_ids.dim() == 2:\n",
    "        # 二维情况：(batch_size, seq_len)\n",
    "        batch_size, seq_len = word_ids.size()\n",
    "        onehot_tensor = torch.zeros(batch_size, seq_len, vocab_size, dtype=torch.float32)\n",
    "        onehot_tensor.scatter_(2, word_ids.unsqueeze(2), 1)\n",
    "    else:\n",
    "        raise ValueError(\"word_ids must be a 1D or 2D tensor\")\n",
    "    return onehot_tensor\n",
    "\n",
    "def onehot2index(word_ids):\n",
    "    \"\"\"\n",
    "    独热编码转化为索引 (*, vocab_size) ---> (*,)\n",
    "    \"\"\"\n",
    "    return torch.argmax(word_ids, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(TensorDataset):\n",
    "    \"\"\"\n",
    "    数据集定义\n",
    "    \"\"\"\n",
    "    def __init__(self, data, tokenizer, max_len=64):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len  # 每条数据的最大长度\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        将文本转化为索引并返回\n",
    "        \"\"\"\n",
    "        line = self.data[index]\n",
    "        word_ids = self.encode_pad_line(line)\n",
    "        return torch.tensor(word_ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def encode_pad_line(self, line):\n",
    "        \"\"\"\n",
    "        将文本转化为索引并返回，对齐序列长度为`max_len`\n",
    "        \"\"\"\n",
    "        word_ids = self.tokenizer.encode(line)\n",
    "        # 如果句子长度不足max_len，填充PAD；超过max_len，截断\n",
    "        if len(word_ids) <= self.max_len:\n",
    "            word_ids = word_ids + [self.tokenizer.pad_id] * (self.max_len - len(word_ids))\n",
    "        else:\n",
    "            word_ids = word_ids[:self.max_len - 1].append(self.tokenizer.eos_id)\n",
    "        return word_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 嵌入层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    \"\"\"\n",
    "    嵌入层 将索引转化为独热向量，并线性嵌入\n",
    "    \"\"\"\n",
    "    def __init__(self, v, h):\n",
    "        \"\"\"\n",
    "        v: 词汇表大小\n",
    "        h: 嵌入后维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(v, h)\n",
    "        self.h = h\n",
    "        self.v = v\n",
    "\n",
    "    def forward(self, src):\n",
    "        # print(src.size())\n",
    "        onehot_tensor = index2onehot(src, self.v)\n",
    "        # print(onehot_tensor.size())\n",
    "        return self.embedding(onehot_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 位置编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    位置编码\n",
    "    \"\"\"\n",
    "    def __init__(self, h, dropout=0.1, max_len=64):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, h)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, h, 2).float() * (-math.log(10000.0) / h))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size(), self.pe.size())\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False) \n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意力模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    注意力模块，提供 q = k = v 的自注意力模式和 k = v 的交叉注意力模式\n",
    "    \"\"\"\n",
    "    def __init__(self, h, a, dropout=0.1, type = 'self'):\n",
    "        '''\n",
    "        h: 嵌入层维度\n",
    "        a: 注意力头数\n",
    "        d_k: 每个注意力头的第二个维度 d_k = h//a\n",
    "\n",
    "        X: (s,h) ---Wq, Wk, Wv: (h, h//a) ---> Q,K,V: (s, h//a) \n",
    "\n",
    "            ---> softmax(Q * K.t / sqrt(d_k)) * V: (s, h//a)\n",
    "\n",
    "            ---> output: (s, h) ---out_proj: (h, h)---> output: (s, h)\n",
    "        '''\n",
    "        super().__init__()  # 注意这里的修正，使用super()而不是super.__init__()\n",
    "        self.h = h\n",
    "        self.a = a\n",
    "        self.d_k = h // a\n",
    "        self.types = type\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # 初始化Q, K, V的权重矩阵\n",
    "        # 每个权重矩阵的维数是(s, h//a) 这里是(h, h)，是将每个头的相应矩阵拼接到一起了\n",
    "        self.Wq = nn.Linear(h, h)\n",
    "        self.Wk = nn.Linear(h, h)\n",
    "        self.Wv = nn.Linear(h, h)\n",
    "        \n",
    "        # 缩放因子，用于缩放点积结果\n",
    "        self.scale = 1 / math.sqrt(self.d_k)\n",
    "\n",
    "        self.out_proj = nn.Linear(h, h)\n",
    "\n",
    "    def forward(self, x, y = None, padding_mask=None, tgt_sequence_mask = None):\n",
    "        \"\"\"\n",
    "        x: (batch_size, s = tgt_s, h), 自注意力的q k v\n",
    "        y: (batch_size, s = src_s, h), 交叉注意力的k v\n",
    "        tgt_sequence_mask: (tgt_s, tgt_s)\n",
    "        padding_mask : (batch_size, src_s)\n",
    "        padding_mask: 添加给key的掩码，用于掩盖pad的影响\n",
    "        tgt_sequence_mask: decoder自注意力添加给key的掩码，用于遮蔽未来信息\n",
    "\n",
    "        Step #1 通过线性变换得到Q, K, V\n",
    "        q,k,v: (batch_size, s, h) ---> (batch_size, s, a, d_k) ---> (batch_size, a, s, d_k)\n",
    "        crros attention时q的s=tgt_s, kv的s=src_s\n",
    "\n",
    "        Step#2 应用掩码，计算注意力分数\n",
    "        k: (batch_size, a, src_s, d_k) ---> (batch_size, a, d_k, src_s)\n",
    "        tgt_sequence_mask: (tgt_s, tgt_s) ---> (batch_size, a, tgt_s, tgt_s)\n",
    "        padding_mask : (batch_size, src_s) ---> (batch_size, a, tgt_s, src_s)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \"\"\"\n",
    "        Step #1 通过线性变换得到Q, K, V\n",
    "        q,k,v: (batch_size, s, h) ---> (batch_size, s, a, d_k) ---> (batch_size, a, s, d_k)\n",
    "        crros attention时q的s=tgt_s, kv的s=src_s\n",
    "        \"\"\"\n",
    "        if self.types == 'self':            # 自注意力机制，均来自输入x            \n",
    "            assert y is None, (\"Self Attention but different input for Q K V\")\n",
    "            q = k = v = x\n",
    "        elif self.types == 'cross':         # 交叉注意力机制，q来自x，k v来自y\n",
    "            assert y is not None, (\"Cross Attention but the same input for Q K V\")\n",
    "            q = x\n",
    "            k = v = y\n",
    "        else: raise ValueError(\"Undefined Attention Type\")\n",
    "\n",
    "        q = self.Wq(q).view(batch_size, -1, self.a, self.d_k).transpose(1, 2)\n",
    "        k = self.Wk(k).view(batch_size, -1, self.a, self.d_k).transpose(1, 2)\n",
    "        v = self.Wv(v).view(batch_size, -1, self.a, self.d_k).transpose(1, 2)\n",
    "\n",
    "        \"\"\"\n",
    "        Step#2 应用掩码，计算注意力分数\n",
    "        k: (batch_size, a, src_s, d_k) ---> (batch_size, a, d_k, src_s)\n",
    "        tgt_sequence_mask: (tgt_s, tgt_s) ---> (batch_size, a, tgt_s, tgt_s)\n",
    "        padding_mask : (batch_size, src_s) ---> (batch_size, a, tgt_s, src_s)\n",
    "        \"\"\"\n",
    "        k_len  = k.size()[2]\n",
    "        scores = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "        if padding_mask is not None:\n",
    "            # print(padding_mask)\n",
    "            mask = padding_mask.view(batch_size, 1, 1, k_len).expand(batch_size, self.a, q.size()[2], k_len)\n",
    "            if tgt_sequence_mask is not None: \n",
    "                assert self.types == 'self' , \\\n",
    "                        (f\"Only Self Attention in Decoder Needs Sequence Mask, but now {self.types} attetion!\")\n",
    "                s_mask = tgt_sequence_mask.view(1, 1, k_len, k_len).   \\\n",
    "                expand(batch_size, self.a, -1, -1)\n",
    "                mask = s_mask.logical_or(mask)\n",
    "            # print(mask.size(), scores.size())\n",
    "            # print(mask)\n",
    "            scores = scores.masked_fill(mask, -1e9)\n",
    "        \n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.h)\n",
    "        output = self.out_proj(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeedForward层\n",
    "\n",
    "支持选择两种激活函数RELU或GELU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    FeedForward层，默认hiddenDim = 4 * h\n",
    "    \"\"\"\n",
    "    def __init__(self, h, hiddenDim = None, outDim = None, dropout = 0.1, type = 'relu'):\n",
    "        \"\"\"\n",
    "        h: 嵌入层维度\n",
    "        hiddenDim: 隐层维度，默认4*h\n",
    "        outDim: 输出维度，默认h\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.h = h\n",
    "        if hiddenDim is None: hiddenDim = 4 * h\n",
    "        if outDim is None: outDim = h\n",
    "        self.W1 = nn.Linear(h, hiddenDim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.W2 = nn.Linear(hiddenDim, outDim)\n",
    "        self.types = type\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        W1: (h, hiddenDim)\n",
    "        W2: (hiddenDim, outDim)\n",
    "        x: (h, h) ---> x * W_1: (h, hiddenDim) ---> relu/gelu: (h, hiddenDim) ---> A' * W2: (h, outDim)\n",
    "        \"\"\"\n",
    "        x = self.W1(x)\n",
    "        if self.types == 'relu': x = F.relu(x)\n",
    "        elif self.types == 'gelu': x = F.gelu(x)\n",
    "        else: raise ValueError(\"Unsupported activation type\")\n",
    "        x = self.dropout(x)\n",
    "        x = self.W2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    层归一化\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-5, elementwise_affine=True):\n",
    "        super().__init__()\n",
    "        self.normalized_shape = normalized_shape\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        层归一化，计算input最后一个维度均值和方差并标准化\n",
    "        input: (*, h) ---> (*, h)\n",
    "        \"\"\"\n",
    "        # 计算均值和方差\n",
    "        assert self.normalized_shape[0] == input.size()[-1], (\"Unmatched Shape.\")\n",
    "        mean = input.mean(dim=-1, keepdim=True)\n",
    "        var = input.var(dim=-1, unbiased=False, keepdim=True)\n",
    "        std = torch.sqrt(var + self.eps)\n",
    "        \n",
    "        # 应用层归一化公式\n",
    "        normalized_input = (input - mean) / std\n",
    "        normalized_input = normalized_input * self.weight + self.bias\n",
    "        \n",
    "        return normalized_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfomer主流程\n",
    "包含从嵌入层进入attention block之后的所有流程：encoder decoder feedforward add&norm\n",
    "- 对于encoder来讲，self-attention ---> add&norm ---> feedforward ---> add&norm\n",
    "- 对于decoder来讲，self-attention ---> add&norm ---> cross-attention ---> add&norm ---> feedforward ---> add&norm\n",
    "   \n",
    "支持LayerNorm结构调整，通过参数norm_first指定。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer中解码器和编码器架构\n",
    "    \"\"\"\n",
    "    def __init__(self, h, a, num_encoder_layers, num_decoder_layers, dim_feedforward=2048, dropout=0.1):\n",
    "        \"\"\"\n",
    "        h: 输入维度\n",
    "        a: 注意力头数\n",
    "        num_encoder_layers: 编码器层数\n",
    "        num_decoder_layers: 解码器层数\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoders = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                Attention(h, a, dropout),\n",
    "                LayerNorm((h,)),\n",
    "                FeedForward(h, dropout = dropout),\n",
    "                LayerNorm((h,))\n",
    "            ]) for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.decoders = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                Attention(h, a, dropout),\n",
    "                LayerNorm((h,)),\n",
    "                Attention(h, a, dropout, type='cross'),\n",
    "                LayerNorm((h,)),\n",
    "                FeedForward(h, dropout = dropout),\n",
    "                LayerNorm((h,))\n",
    "            ]) for _ in range(num_decoder_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, encoder_input, decoder_input, src_padding_mask=None, tgt_padding_mask = None, tgt_sequence_mask=None, norm_first = False):\n",
    "        \"\"\"\n",
    "        Transformer前向传播\n",
    "        encoder_input: 编码器输入\n",
    "        decoder_input: 解码器输入\n",
    "        src_padding_mask: 编码器pad掩码\n",
    "        tgt_padding_mask: 解码器pad掩码\n",
    "        tgt_sequence_mask: 解码器自注意力序列掩码，用于遮蔽未来信息\n",
    "        norm_first: 是否调整LN结构，如果为True，则先进行归一化和相应计算，再进行残差连接\n",
    "        \"\"\"\n",
    "        for enc in self.encoders:\n",
    "            attention, norm1, ff, norm2 = enc\n",
    "            if not norm_first:\n",
    "                encoder_input = norm1(attention(encoder_input, padding_mask=src_padding_mask) + encoder_input)\n",
    "                encoder_input = norm2(ff(encoder_input) + encoder_input)\n",
    "            else:\n",
    "                encoder_input = attention(norm1(encoder_input), padding_mask=src_padding_mask) + encoder_input\n",
    "                encoder_input = ff(norm2(encoder_input)) + encoder_input\n",
    "\n",
    "        for dec in self.decoders:\n",
    "            self_attention, norm1, cross_attention, norm2, ff, norm3 = dec\n",
    "            if not norm_first:\n",
    "                decoder_input = norm1(self_attention(decoder_input, padding_mask=tgt_padding_mask, \\\n",
    "                                                    tgt_sequence_mask = tgt_sequence_mask) + decoder_input)\n",
    "                decoder_input = norm2(cross_attention(decoder_input, encoder_input, \\\n",
    "                                                    padding_mask=src_padding_mask) + decoder_input)\n",
    "                decoder_input = norm3(ff(decoder_input) + decoder_input)\n",
    "            else:\n",
    "                decoder_input = self_attention(norm1(decoder_input), padding_mask=tgt_padding_mask, \\\n",
    "                                                    tgt_sequence_mask = tgt_sequence_mask) + decoder_input\n",
    "                decoder_input = cross_attention(norm2(decoder_input), encoder_input, \\\n",
    "                                                    padding_mask=src_padding_mask) + decoder_input\n",
    "                decoder_input = ff(norm3(decoder_input)) + decoder_input\n",
    "        return decoder_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(nn.Module):\n",
    "    \"\"\"\n",
    "    预测层\n",
    "    \"\"\"\n",
    "    def __init__(self, h, v):\n",
    "        super().__init__()\n",
    "        self.w = nn.Linear(h, v)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer架构\n",
    "    \"\"\"\n",
    "    def __init__(self, v, h, a, num_encoder_layers, num_decoder_layers, dimFF, dropout, max_len):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(v,h)\n",
    "        # self.embedding = nn.Embedding(v, h, padding_idx=1)\n",
    "        self.posEncoding = PositionalEncoding(h, 0, max_len)\n",
    "        self.transformer = TransformerEncoderDecoder(h, a, num_encoder_layers, num_decoder_layers, dimFF, dropout)\n",
    "        self.predict = Prediction(h, v)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, src, tgt, src_padding_mask = None, tgt_padding_mask = None, tgt_sequence_mask = None):\n",
    "        \"\"\"\n",
    "        src/tgt: 两段index序列，分别被嵌入层转化为编码器和解码器输入\n",
    "        src_padding_mask: 编码器pad掩码\n",
    "        tgt_padding_mask: 解码器pad掩码\n",
    "        tgt_sequence_mask: 解码器自注意力序列掩码，用于遮蔽未来信息\n",
    "        如果不手动提供上述掩码，会自动生成默认pad掩码和序列掩码\n",
    "        \"\"\"\n",
    "        if src_padding_mask is None: \n",
    "            src_padding_mask = self.get_key_padding_mask(src)\n",
    "        if tgt_padding_mask is None: \n",
    "            tgt_padding_mask = self.get_key_padding_mask(tgt)\n",
    "        if tgt_sequence_mask is None: \n",
    "            tgt_sequence_mask = self.get_sequence_mask(tgt)\n",
    "\n",
    "        src = self.embedding(src)\n",
    "        tgt = self.embedding(tgt)\n",
    "\n",
    "        src = self.posEncoding(src)\n",
    "        tgt = self.posEncoding(tgt)\n",
    "\n",
    "        output = self.transformer(src, tgt, src_padding_mask, tgt_padding_mask, tgt_sequence_mask)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sequence_mask(tgt):\n",
    "        \"\"\"\n",
    "        tgt: (s,) ---> (s,s)\n",
    "        生成序列掩码\n",
    "        \"\"\"\n",
    "        size = tgt.size()[-1]\n",
    "        sr = torch.triu(torch.full((size, size), True), diagonal=1)\n",
    "        # print(sr)\n",
    "        return sr\n",
    "\n",
    "    @staticmethod\n",
    "    def get_key_padding_mask(tokens):\n",
    "        \"\"\"\n",
    "        tokens: (s,) ---> (s,)\n",
    "        生成pad掩码\n",
    "        \"\"\"\n",
    "        key_padding_mask = torch.full(tokens.size(), False, dtype=bool)\n",
    "        key_padding_mask[tokens == 1] = True\n",
    "        return key_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练和预测\n",
    "\n",
    "### 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embedding): Embedding(\n",
      "    (embedding): Linear(in_features=3428, out_features=128, bias=True)\n",
      "  )\n",
      "  (posEncoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (transformer): TransformerEncoderDecoder(\n",
      "    (encoders): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (decoders): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "        (4): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): LayerNorm()\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "        (4): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): LayerNorm()\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "        (4): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predict): Prediction(\n",
      "    (w): Linear(in_features=128, out_features=3428, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(tokens)\n",
    "v = len(tokenizer)\n",
    "batch_size = 64\n",
    "max_len = 64\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "dataset = MyDataset(poetry, tokenizer,  max_len)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 初始化模型、优化器和损失函数\n",
    "h = 128\n",
    "a = 4\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dim_feedforward = 4 * h\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(v, h, a, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, max_len)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model.to(device)\n",
    "    # print(next(model.parameters()).device)  # 输出: cuda:0\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train... [epoch 1/50, loss 3.75162]: 100%|██████████| 381/381 [03:54<00:00,  1.63it/s]\n",
      "Train... [epoch 2/50, loss 3.30618]: 100%|██████████| 381/381 [04:09<00:00,  1.52it/s]\n",
      "Train... [epoch 3/50, loss 3.18243]: 100%|██████████| 381/381 [04:06<00:00,  1.55it/s]\n",
      "Train... [epoch 4/50, loss 3.02170]: 100%|██████████| 381/381 [04:07<00:00,  1.54it/s]\n",
      "Train... [epoch 5/50, loss 2.86452]: 100%|██████████| 381/381 [04:06<00:00,  1.55it/s]\n",
      "Train... [epoch 6/50, loss 2.72663]: 100%|██████████| 381/381 [04:04<00:00,  1.56it/s]\n",
      "Train... [epoch 7/50, loss 2.64409]: 100%|██████████| 381/381 [04:05<00:00,  1.55it/s]\n",
      "Train... [epoch 8/50, loss 2.59187]: 100%|██████████| 381/381 [04:05<00:00,  1.55it/s]\n",
      "Train... [epoch 9/50, loss 2.53447]: 100%|██████████| 381/381 [04:03<00:00,  1.56it/s]\n",
      "Train... [epoch 10/50, loss 2.50077]: 100%|██████████| 381/381 [04:07<00:00,  1.54it/s]\n",
      "Train... [epoch 11/50, loss 2.44349]: 100%|██████████| 381/381 [04:18<00:00,  1.48it/s]\n",
      "Train... [epoch 12/50, loss 2.42751]: 100%|██████████| 381/381 [04:21<00:00,  1.45it/s]\n",
      "Train... [epoch 13/50, loss 2.34732]: 100%|██████████| 381/381 [04:17<00:00,  1.48it/s]\n",
      "Train... [epoch 14/50, loss 2.33529]: 100%|██████████| 381/381 [04:19<00:00,  1.47it/s]\n",
      "Train... [epoch 15/50, loss 2.33159]: 100%|██████████| 381/381 [04:17<00:00,  1.48it/s]\n",
      "Train... [epoch 16/50, loss 2.28127]: 100%|██████████| 381/381 [04:11<00:00,  1.51it/s]\n",
      "Train... [epoch 17/50, loss 2.26320]: 100%|██████████| 381/381 [04:10<00:00,  1.52it/s]\n",
      "Train... [epoch 18/50, loss 2.24297]: 100%|██████████| 381/381 [03:52<00:00,  1.64it/s]\n",
      "Train... [epoch 19/50, loss 2.22469]: 100%|██████████| 381/381 [03:58<00:00,  1.60it/s]\n",
      "Train... [epoch 20/50, loss 2.21480]: 100%|██████████| 381/381 [03:51<00:00,  1.65it/s]\n",
      "Train... [epoch 21/50, loss 2.18236]: 100%|██████████| 381/381 [04:02<00:00,  1.57it/s]\n",
      "Train... [epoch 22/50, loss 2.15788]: 100%|██████████| 381/381 [04:04<00:00,  1.56it/s]\n",
      "Train... [epoch 23/50, loss 2.12794]: 100%|██████████| 381/381 [04:15<00:00,  1.49it/s]\n",
      "Train... [epoch 24/50, loss 2.12323]: 100%|██████████| 381/381 [04:18<00:00,  1.48it/s]\n",
      "Train... [epoch 25/50, loss 2.09263]: 100%|██████████| 381/381 [04:07<00:00,  1.54it/s]\n",
      "Train... [epoch 26/50, loss 2.09331]: 100%|██████████| 381/381 [04:07<00:00,  1.54it/s]\n",
      "Train... [epoch 27/50, loss 2.08910]: 100%|██████████| 381/381 [04:06<00:00,  1.55it/s]\n",
      "Train... [epoch 28/50, loss 2.07433]: 100%|██████████| 381/381 [04:13<00:00,  1.50it/s]\n",
      "Train... [epoch 29/50, loss 2.05864]: 100%|██████████| 381/381 [04:02<00:00,  1.57it/s]\n",
      "Train... [epoch 30/50, loss 2.04378]: 100%|██████████| 381/381 [04:05<00:00,  1.55it/s]\n",
      "Train... [epoch 31/50, loss 2.03497]: 100%|██████████| 381/381 [04:04<00:00,  1.56it/s]\n",
      "Train... [epoch 32/50, loss 2.02696]: 100%|██████████| 381/381 [04:04<00:00,  1.56it/s]\n",
      "Train... [epoch 33/50, loss 2.02105]: 100%|██████████| 381/381 [04:03<00:00,  1.57it/s]\n",
      "Train... [epoch 34/50, loss 2.01973]: 100%|██████████| 381/381 [04:04<00:00,  1.56it/s]\n",
      "Train... [epoch 35/50, loss 2.00455]: 100%|██████████| 381/381 [04:08<00:00,  1.53it/s]\n",
      "Train... [epoch 36/50, loss 1.99147]: 100%|██████████| 381/381 [04:05<00:00,  1.55it/s]\n",
      "Train... [epoch 37/50, loss 1.94267]: 100%|██████████| 381/381 [04:14<00:00,  1.50it/s]\n",
      "Train... [epoch 38/50, loss 1.97026]: 100%|██████████| 381/381 [04:10<00:00,  1.52it/s]\n",
      "Train... [epoch 39/50, loss 1.94351]: 100%|██████████| 381/381 [04:16<00:00,  1.49it/s]\n",
      "Train... [epoch 40/50, loss 1.95706]: 100%|██████████| 381/381 [04:11<00:00,  1.52it/s]\n",
      "Train... [epoch 41/50, loss 1.93072]: 100%|██████████| 381/381 [04:07<00:00,  1.54it/s]\n",
      "Train... [epoch 42/50, loss 1.92114]: 100%|██████████| 381/381 [04:03<00:00,  1.57it/s]\n",
      "Train... [epoch 43/50, loss 1.91324]: 100%|██████████| 381/381 [04:04<00:00,  1.56it/s]\n",
      "Train... [epoch 44/50, loss 1.92061]: 100%|██████████| 381/381 [04:04<00:00,  1.56it/s]\n",
      "Train... [epoch 45/50, loss 1.90340]: 100%|██████████| 381/381 [04:05<00:00,  1.55it/s]\n",
      "Train... [epoch 46/50, loss 1.93287]: 100%|██████████| 381/381 [04:03<00:00,  1.56it/s]\n",
      "Train... [epoch 47/50, loss 1.90580]: 100%|██████████| 381/381 [04:03<00:00,  1.57it/s]\n",
      "Train... [epoch 48/50, loss 1.89576]: 100%|██████████| 381/381 [03:58<00:00,  1.60it/s]\n",
      "Train... [epoch 49/50, loss 1.87778]: 100%|██████████| 381/381 [03:55<00:00,  1.62it/s]\n",
      "Train... [epoch 50/50, loss 1.89959]: 100%|██████████| 381/381 [03:55<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "import tqdm\n",
    "\n",
    "losses = []\n",
    "print_every = 1\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    data_progress = tqdm.tqdm(dataloader, desc=\"Train...\")\n",
    "    for step, data in enumerate(data_progress, 1):\n",
    "        # data: (batch_size, seq_len) \n",
    "        # ---> src: (batch_size, src_s) + tgt: (batch_size, tgt_s)\n",
    "        # 随机选一个位置，拆分src和tgt\n",
    "        e = random.randint(1, 20)\n",
    "        src = data[:, :e]\n",
    "        # tgt不要最后一个token，tgt_y不要第一个的token\n",
    "        tgt, tgt_y = data[:, e:-1], data[:, e + 1:]\n",
    "        # 进行Transformer的计算和预测 \n",
    "        # out: (batch_size, tgt_s, h) ---> (batch_size, tgt_s, v) \n",
    "        #                           tgt_y: (batch_size, tgt_s)\n",
    "        out = model(src, tgt)\n",
    "        out = model.predict(out)\n",
    "        loss = criterion(out.view(-1, out.size(-1)), tgt_y.contiguous().view(-1))\n",
    "        # 监控nan\n",
    "        with torch.autograd.set_detect_anomaly(False):\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # 更新训练进度\n",
    "        data_progress.set_description(f\"Train... [epoch {epoch}/{num_epochs}, loss {(total_loss / step):.5f}]\")\n",
    "    losses.append(total_loss/step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAHHCAYAAABQhTneAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABb7ElEQVR4nO3deVxU5f4H8M+wDesM+zKAiKAoKmquuKeomJWklZpdtM0y7Zctt5uVqaUXteW2Xm0xtVtmWqJluSua5r4CJoKKoDBsCsM6wMzz+wOZmgBFtjMwn/frdV4w5zxn+J4DOZ/O85znyIQQAkRERERmwkLqAoiIiIhaEsMPERERmRWGHyIiIjIrDD9ERERkVhh+iIiIyKww/BAREZFZYfghIiIis8LwQ0RERGaF4YeIiIjMCsMPUSsxffp0tG/fvkH7LliwADKZrGkLIrqN6r+73NxcqUshMsLwQ9RIMpmsXktcXJzUpUpi+vTpcHR0lLqMehFC4H//+x+GDh0KZ2dn2Nvbo3v37njrrbdQXFwsdXk1VIeLuha1Wi11iUQmyUrqAohau//9739Gr7/++mvs3LmzxvouXbo06ud88cUX0Ov1Ddr3jTfewKuvvtqon9/W6XQ6PPLII1i/fj2GDBmCBQsWwN7eHr/99hsWLlyIDRs2YNeuXfDy8pK61BqWL19ea8B0dnZu+WKIWgGGH6JGevTRR41eHz58GDt37qyx/u9KSkpgb29f759jbW3doPoAwMrKClZW/M/9VpYtW4b169fj5ZdfxjvvvGNYP2PGDDz88MOIiorC9OnTsXXr1hatqz5/Jw8++CDc3d1bqCKi1o/dXkQtYPjw4ejWrRtOnDiBoUOHwt7eHq+99hoAYPPmzRg3bhxUKhXkcjmCgoLw9ttvQ6fTGb3H38f8pKamQiaT4d1338Xnn3+OoKAgyOVy9O3bF8eOHTPat7YxPzKZDLNnz8amTZvQrVs3yOVydO3aFdu2batRf1xcHPr06QNbW1sEBQXhs88+a/JxRBs2bEDv3r1hZ2cHd3d3PProo7h27ZpRG7Vajcceewx+fn6Qy+Xw8fHB+PHjkZqaamhz/PhxjBkzBu7u7rCzs0NgYCAef/zxW/7s0tJSvPPOO+jUqRNiYmJqbL/vvvswbdo0bNu2DYcPHwYA3HvvvejQoUOt7xceHo4+ffoYrfvmm28Mx+fq6orJkycjPT3dqM2t/k4aIy4uDjKZDN9//z1ee+01eHt7w8HBAffff3+NGoD6/S4A4Pz583j44Yfh4eEBOzs7hISE4PXXX6/RLj8/H9OnT4ezszOUSiUee+wxlJSUGLXZuXMnBg8eDGdnZzg6OiIkJKRJjp2oNvxfQaIWkpeXh7Fjx2Ly5Ml49NFHDd0nq1evhqOjI1588UU4Ojpiz549ePPNN6HRaIyuQNRl7dq1KCwsxNNPPw2ZTIZly5ZhwoQJuHTp0m2vFh04cAAbN27Es88+CycnJ3z00UeYOHEi0tLS4ObmBgA4deoUIiMj4ePjg4ULF0Kn0+Gtt96Ch4dH40/KTatXr8Zjjz2Gvn37IiYmBllZWfjwww9x8OBBnDp1ytB9M3HiRCQmJuK5555D+/btkZ2djZ07dyItLc3wevTo0fDw8MCrr74KZ2dnpKamYuPGjbc9Dzdu3MDzzz9f5xWy6OhorFq1Clu2bMGAAQMwadIkREdH49ixY+jbt6+h3ZUrV3D48GGj393ixYsxb948PPzww3jyySeRk5ODjz/+GEOHDjU6PqDuv5NbuX79eo11VlZWNbq9Fi9eDJlMhn/961/Izs7GBx98gIiICJw+fRp2dnYA6v+7OHv2LIYMGQJra2vMmDED7du3x8WLF/Hzzz9j8eLFRj/34YcfRmBgIGJiYnDy5El8+eWX8PT0xNKlSwEAiYmJuPfeexEWFoa33noLcrkcKSkpOHjw4G2PnahBBBE1qVmzZom//6c1bNgwAUCsWLGiRvuSkpIa655++mlhb28vysrKDOumTZsmAgICDK8vX74sAAg3Nzdx/fp1w/rNmzcLAOLnn382rJs/f36NmgAIGxsbkZKSYlh35swZAUB8/PHHhnX33XefsLe3F9euXTOsS05OFlZWVjXeszbTpk0TDg4OdW4vLy8Xnp6eolu3bqK0tNSwfsuWLQKAePPNN4UQQty4cUMAEO+8806d7xUbGysAiGPHjt22rr/64IMPBAARGxtbZ5vr168LAGLChAlCCCEKCgqEXC4XL730klG7ZcuWCZlMJq5cuSKEECI1NVVYWlqKxYsXG7WLj48XVlZWRutv9XdSm+rfa21LSEiIod3evXsFAOHr6ys0Go1h/fr16wUA8eGHHwoh6v+7EEKIoUOHCicnJ8NxVtPr9TXqe/zxx43aPPDAA8LNzc3w+j//+Y8AIHJycup13ESNxW4vohYil8vx2GOP1Vhf/X/cAFBYWIjc3FwMGTIEJSUlOH/+/G3fd9KkSXBxcTG8HjJkCADg0qVLt903IiICQUFBhtdhYWFQKBSGfXU6HXbt2oWoqCioVCpDu+DgYIwdO/a2718fx48fR3Z2Np599lnY2toa1o8bNw6dO3fGL7/8AqDqPNnY2CAuLg43btyo9b2qr0ps2bIFFRUV9a6hsLAQAODk5FRnm+ptGo0GAKBQKDB27FisX78eQghDu++//x4DBgxAu3btAAAbN26EXq/Hww8/jNzcXMPi7e2Njh07Yu/evUY/p66/k1v58ccfsXPnTqNl1apVNdpFR0cbHeODDz4IHx8f/PrrrwDq/7vIycnB/v378fjjjxuOs1ptXaHPPPOM0eshQ4YgLy/PcC6rf2+bN29u8KB+ojvB8EPUQnx9fWFjY1NjfWJiIh544AEolUooFAp4eHgYBksXFBTc9n3//uFTHYTqCgi32rd6/+p9s7OzUVpaiuDg4BrtalvXEFeuXAEAhISE1NjWuXNnw3a5XI6lS5di69at8PLywtChQ7Fs2TKj27mHDRuGiRMnYuHChXB3d8f48eOxatUqaLXaW9ZQHQiqQ1BtagtIkyZNQnp6Og4dOgQAuHjxIk6cOIFJkyYZ2iQnJ0MIgY4dO8LDw8No+eOPP5CdnW30c+r6O7mVoUOHIiIiwmgJDw+v0a5jx45Gr2UyGYKDgw1jpur7u6gOx926datXfbf7G500aRIGDRqEJ598El5eXpg8eTLWr1/PIETNhuGHqIX89QpPtfz8fAwbNgxnzpzBW2+9hZ9//hk7d+40jIWozz/+lpaWta7/69WI5thXCnPmzMGFCxcQExMDW1tbzJs3D126dMGpU6cAVH2Y//DDDzh06BBmz56Na9eu4fHHH0fv3r1RVFRU5/tWT0Nw9uzZOttUbwsNDTWsu++++2Bvb4/169cDANavXw8LCws89NBDhjZ6vR4ymQzbtm2rcXVm586d+Oyzz4x+Tm1/J63d7f7O7OzssH//fuzatQv/+Mc/cPbsWUyaNAmjRo2qMfCfqCkw/BBJKC4uDnl5eVi9ejWef/553HvvvYiIiDDqxpKSp6cnbG1tkZKSUmNbbesaIiAgAACQlJRUY1tSUpJhe7WgoCC89NJL2LFjBxISElBeXo733nvPqM2AAQOwePFiHD9+HN9++y0SExOxbt26Omuovsto7dq1dX7Yfv311wCq7vKq5uDggHvvvRcbNmyAXq/H999/jyFDhhh1EQYFBUEIgcDAwBpXZyIiIjBgwIDbnKGmk5ycbPRaCIGUlBTDXYT1/V1U3+WWkJDQZLVZWFhg5MiReP/993Hu3DksXrwYe/bsqdEtSNQUGH6IJFT9f8R/vdJSXl6O//73v1KVZMTS0hIRERHYtGkTMjIyDOtTUlKabL6bPn36wNPTEytWrDDqntq6dSv++OMPjBs3DkDVfDdlZWVG+wYFBcHJycmw340bN2pcterZsycA3LLry97eHi+//DKSkpJqvVX7l19+werVqzFmzJgaYWXSpEnIyMjAl19+iTNnzhh1eQHAhAkTYGlpiYULF9aoTQiBvLy8Outqal9//bVR194PP/yAzMxMw/it+v4uPDw8MHToUHz11VdIS0sz+hkNuWpY291q9fm9ETUUb3UnktDAgQPh4uKCadOm4f/+7/8gk8nwv//9z6S6nRYsWIAdO3Zg0KBBmDlzJnQ6HT755BN069YNp0+frtd7VFRUYNGiRTXWu7q64tlnn8XSpUvx2GOPYdiwYZgyZYrh9ur27dvjhRdeAABcuHABI0eOxMMPP4zQ0FBYWVkhNjYWWVlZmDx5MgBgzZo1+O9//4sHHngAQUFBKCwsxBdffAGFQoF77rnnljW++uqrOHXqFJYuXYpDhw5h4sSJsLOzw4EDB/DNN9+gS5cuWLNmTY397rnnHjg5OeHll1+GpaUlJk6caLQ9KCgIixYtwty5c5GamoqoqCg4OTnh8uXLiI2NxYwZM/Dyyy/X6zzW5Ycffqh1hudRo0YZ3Srv6uqKwYMH47HHHkNWVhY++OADBAcH46mnngJQNZFmfX4XAPDRRx9h8ODBuOuuuzBjxgwEBgYiNTUVv/zyS73/Lqq99dZb2L9/P8aNG4eAgABkZ2fjv//9L/z8/DB48OCGnRSiW5HkHjOiNqyuW927du1aa/uDBw+KAQMGCDs7O6FSqcQrr7witm/fLgCIvXv3GtrVdat7bbd+AxDz5883vK7rVvdZs2bV2DcgIEBMmzbNaN3u3btFr169hI2NjQgKChJffvmleOmll4StrW0dZ+FP06ZNq/N27KCgIEO777//XvTq1UvI5XLh6uoqpk6dKq5evWrYnpubK2bNmiU6d+4sHBwchFKpFP379xfr1683tDl58qSYMmWKaNeunZDL5cLT01Pce++94vjx47etUwghdDqdWLVqlRg0aJBQKBTC1tZWdO3aVSxcuFAUFRXVud/UqVMFABEREVFnmx9//FEMHjxYODg4CAcHB9G5c2cxa9YskZSUZGhzq7+T2tzqVve//v1U3+r+3Xffiblz5wpPT09hZ2cnxo0bV+NWdSFu/7uolpCQIB544AHh7OwsbG1tRUhIiJg3b16N+v5+C/uqVasEAHH58mUhRNXf1/jx44VKpRI2NjZCpVKJKVOmiAsXLtT7XBDdCZkQJvS/mETUakRFRSExMbHGOBIyPXFxcbj77ruxYcMGPPjgg1KXQyQ5jvkhotsqLS01ep2cnIxff/0Vw4cPl6YgIqJG4JgfIrqtDh06YPr06ejQoQOuXLmC5cuXw8bGBq+88orUpRER3TGGHyK6rcjISHz33XdQq9WQy+UIDw/Hv//97xqT5hERtQYc80NERERmhWN+iIiIyKww/BAREZFZ4ZifWuj1emRkZMDJyanWJxQTERGR6RFCoLCwECqVChYWdV/fYfipRUZGBvz9/aUug4iIiBogPT0dfn5+dW5n+KmFk5MTgKqTp1AoJK6GiIiI6kOj0cDf39/wOV4Xhp9aVHd1KRQKhh8iIqJW5nZDVjjgmYiIiMwKww8RERGZFYYfIiIiMisMP0RERGRWGH6IiIjIrDD8EBERkVlh+CEiIiKzwvBDREREZoXhh4iIiMwKww8RERGZFUnDz/LlyxEWFmZ4jER4eDi2bt1aZ/vhw4dDJpPVWMaNG2doM3369BrbIyMjW+JwiIiIqBWQ9Nlefn5+WLJkCTp27AghBNasWYPx48fj1KlT6Nq1a432GzduRHl5ueF1Xl4eevTogYceesioXWRkJFatWmV4LZfLm+8giIiIqFWRNPzcd999Rq8XL16M5cuX4/Dhw7WGH1dXV6PX69atg729fY3wI5fL4e3t3fQFN5K2UoesAi0c5JZwc2QgIyIikoLJjPnR6XRYt24diouLER4eXq99Vq5cicmTJ8PBwcFofVxcHDw9PRESEoKZM2ciLy/vlu+j1Wqh0WiMlubw8oazGPrOXsSeutYs709ERES3J+mVHwCIj49HeHg4ysrK4OjoiNjYWISGht52v6NHjyIhIQErV640Wh8ZGYkJEyYgMDAQFy9exGuvvYaxY8fi0KFDsLS0rPW9YmJisHDhwiY5nltRKW0BANfyS5v9ZxEREVHtZEIIIWUB5eXlSEtLQ0FBAX744Qd8+eWX2Ldv320D0NNPP41Dhw7h7Nmzt2x36dIlBAUFYdeuXRg5cmStbbRaLbRareG1RqOBv78/CgoKoFAo7vyg6rDm91TM/ykRkV29seIfvZvsfYmIiKjq81upVN7281vybi8bGxsEBwejd+/eiImJQY8ePfDhhx/ecp/i4mKsW7cOTzzxxG3fv0OHDnB3d0dKSkqdbeRyueGOs+qlOfjcvPKTUcArP0RERFKRPPz8nV6vN7oKU5sNGzZAq9Xi0Ucfve37Xb16FXl5efDx8WmqEhtM5WwHAMjIL5O4EiIiIvMl6ZifuXPnYuzYsWjXrh0KCwuxdu1axMXFYfv27QCA6Oho+Pr6IiYmxmi/lStXIioqCm5ubkbri4qKsHDhQkycOBHe3t64ePEiXnnlFQQHB2PMmDEtdlx1qQ4/uUVaaCt1kFvVPgaJiIiImo+k4Sc7OxvR0dHIzMyEUqlEWFgYtm/fjlGjRgEA0tLSYGFhfHEqKSkJBw4cwI4dO2q8n6WlJc6ePYs1a9YgPz8fKpUKo0ePxttvv20Sc/242FvD1toCZRV6qAvKEODmcPudiIiIqElJPuDZFNV3wFRDjHg3Dpdyi7H2qf4YGOTepO9NRERkzlrNgGdzU931lclxP0RERJJg+Glhhju+ONcPERGRJBh+Wpjhjq8CXvkhIiKSAsNPC1M588oPERGRlBh+WphhzA8nOiQiIpIEw08L81FyokMiIiIpMfy0sOpuryJtJTRlFRJXQ0REZH4YflqYvY0VnO2tAXDcDxERkRQYfiSgUnKuHyIiIqkw/EiguuvrGq/8EBERtTiGHwnwji8iIiLpMPxIgHd8ERERSYfhRwKc6JCIiEg6DD8S+PMRFww/RERELY3hRwLV4UddUAa9XkhcDRERkXlh+JGAl5McFjKgQieQW6SVuhwiIiKzwvAjAStLC3gpbo774dPdiYiIWhTDj0R8lBz0TEREJAWGH4kYBj0z/BAREbUohh+J/Bl+2O1FRETUkhh+JKK62e3FWZ6JiIhaFsOPRHzY7UVERCQJhh+J+BomOmS3FxERUUti+JFI9d1eOYVaaCt1EldDRERkPhh+JOLqYAO5VdXpzyrgRIdEREQtheFHIjKZzHDH1zWO+yEiImoxDD8Sqn66O+/4IiIiajkMPxLyUfKOLyIiopbG8CMhFe/4IiIianEMPxJS8fleRERELY7hR0LVV34y+YgLIiKiFsPwI6HqAc+88kNERNRyGH4kVD3guVBbCU1ZhcTVEBERmQeGHwk5yK2gtLMGwK4vIiKiliJp+Fm+fDnCwsKgUCigUCgQHh6OrVu31tl+9erVkMlkRoutra1RGyEE3nzzTfj4+MDOzg4RERFITk5u7kNpsD/v+GLXFxERUUuQNPz4+flhyZIlOHHiBI4fP44RI0Zg/PjxSExMrHMfhUKBzMxMw3LlyhWj7cuWLcNHH32EFStW4MiRI3BwcMCYMWNQVmaaV1Z4xxcREVHLspLyh993331GrxcvXozly5fj8OHD6Nq1a637yGQyeHt717pNCIEPPvgAb7zxBsaPHw8A+Prrr+Hl5YVNmzZh8uTJTXsATYB3fBEREbUskxnzo9PpsG7dOhQXFyM8PLzOdkVFRQgICIC/v3+Nq0SXL1+GWq1GRESEYZ1SqUT//v1x6NChOt9Tq9VCo9EYLS3Fh3d8ERERtSjJw098fDwcHR0hl8vxzDPPIDY2FqGhobW2DQkJwVdffYXNmzfjm2++gV6vx8CBA3H16lUAgFqtBgB4eXkZ7efl5WXYVpuYmBgolUrD4u/v30RHd3u+HPNDRETUoiQPPyEhITh9+jSOHDmCmTNnYtq0aTh37lytbcPDwxEdHY2ePXti2LBh2LhxIzw8PPDZZ581qoa5c+eioKDAsKSnpzfq/e7En8/3YrcXERFRS5B0zA8A2NjYIDg4GADQu3dvHDt2DB9++GG9Ao21tTV69eqFlJQUADCMBcrKyoKPj4+hXVZWFnr27Fnn+8jlcsjl8kYcRcNVT3SoLiiDXi9gYSGTpA4iIiJzIfmVn7/T6/XQarX1aqvT6RAfH28IOoGBgfD29sbu3bsNbTQaDY4cOXLLcURS8lLYQiYDynV65BbX77iJiIio4SS98jN37lyMHTsW7dq1Q2FhIdauXYu4uDhs374dABAdHQ1fX1/ExMQAAN566y0MGDAAwcHByM/PxzvvvIMrV67gySefBFB1J9icOXOwaNEidOzYEYGBgZg3bx5UKhWioqKkOsxbsra0gJeTLdSaMmTml8HTyfb2OxEREVGDSRp+srOzER0djczMTCiVSoSFhWH79u0YNWoUACAtLQ0WFn9enLpx4waeeuopqNVquLi4oHfv3vj999+NBki/8sorKC4uxowZM5Cfn4/Bgwdj27ZtNSZDNCU+zlXhJyO/FD38naUuh4iIqE2TCSGE1EWYGo1GA6VSiYKCAigUimb/ebPWnsQvZzMx795QPDE4sNl/HhERUVtU389vkxvzY46qZ3nO5Fw/REREzY7hxwTw+V5EREQth+HHBHCuHyIiopbD8GMCDLM8s9uLiIio2TH8mIDq53vlFGlRXqmXuBoiIqK2jeHHBLg52MDGygJCAFkadn0RERE1J4YfEyCTyQx3fLHri4iIqHkx/JgI3vFFRETUMhh+TATv+CIiImoZDD8mwteZ3V5EREQtgeHHRPjc7PbKLOCVHyIioubE8GMiVJzrh4iIqEUw/JgI3u1FRETUMhh+TER1t5emrBJF2kqJqyEiImq7GH5MhKPcCgpbKwB8ujsREVFzYvgxIdXjfq4x/BARETUbhh8TouIdX0RERM2O4ceEqDjXDxERUbNj+DEhf97uzis/REREzYXhx4SolJzrh4iIqLkx/JiQP8f8MPwQERE1F4YfE+JTPdFhQRmEEBJXQ0RE1DYx/JgQb6UtZDKgvFKPvOJyqcshIiJqkxh+TIi1pQU8neQAOO6HiIiouTD8mBje8UVERNS8GH5MDO/4IiIial4MPyameqJD3vFFRETUPBh+TIzPzSs/l3KKJa6EiIiobWL4MTEDOrgBAPYn5yC7kON+iIiImhrDj4kJVSlwVztnVOgEvj+aLnU5REREbQ7DjwmKDm8PAFh7NA2VOr20xRAREbUxDD8maGx3b7g62CCzoAy7z2dLXQ4REVGbwvBjguRWlpjU1x8A8M3hKxJXQ0RE1LYw/JioR/q1g0wG/Jaci0s5RVKXQ0RE1GZIGn6WL1+OsLAwKBQKKBQKhIeHY+vWrXW2/+KLLzBkyBC4uLjAxcUFEREROHr0qFGb6dOnQyaTGS2RkZHNfShNzt/VHiNCPAEA3xxOk7gaIiKitkPS8OPn54clS5bgxIkTOH78OEaMGIHx48cjMTGx1vZxcXGYMmUK9u7di0OHDsHf3x+jR4/GtWvXjNpFRkYiMzPTsHz33XctcThN7tHwAADAhhPpKCmvlLgaIiKitkEmhBBSF/FXrq6ueOedd/DEE0/ctq1Op4OLiws++eQTREdHA6i68pOfn49NmzY1uAaNRgOlUomCggIoFIoGv09j6fUCw9+NQ9r1Eiyd2B2T+raTrBYiIiJTV9/Pb5MZ86PT6bBu3ToUFxcjPDy8XvuUlJSgoqICrq6uRuvj4uLg6emJkJAQzJw5E3l5ebd8H61WC41GY7SYAgsLGR4dUBV4vj50BSaWU4mIiFolycNPfHw8HB0dIZfL8cwzzyA2NhahoaH12vdf//oXVCoVIiIiDOsiIyPx9ddfY/fu3Vi6dCn27duHsWPHQqfT1fk+MTExUCqVhsXf37/Rx9VUHurtDxsrCyRmaHA6PV/qcoiIiFo9ybu9ysvLkZaWhoKCAvzwww/48ssvsW/fvtsGoCVLlmDZsmWIi4tDWFhYne0uXbqEoKAg7Nq1CyNHjqy1jVarhVarNbzWaDTw9/eXvNur2kvrz+DHk1cx4S5fvP9wT6nLISIiMkmtptvLxsYGwcHB6N27N2JiYtCjRw98+OGHt9zn3XffxZIlS7Bjx45bBh8A6NChA9zd3ZGSklJnG7lcbrjjrHoxJf+4OfB5y9lMXC8ul7gaIiKi1k3y8PN3er3e6CrM3y1btgxvv/02tm3bhj59+tz2/a5evYq8vDz4+Pg0ZZktqoefEt19lSiv1GP9cT7vi4iIqDEkDT9z587F/v37kZqaivj4eMydOxdxcXGYOnUqACA6Ohpz5841tF+6dCnmzZuHr776Cu3bt4darYZarUZRUdUkgEVFRfjnP/+Jw4cPIzU1Fbt378b48eMRHByMMWPGSHKMTUEmkxmu/nx75Ap0eg58JiIiaihJw092djaio6MREhKCkSNH4tixY9i+fTtGjRoFAEhLS0NmZqah/fLly1FeXo4HH3wQPj4+huXdd98FAFhaWuLs2bO4//770alTJzzxxBPo3bs3fvvtN8jlckmOsancF6aC0s4a6ddLsf9CjtTlEBERtVqSD3g2RaYyz8/fLdpyDl8euIwRnT3x1fS+UpdDRERkUlrNgGeqv6kDqrq+9iZlI/16icTVEBERtU4MP61IoLsDhnR0hxDAN0f4tHciIqKGYPhpZf5x8+rP+mPpKKuoe+JGIiIiqh3DTyszsosXfJ3tcKOkAr/GZ95+ByIiIjLC8NPKWFrI8Ej/qud9fXOYXV9ERER3iuGnFXqojx9kMuBkWj6u5ZdKXQ4REVGrwvDTCnk62aJvQNWT7HckqiWuhoiIqHVh+GmlxnTzBgBsS2D4ISIiuhMMP63U6FAvAMCx1OvIK6r7WWhERERkjOGnlfJ3tUc3XwX0Atj1R5bU5RAREbUaDD+tWGRXdn0RERHdKYafVmzMzfBzMCUPhWUVEldDRETUOjD8tGLBno7o4OGAcp0ee5P4pHciIqL6YPhpxWQymaHrazu7voiIiOqF4aeVi7x5y/vepGw+64uIiKgeGH5aue6+SqiUtigp1+G35FypyyEiIjJ5DD+tnEwmw+jqri/O9kxERHRbDD9tQHXX164/slCh00tcDRERkWlj+GkD+rZ3hauDDfJLKnD08nWpyyEiIjJpDD9tgKWFDKO6VD3ughMeEhER3RrDTxtR3fW145waer2QuBoiIiLTxfDTRgwMdoOj3ApZGi1OX82XuhwiIiKTxfDTRsitLHF3Z08AnPCQiIjoVhh+2pDIv9zyLgS7voiIiGrD8NOGDA/xgI2VBVLzSpCUVSh1OURERCaJ4acNcZBbYWhHDwC864uIiKguDD9tzJiuvOWdiIjoVhh+2piILl6wtJDhvLoQV/KKpS6HiIjI5DD8tDEuDjYY0MEVAJ/1RUREVBuGnzZozM27vtj1RUREVBPDTxs0OrQq/JxMy0eWpkziaoiIiEwLw08b5K20Ra92zgCAHeeypC2GiIjIxDD8tFGGCQ/Z9UVERGRE0vCzfPlyhIWFQaFQQKFQIDw8HFu3br3lPhs2bEDnzp1ha2uL7t2749dffzXaLoTAm2++CR8fH9jZ2SEiIgLJycnNeRgmqXrcz6FLebhRXC5xNURERKZD0vDj5+eHJUuW4MSJEzh+/DhGjBiB8ePHIzExsdb2v//+O6ZMmYInnngCp06dQlRUFKKiopCQkGBos2zZMnz00UdYsWIFjhw5AgcHB4wZMwZlZeY19qW9uwM6eztBpxfY+Qe7voiIiKrJhIk9BMrV1RXvvPMOnnjiiRrbJk2ahOLiYmzZssWwbsCAAejZsydWrFgBIQRUKhVeeuklvPzyywCAgoICeHl5YfXq1Zg8eXK9atBoNFAqlSgoKIBCoWiaA5PAh7uS8Z9dFzCisye+mt5X6nKIiIiaVX0/v01mzI9Op8O6detQXFyM8PDwWtscOnQIERERRuvGjBmDQ4cOAQAuX74MtVpt1EapVKJ///6GNubknu5VXV+/JedAU1YhcTVERESmwUrqAuLj4xEeHo6ysjI4OjoiNjYWoaGhtbZVq9Xw8vIyWufl5QW1Wm3YXr2urja10Wq10Gq1htcajaZBx2JqOno5IcjDARdzirHnj2xE9fKVuiQiIiLJSX7lJyQkBKdPn8aRI0cwc+ZMTJs2DefOnWvRGmJiYqBUKg2Lv79/i/785nRPdx8AwK/xmRJXQkREZBokDz82NjYIDg5G7969ERMTgx49euDDDz+sta23tzeysowH72ZlZcHb29uwvXpdXW1qM3fuXBQUFBiW9PT0xhySSRnbrSr87LuQg2JtpcTVEBERSU/y8PN3er3eqAvqr8LDw7F7926jdTt37jSMEQoMDIS3t7dRG41GgyNHjtQ5jggA5HK54Xb76qWt6OLjhAA3e2gr9diblC11OURERJKTNPzMnTsX+/fvR2pqKuLj4zF37lzExcVh6tSpAIDo6GjMnTvX0P7555/Htm3b8N577+H8+fNYsGABjh8/jtmzZwMAZDIZ5syZg0WLFuGnn35CfHw8oqOjoVKpEBUVJcUhSk4mkxmu/myN54SHREREkg54zs7ORnR0NDIzM6FUKhEWFobt27dj1KhRAIC0tDRYWPyZzwYOHIi1a9fijTfewGuvvYaOHTti06ZN6Natm6HNK6+8guLiYsyYMQP5+fkYPHgwtm3bBltb2xY/PlMxtps3Vuy7iL1J2Sgt18HOxlLqkoiIiCRjcvP8mIK2Ms9PNSEEBi/di2v5pVjxaG9Edqt7/BMREVFr1erm+aHmU9X1VRV4tibwri8iIjJvDD9mYuzNCQ93/5ENbaVO4mqIiIikw/BjJnr5u8BLIUeRthIHknOlLoeIiEgyDD9mwsJChsiu1V1fvOuLiIjMF8OPGRl7c7bnHYlqlFfqJa6GiIhIGgw/ZqRve1e4O9pAU1aJQ5fypC6HiIhIEgw/ZsTSQobRN7u+tvGuLyIiMlMMP2bmnpuzPW9PzEKljl1fRERkfhh+zEz/Dq5wtrfG9eJyHE29LnU5RERELY7hx8xYW1pgdKgXAD7ri4iIzBPDjxmqvutrW6Iaej2fbkJEROaF4ccMDQpyh5OtFXIKtTiRdkPqcoiIiFoUw48ZsrGywKguVV1fv8bzri8iIjIvDD9mqvrJ7tsS2PVFRETmheHHTA3t5AEHG0tkFpThzNV8qcshIiJqMQ0KP+np6bh69arh9dGjRzFnzhx8/vnnTVYYNS9ba0uMuNn1tY3P+iIiIjPSoPDzyCOPYO/evQAAtVqNUaNG4ejRo3j99dfx1ltvNWmB1HzG3uz6+jUhE0Kw64uIiMxDg8JPQkIC+vXrBwBYv349unXrht9//x3ffvstVq9e3ZT1UTMaHuIBW2sLpF8vRcI1jdTlEBERtYgGhZ+KigrI5XIAwK5du3D//fcDADp37ozMTN491FrY21hhZOeqrq/YU9ckroaIiKhlNCj8dO3aFStWrMBvv/2GnTt3IjIyEgCQkZEBNze3Ji2QmteEu3wBAJtPX0MFn/VFRERmoEHhZ+nSpfjss88wfPhwTJkyBT169AAA/PTTT4buMGodhnbygLujHHnF5YhLypG6HCIiomZn1ZCdhg8fjtzcXGg0Gri4uBjWz5gxA/b29k1WHDU/a0sLRPVU4csDl/HjiasYdfO5X0RERG1Vg678lJaWQqvVGoLPlStX8MEHHyApKQmenp5NWiA1v4m9/QAAu89n4UZxucTVEBERNa8GhZ/x48fj66+/BgDk5+ejf//+eO+99xAVFYXly5c3aYHU/Lr4KNBVpUCFTuCnMxlSl0NERNSsGhR+Tp48iSFDhgAAfvjhB3h5eeHKlSv4+uuv8dFHHzVpgdQyJt5VdfXnx5NXb9OSiIiodWtQ+CkpKYGTkxMAYMeOHZgwYQIsLCwwYMAAXLlypUkLpJYxvqcKVhYynL1agOSsQqnLISIiajYNCj/BwcHYtGkT0tPTsX37dowePRoAkJ2dDYVC0aQFUstwc5RjeEjVeK0fePWHiIjasAaFnzfffBMvv/wy2rdvj379+iE8PBxA1VWgXr16NWmB1HIevDnwOfbkNVRyzh8iImqjGnSr+4MPPojBgwcjMzPTMMcPAIwcORIPPPBAkxVHLWtEZ0+42Fsju1CLAym5hitBREREbUmDrvwAgLe3N3r16oWMjAzDE9779euHzp07N1lx1LJsrCxwfw8VAODHk3zcBRERtU0NCj96vR5vvfUWlEolAgICEBAQAGdnZ7z99tvQ69ld0po92NsfALAjUY2C0gqJqyEiImp6Der2ev3117Fy5UosWbIEgwYNAgAcOHAACxYsQFlZGRYvXtykRVLL6earQCcvR1zIKsIvZzPxSP92UpdERETUpGRCCHGnO6lUKqxYscLwNPdqmzdvxrPPPotr11p3l4lGo4FSqURBQYFZ3r322b6LiNl6Hr0DXPDjzIFSl0NERFQv9f38blC31/Xr12sd29O5c2dcv369IW9JJuSBXr6wkAEnrtzA5dxiqcshIiJqUg0KPz169MAnn3xSY/0nn3yCsLCwer9PTEwM+vbtCycnJ3h6eiIqKgpJSUm33Gf48OGQyWQ1lnHjxhnaTJ8+vcb2yMjI+h+gmfNU2GJoJw8AwEbO+UNERG1Mg8b8LFu2DOPGjcOuXbsMc/wcOnQI6enp+PXXX+v9Pvv27cOsWbPQt29fVFZW4rXXXsPo0aNx7tw5ODg41LrPxo0bUV7+58M38/Ly0KNHDzz00ENG7SIjI7Fq1SrDa7lcfieHaPYm3uWHuKQcbDx5DS9EdIKFhUzqkoiIiJpEg8LPsGHDcOHCBXz66ac4f/48AGDChAmYMWMGFi1aZHju1+1s27bN6PXq1avh6emJEydOYOjQobXu4+rqavR63bp1sLe3rxF+5HI5vL2963tI9DejQr3gZGuFa/mlOHwpDwOD3aUuiYiIqEk0eJ4flUqFxYsX48cff8SPP/6IRYsW4caNG1i5cmWDiykoKABQM+DcysqVKzF58uQaV4ri4uLg6emJkJAQzJw5E3l5eQ2uyxzZWlvivptz/vBxF0RE1JY0OPw0Nb1ejzlz5mDQoEHo1q1bvfY5evQoEhIS8OSTTxqtj4yMxNdff43du3dj6dKl2LdvH8aOHQudTlfr+2i1Wmg0GqOF/nzS+7YENYq1lRJXQ0RE1DQa1O3VHGbNmoWEhAQcOHCg3vusXLkS3bt3R79+/YzWT5482fB99+7dERYWhqCgIMTFxWHkyJE13icmJgYLFy5sePFt1F3tnBHo7oDLucX4NT4TD/Xxl7okIiKiRjOJKz+zZ8/Gli1bsHfvXvj5+dVrn+LiYqxbtw5PPPHEbdt26NAB7u7uSElJqXX73LlzUVBQYFjS09PvqP62SiaTYeJdvgCAH9n1RUREbcQdXfmZMGHCLbfn5+ff0Q8XQuC5555DbGws4uLiEBgYWO99N2zYAK1Wi0cfffS2ba9evYq8vDz4+PjUul0ul/NusDo8cJcf3tt5AYcvXUf69RL4u9pLXRIREVGj3NGVH6VSecslICAA0dHR9X6/WbNm4ZtvvsHatWvh5OQEtVoNtVqN0tJSQ5vo6GjMnTu3xr4rV65EVFQU3NzcjNYXFRXhn//8Jw4fPozU1FTs3r0b48ePR3BwMMaMGXMnh0sAfJ3tMDCo6hyvOpgqbTFERERN4I6u/Px13pymsHz5cgBVExf+/edMnz4dAJCWlgYLC+OMlpSUhAMHDmDHjh013tPS0hJnz57FmjVrkJ+fD5VKhdGjR+Ptt9/m1Z0GmjE0CAdT8rDmUCom9vZFV5VS6pKIiIgarEHP9mrrzP3ZXrWZtfYkfjmbiR7+ztg4cyAsOekhERGZmGZ9theZn/n3hsJJboUz6fn49sgVqcshIiJqMIYfqhdPhS3+GRkCAHhnWxKyNGUSV0RERNQwDD9Ub1P7B6CHnxKF2kq8teWc1OUQERE1CMMP1ZulhQz/ntAdlhYy/HI2E3FJ2VKXREREdMcYfuiOdFUp8djA9gCAeZsTUFpe+yNDiIiITBXDD92xF0Z1gkppi/Trpfh4T7LU5RAREd0Rhh+6Yw5yKyy4vysA4PP9l5CkLpS4IiIiovpj+KEGGd3VG6NCvVCpF3g9Nh56PaeLIiKi1oHhhxps4f1dYW9jieNXbmD9cT4MloiIWgeGH2owlbMdXhzVCQAQs/U8cou0EldERER0eww/1CjTB7ZHqI8CBaUV+Pcvf0hdDhER0W0x/FCjWFla4N8TukMmAzaeuoaDKblSl0RERHRLDD/UaD39nRE9IABA1QNQz2VoJK6IiIiobgw/1CReieyMXu2ckV9SgUdXHuHt70REZLIYfqhJOMitsObxfujhp8T14nI88sVhJGcxABERkelh+KEmo7C1xteP90c3XwXyissx5YsjuJhTJHVZRERERhh+qEkp7a3xv8f7o4uPArlFWkz5/DAu5xZLXRYREZEBww81ORcHG3z7ZH909nZCdqEWj3xxGGl5JVKXRUREBIDhh5qJq4MNvnmyPzp6OiKzoAxTvjiM9OsMQEREJD2GH2o27o5yfPtUf3TwcMC1/FJM+eIwruWXSl0WERGZOYYfalaeTrb47qkBCHR3wNUbpZjy+WFkFjAAERGRdBh+qNl5KWyx9qn+aOdqj7TrJZj6xRFcLy6XuiwiIjJTDD/UInyUdvhuxgD4OtvhUm4xnlhzDKXlOqnLIiIiM8TwQy3G19kOax7vC6WdNU6l5WP22pOo1OmlLouIiMwMww+1qGBPJ3w1vQ/kVhbYfT4bb2xKgBBC6rKIiMiMMPxQi+sd4IqPp/SChQxYdywdH+5OlrokIiIyIww/JInRXb3xdlQ3AMAHu5Lx3dE0iSsiIiJzwfBDkpnaPwD/NyIYAPB6bDx2ncuSuCIiIjIHDD8kqRdGdcLDffygF8Ds707iZNoNqUsiIqI2juGHJCWTybD4ge64O8QDZRV6PLH6GJ8ET0REzYrhhyRnbWmBT6fehR7+zrhRUoHolUeRrSmTuiwiImqjGH7IJNjbWOGraX0Q6F71HLB/rDyK5KxCqcsiIqI2iOGHTIaboxxrHusHd0c5krIKMe6jA/h0bwoqOBEiERE1IYYfMint3Oyx5bnBGNHZE+U6Pd7ZnoSoTw8iMaNA6tKIiKiNkDT8xMTEoG/fvnBycoKnpyeioqKQlJR0y31Wr14NmUxmtNja2hq1EULgzTffhI+PD+zs7BAREYHkZE6k11p4K22xcloffDCpJ5ztrZGYocH4Tw7i/R1J0FbyeWBERNQ4koafffv2YdasWTh8+DB27tyJiooKjB49GsXFxbfcT6FQIDMz07BcuXLFaPuyZcvw0UcfYcWKFThy5AgcHBwwZswYlJVxEG1rIZPJENXLFztfGIax3bxRqRf4aE8K7vv4AE6n50tdHhERtWIyYUIPVsrJyYGnpyf27duHoUOH1tpm9erVmDNnDvLz82vdLoSASqXCSy+9hJdffhkAUFBQAC8vL6xevRqTJ0++bR0ajQZKpRIFBQVQKBQNPh5qOr/GZ+LNzQnILSqHhQx4akgHvDCqE2ytLaUujYiITER9P79NasxPQUHVuA5XV9dbtisqKkJAQAD8/f0xfvx4JCYmGrZdvnwZarUaERERhnVKpRL9+/fHoUOHan0/rVYLjUZjtJBpuae7D3a8MAxRPVXQC+Cz/Zdwz0e/If16idSlERFRK2My4Uev12POnDkYNGgQunXrVme7kJAQfPXVV9i8eTO++eYb6PV6DBw4EFevXgUAqNVqAICXl5fRfl5eXoZtfxcTEwOlUmlY/P39m+ioqCm5Otjgg8m98GV0H3gp5LiUU4xpXx3F9eJyqUsjIqJWxGTCz6xZs5CQkIB169bdsl14eDiio6PRs2dPDBs2DBs3boSHhwc+++yzBv/suXPnoqCgwLCkp6c3+L2o+UWEeuGn2YPh62yHS7nFeHz1MZSUV0pdFhERtRImEX5mz56NLVu2YO/evfDz87ujfa2trdGrVy+kpKQAALy9vQEAWVnGD8nMysoybPs7uVwOhUJhtJBp81LYYs3jfaG0s8bp9Hw8t/YUKjkfEBER1YOk4UcIgdmzZyM2NhZ79uxBYGDgHb+HTqdDfHw8fHx8AACBgYHw9vbG7t27DW00Gg2OHDmC8PDwJqudpBfs6YSvpveB3MoCu89n4/XYBJjQ+H0iIjJRkoafWbNm4ZtvvsHatWvh5OQEtVoNtVqN0tJSQ5vo6GjMnTvX8Pqtt97Cjh07cOnSJZw8eRKPPvoorly5gieffBJA1S3Sc+bMwaJFi/DTTz8hPj4e0dHRUKlUiIqKaulDpGbWO8AVnzxyFyxkwPfH0/GfnRekLomIiEyclZQ/fPny5QCA4cOHG61ftWoVpk+fDgBIS0uDhcWfGe3GjRt46qmnoFar4eLigt69e+P3339HaGiooc0rr7yC4uJizJgxA/n5+Rg8eDC2bdtWYzJEahtGhXphUVR3vBYbj4/2pMBLaYup/QOkLouIiEyUSc3zYyo4z0/r9J+dF/Dh7mRYyIDlj/bGmK61j/EiIqK2qVXO80PUGHMiOmJKP3/oBfB/353C8dTrUpdEREQmiOGH2gyZTIa3x3dDRBdPaCv1eGLNcSRnFUpdFhERmRiGH2pTrCwt8PGUu3BXO2cUlFZg2ldHsfd8Nsoq+EBUIiKqwjE/teCYn9bvRnE5Jq74HZdyqh6S62BjieEhnhgV6oW7QzyhtLeWuEIiImpq9f38ZvipBcNP25ClKcMne1Kw45waWRqtYb2VhQwDOrhhdFcvRHTxgsrZTsIqiYioqTD8NALDT9ui1wvEXyvAjnNq7DyXhQtZRUbbu/sq8do9XRAe5CZRhURE1BQYfhqB4adtu5xbjJ03g9DxKzcgBOBsb41dLw6Du6Nc6vKIiKiBeKs7UR0C3R0wY2gQNjwzEMdej0AXHwXySyrw9pZzUpdGREQtgOGHzJq7oxxLJ3aHhQzYfDoDe5OypS6JiIiaGcMPmb0wP2c8PqjqobpvxCagWFspcUVERNScGH6IALw4uhP8XOxwLb8U7+5IkrocIiJqRgw/RADsbazw7we6AwBW/56KU2k3JK6IiIiaC8MP0U1DO3lgwl2+EAJ49cd4lFfqpS6JiIiaAcMP0V+8MS4Urg42SMoqxGf7LkpdDhERNQOGH6K/cHWwwfz7QgEAH+9JQUp20W32ICKi1obhh+hv7u+hwvAQD5Tr9HhtYzz0es4DSkTUljD8EP2NTCbDoqhusLexxNHU6/juWJrUJRERURNi+CGqhZ+LPf45JgQAsOTX81AXlElcERERNRWGH6I6RIe3R09/ZxRqK/Hm5gSpyyEioibC8ENUB0sLGZZM7A4rCxl2nMvChuPpqNTx9nciotaOT3WvBZ/qTn/13o4kfLwnBQDgYGOJuwJc0CfAFX3bu6BnO2fY21hJXCEREQH1//zmv9pEtzHr7mBkacqwNUGNwrJK/Jaci9+ScwFUXR3qplKgT3tX9AlwQahKARcHGzjJrSCTySSunIiIasMrP7XglR+qjV4vcCG7EMdSb+B46nUcT72Ba/mltba1tJBBaWcNZ3trONtZw8XeBkr7qq+B7g54uI8/bKzY60xE1JTq+/nN8FMLhh+qr2v5pYYgdCz1OlLzilFWcftxQRFdvPDp1F6QW1m2QJVEROaB4acRGH6oMcoqdMgvqUB+aXnV15KbX0srkFuoxf8OX4G2Uo+7Qzyw/NHesLVmACIiagoMP43A8EPN6WBKLp5YcwxlFXoM6eiOL6L7MAARETWB+n5+c9ABUQsbFOyO1Y/1g72NJX5LzsXjq4+hpLxS6rKIiMwGww+RBAZ0cMOax/vBwcYSv1/Mw/RVx1CsZQAiImoJDD9EEunb3hX/e7I/nORWOHr5OqZ9dRSFZRVSl0VE1OYx/BBJ6K52Lvjmyf5Q2Frh+JUbiP7qKDQMQEREzYrhh0hiPfydsfapAXC2t8aptHw8+uURFJQwABERNReGHyIT0M1XibVPDoCrgw3OXi3AI18exnm1RuqyiIjaJN7qXgve6k5SSVIXYuqXh5FbVA4A6OzthPt7qnBfmAr+rvYSV0dEZNo4z08jMPyQlC7lFGHJ1vOIS8pB+V+eIt8nwAXje6pwT3cfuDnKJayQiMg0tYp5fmJiYtC3b184OTnB09MTUVFRSEpKuuU+X3zxBYYMGQIXFxe4uLggIiICR48eNWozffp0yGQyoyUyMrI5D4WoyXTwcMTn0X1w7PUILJ3YHQOD3CCTAcev3MC8zYno9+/dmL7qKGJPXeX8QEREDSDplZ/IyEhMnjwZffv2RWVlJV577TUkJCTg3LlzcHBwqHWfqVOnYtCgQRg4cCBsbW2xdOlSxMbGIjExEb6+vgCqwk9WVhZWrVpl2E8ul8PFxaVedfHKD5maLE0Zfj6TgZ/OZODs1QLDeke5Fe7vqcKUvu3Q3U8pYYVERNJrld1eOTk58PT0xL59+zB06NB67aPT6eDi4oJPPvkE0dHRAKrCT35+PjZt2tSgOhh+yJRdzCnCT6czsOn0NVzJKzGs76pSYHJff4zv5QuFrbWEFRIRSaNVdHv9XUFB1f/Rurq61nufkpISVFRU1NgnLi4Onp6eCAkJwcyZM5GXl1fne2i1Wmg0GqOFyFQFeTjihVGdsPel4Vj7VH/c30MFG0sLJGZoqrrFFu/CS+vP4HjqdZjQ/9sQEZkMk7nyo9frcf/99yM/Px8HDhyo937PPvsstm/fjsTERNja2gIA1q1bB3t7ewQGBuLixYt47bXX4OjoiEOHDsHSsuYDJBcsWICFCxfWWM8rP9Ra3Cgux8ZT17DuaBqSs4sM6zt6OuLhPv64r4cK3kpbCSskImp+ra7ba+bMmdi6dSsOHDgAPz+/eu2zZMkSLFu2DHFxcQgLC6uz3aVLlxAUFIRdu3Zh5MiRNbZrtVpotVrDa41GA39/f4YfanWEEDiZlo91R9Ow5WwmSit0AACZDAjv4IaoXr6I7ObNbjEiapNaVfiZPXs2Nm/ejP379yMwMLBe+7z77rtYtGgRdu3ahT59+ty2vYeHBxYtWoSnn376tm055ofaAk1ZBX4+k4FNp67hWOoNw3obKwtEdPHE+J6+GB7iAblVzauhREStUX0/v61asKYahBB47rnnEBsbi7i4uHoHn2XLlmHx4sXYvn17vYLP1atXkZeXBx8fn8aWTNRqKGytMbV/AKb2D0D69RL8dDMIJWcX4dd4NX6NV0NpZ417unsjspsPwnyVcHGwkbpsIqJmJ+mVn2effRZr167F5s2bERISYlivVCphZ2cHAIiOjoavry9iYmIAAEuXLsWbb76JtWvXYtCgQYZ9HB0d4ejoiKKiIixcuBATJ06Et7c3Ll68iFdeeQWFhYWIj4+HXH77yeF45YfaKiEEzmVqsOnUNfx0JgNZGq3Rdl9nO4SqFOiqUqCrSoluvgp4K2whk8kkqpiIqP5aRbdXXf+grlq1CtOnTwcADB8+HO3bt8fq1asBAO3bt8eVK1dq7DN//nwsWLAApaWliIqKwqlTp5Cfnw+VSoXRo0fj7bffhpeXV73qYvghc6DTCxy5lIdNp6/hyOXrRrfN/5Wrgw26qhTo1c4Fjw9qD2d7Xh0iItPUKsKPqWL4IXOkKavAuQwNEjM0SMwowLkMDZKzi6DT//lPhLujDebdG4r7e6h4NYiITA7DTyMw/BBVKavQIUldiISMAqw6mIqUm7fRD+vkgUVR3fiwVSIyKQw/jcDwQ1STtlKHz/Zdwid7UlCu08PO2hIvjuqExwa1h5WlSc2XSkRmqlXO8ExEpktuZYn/G9kRW+cMQf9AV5RW6LD41z8w/tODiP/L88aIiEwdww8R3ZEgD0esmzEAyyaGQWlnjcQMDcZ/egBvbzmHYi2fMk9Epo/hh4jumEwmw8N9/bHrxWG4v4cKegGsPHAZo/+zHz+euIoKnV7qEomI6sQxP7XgmB+iOxOXlI03NiXg6o1SAICfix2eHhaEh3r7wdaaM0gTUcvggOdGYPghunMl5ZVY/XsqVv52GXnF5QAAd0c5nhoSiKkDAuAol3RCeSIyAww/jcDwQ9RwpeU6rD+ejs/3X8K1/KorQQpbK0wfFIjHBrbnIzSIqNkw/DQCww9R41Xo9Nh8OgP/jUvBpZxiAIC9jSUe6dcOM4Z1gKeTrcQVElFbw/DTCAw/RE1HpxfYkajGJ3tTkJihAQA4yq3w3IhgPDYoEDZWvO+CiJoGw08jMPwQNT0hBPYn5+L9HUk4c3NeoEB3B7x5byju7uwpcXVE1BYw/DQCww9R89HrBTaeuoYlW88jt6jqqfJ3h3hg3r2h6ODhKHF1RNSaMfw0AsMPUfMrLKvAJ3tS8NXBy6jQCVhbyvD4oEDMHhEMJ1trqcsjolaI4acRGH6IWs6lnCK8veUc9iblAAA8nOT4V2RnTOjlCwsLPjmeiOqP4acRGH6IWt6e81l4e8sfuJxbdWeYwtYKngpbeDjK4e4kv/nVxuh1e3cHzh9ERAb1/fzmvxpEZBJGdPbC4GAPrDp4GR/vSYGmrBKasiKkZBfVuY+dtSWeGxmMJwYHQm7FmaSJqH545acWvPJDJK2S8kpcvVGKnEItcou0yCnUIqdIi9zC8ptftcguLENuUdVM0h3cHTD//q4Y1slD4sqJSErs9moEhh8i0yeEQOypa/j3r3/eNTamqxfeGBcKf1d7iasjIinU9/Obs4sRUaskk8kw4S4/7H15GJ4YHAhLCxm2J2Yh4v19+Gh3MsoqdFKXSEQmild+asErP0StT5K6EG9uTsCRy9cBAO1c7TH/vlCM7OIlcWVE1FLY7dUIDD9ErZMQAj+fzcTiX84hS1PVFdYv0BUejnLo9AKVegG9ENDp/7IIAQhAYWcNNwcbuDraVH29ubg5yA3rbK05qJrIlDH8NALDD1HrVqStxMd7krHyt8uo1DfdP3GdvBxxd4gnhod4ok97F1hbcuQAkSlh+GkEhh+ituFSThF+S84FAFhayKoWmezP728uQgD5peW4XlSOvOJyXL+5VH2vxfXiclTojP+pdJRbYXCwO+7u7IFhnTzhreRT6omkxvDTCAw/RPRXQghcLy7H7xfzsDcpG/uScpBXXG7UpouPAneHeGBEZ0/0aucCS85OTdTiGH4ageGHiG5FrxdIyCjA3vM52JuUjTNX8/HXf0ndHGwworMnIkK9MKSjO+xtOJ8sUUtg+GkEhh8iuhN5RVrsT87B3vM5iEvKhqas0rDNxsoCg4PdMSrUCyM7e8JTwe4xoubC8NMIDD9E1FAVOj2OpV7HznNZ2HkuC1dvlBpt7+HvjFFdPHF3Z0+E+iggk7F7jKipMPw0AsMPETUFIQQuZBVh5zk1dv6RjTPp+UbbPZ3kuDvEE3d39sCgYHc42VpLUyhRG8Hw0wgMP0TUHLI1Zdj1Rzb2nM/GwZRclP5lFmorCxn6tnfF3Z09cHeIJ4I9HXlViOgOMfw0AsMPETU3baUORy9fN4wTupRbbLTdR2mLUB8FOnk7IcTLCZ28nBDk6cCn1xPdAsNPIzD8EFFLS80txt6kbOxNysHhS3kor9TXaGNpIUN7N3uEeFeFoU5eTgj2dESAmz1DEREYfhqF4YeIpFRSXomzVwuQnFWIpKxCXFAX4bxaY3QX2V9ZyKqeZRbk4YggT0cEeThUfe/hCBcHmxaunkg6DD+NwPBDRKZGCIHsQi2S1IW4kFVo+HoxpxhF2tpDEQC4OtjA38UOKmc7+CjtoHK2vfm9LXyd7eDuKIcFJ2SkNoLhpxEYfoiotagORRezi3AxpwgXc4qrvmYXIaOg7Lb7W1vK4K20hbOdDawtZbCxsoCNlSVsqr+3tIC1pQVsrCzg6WSLYSEeCPNVMjCRSWoV4ScmJgYbN27E+fPnYWdnh4EDB2Lp0qUICQm55X4bNmzAvHnzkJqaio4dO2Lp0qW45557DNuFEJg/fz6++OIL5OfnY9CgQVi+fDk6duxYr7oYfoioLSgpr8SlnGJcyy9FZn4pMgrKkJFfisybX7M0ZWjIc1/dHeWGR3kM7shb9Ml0tIrwExkZicmTJ6Nv376orKzEa6+9hoSEBJw7dw4ODg617vP7779j6NChiImJwb333ou1a9di6dKlOHnyJLp16wYAWLp0KWJiYrBmzRoEBgZi3rx5iI+Px7lz52Bre/vZVRl+iMgcVOr0yCrUIjO/FIVllSjX6VFeWbVU6PR/vr759UJWIfZfyDXqZrO2lKF/oBvu7uyJkZ090d699n+7iVpCqwg/f5eTkwNPT0/s27cPQ4cOrbXNpEmTUFxcjC1bthjWDRgwAD179sSKFSsghIBKpcJLL72El19+GQBQUFAALy8vrF69GpMnT75tHQw/RES1K6/U43jqdew+XzVf0eW/3aLfwd0BA4PdEN7BHQM6uMLNUS5RpWSO6vv5bVJP2ysoKAAAuLq61tnm0KFDePHFF43WjRkzBps2bQIAXL58GWq1GhEREYbtSqUS/fv3x6FDh2oNP1qtFlqt1vBao9E05jCIiNosGysLDAx2x8Bgd8y7NxSXcoqw52YQOnr5Oi7lFuNSbjG+OZwGAAjxckJ4kBvCg9wwINANSnt2kZH0TCb86PV6zJkzB4MGDTJ0X9VGrVbDy8vLaJ2XlxfUarVhe/W6utr8XUxMDBYuXNiY8omIzFIHD0d08HDEk0M6QFNWgUMX83DoYh4OX8rDeXXVrfpJWYVY/XsqZDIg1EeBQcHueHJwIB/ySpIxmfAza9YsJCQk4MCBAy3+s+fOnWt0NUmj0cDf37/F6yAias0UttYY09UbY7p6A6h62v3hS9dx6FIufr+Yh0s5xUjM0CAxQ4OtCZn49okBaOdmL3HVZI5MIvzMnj0bW7Zswf79++Hn53fLtt7e3sjKyjJal5WVBW9vb8P26nU+Pj5GbXr27Fnre8rlcsjl7JcmImpKbo5yjAvzwbiwqn+LszRlOHwpD+/vvIAreSV46LPf8e2T/RHs6SRxpWRuLKT84UIIzJ49G7GxsdizZw8CAwNvu094eDh2795ttG7nzp0IDw8HAAQGBsLb29uojUajwZEjRwxtiIio5XkpbDG+py82PB2OTl6OyNJo8fBnh5GYUSB1aWRmJA0/s2bNwjfffIO1a9fCyckJarUaarUapaWlhjbR0dGYO3eu4fXzzz+Pbdu24b333sP58+exYMECHD9+HLNnzwYAyGQyzJkzB4sWLcJPP/2E+Ph4REdHQ6VSISoqqqUPkYiI/sZTYYt1M8LRzVeB68XlmPL5YZxMu3FH75GRX4oFPyXi3e1JuFFc3kyVUlsl6a3uMlntM4SuWrUK06dPBwAMHz4c7du3x+rVqw3bN2zYgDfeeMMwyeGyZctqneTw888/R35+PgYPHoz//ve/6NSpU73q4q3uRETNT1NWgcdXHcPxKzdgb2OJL6P7YGCw+y33yS8px/K4i1j1e6rh4a+Ocis8OSQQTwwO5ISLZq5VzvNjKhh+iIhaRkl5JWZ8fQIHUnJhY2WBFY/ehRGdvWq0K6vQYdXBVCyPSzE84LVfe1cUaStxLrNqehIXe2vMHB6E6PD2sLWu31PuhRC4lFuMnEIt+gS4wMpS0g4RaiSGn0Zg+CEiajllFTrMXnsKu/7IgpWFDB9O7mUYJF2p0+OHE1fxwa5kqDVVzyrr7O2Ef0V2xvAQDwgBbE1Q472dSbiUUzXhoqeTHM+N7IhJffxhY1UzzGRrynDwYi4OJOfhYEqu4X0D3R3w/MiOuK+HCpZ8dlmrxPDTCAw/REQtq0Knx0vrz+CnMxmwkAFLJ4bBydYa72w/j4s3Q42vsx1eGt0J43v61ggnlTo9Yk9dwwe7knEtv2rcqJ+LHeZEdMKoLl44mnodB1NycTAlF8nZRUb72lhaQG5tgcKbV5Q6ejrihVGdENnVmw9wbWUYfhqB4YeIqOXp9AKvx8Zj3bF0o/Uu9taYdXcwHh0QcNvuLG2lDt8fS8fHe1KQU6ittY1MBnRTKTEo2B2Dgt3QJ8AVOiGw5vdUfLbvoqFbrYuPAi+N6oSRXTzrHKNKpoXhpxEYfoiIpCGEwNtb/sBXBy/DztoSTwwOxIxhHaC4w4HMpeU6fH0oFcv3XUR+SQUC3R0wMMgNg4PdER7kBmd7m1r3KyitwMoDl/HVgcuGB7j28HfGi6M6YWhHd4YgE8fw0wgMP0RE0hFC4GRaPtq52sPDqXET0JZV6FBYVnnH73OjuByf/3YJqw+morRCBwDoE+CC0V29EOqjRBcfJ5N/aGtBSQU+3J2MH06kI6KLF14Y1Qn+rm17Rm2Gn0Zg+CEiIgDIKdRixb6L+N/hK4Zb66t5K2zRxccJoSoFQn2UCFUpEOBqL/k4oUqdHt8dS8f7O5Jwo6TCsN7aUoYp/dph9ohgeDq1zeeqMfw0AsMPERH9VZamDD+cuIrEjAKcy9AgNa+k1nb2NpYI9nREkIcjOrg7IMjTER08HNDezaHO8UoVOj3Sr5fgSl4JLucWIzWvGJdzi2Ehk2FUqBciu3nDvZ5XmQ6m5OKtn88hKasQQNXg7aeGdsDPZzLwW3IuAMDO2hKPDWqPp4cFQWnXtuZFYvhpBIYfIiK6lSJtJZLUGpzL0OBcZtXX8+pCaP92daiaTFZ191kH96owJAQMQefqjVLo9HV/FFvIgPAgN4zrrsKYrl61drel5hZj8a9/YOe5qmdfOttb44WITpjav51h7qLfL+Zi2bYknE7PBwAobK3wzPAgPDYwEHY29ZsXydQx/DQCww8REd2pSp0eqXnFSMkuwsWcYlzKKcbFnCJcyiky3EFWFztrSwS42SPQ3QEBbg4IdLfHjZIK/BqfibNX/3z2maWFDAOD3DCuuw/GdPWGlaUMn+xJwVcHL6NCJ2BpIcM/BgRgTkTHWgd1CyGw81wW3t2RhAtZVbf8ezjJ8X8jgvFQH/96Tw5pqhh+GoHhh4iImooQArlF5biUU4RLucW4lFMECwsZAt0c0N69qkvMSyGv806ytLwS/BKfiV/iM5BwTWNYb2khg4ONpSFYDevkgXn3dkGwp9Nta9LpBTafvob3d17A1Rulhvfr6OmIrioluvkq0M1XiS4+CjjKrZrgLBhLUheio6djk4+PYvhpBIYfIiIyRam5xVVB6Gym4bEeHTwcMG9cKO7u7HnH71deqce6Y2lYEXcRGQVlNbbLZFUzX3e7GYj6Bbqhh5+yQbf8V+j02J6oxprfU3Es9Qb+90Q/DOnoccfvcysMP43A8ENERKbucm4xrt0oRf8OrrBu5DPJhBDI0miRcK0ACRkFSLimQWJGATJrCUTtXO1xfw8VxvdUoaPX7a8y5RRqse5oGr49kmZ4lIiVhQz/iuyMp4Z2aFTdf8fw0wgMP0REREBukRaJGRokXCvA2av5+C05FyXlOsP2zt5OGN/TF/f18IGfi/EcQqfT87Hm91T8cjYT5bqqgeDujjZ4pF87TB0QAC9F099uz/DTCAw/RERENZWUV2LXH9n46fQ17LuQgwrdnxGiT4ALxvdUwd7GCl8fSsWZvwzU7unvjOkD22Nsd2/IrZpvUDXDTyMw/BAREd1afkk5tiaosfn0NRy5fB1/TxM2lha4N8wH0wa2Rw9/5xapieGnERh+iIiI6k9dUIYtZzPw05kMFJVV4oFevpjSv129J2dsKgw/jcDwQ0RE1PrU9/O7ccPDiYiIiFoZhh8iIiIyKww/REREZFYYfoiIiMisMPwQERGRWWH4ISIiIrPC8ENERERmheGHiIiIzArDDxEREZkVhh8iIiIyKww/REREZFYYfoiIiMisMPwQERGRWWH4ISIiIrNiJXUBpkgIAQDQaDQSV0JERET1Vf25Xf05XheGn1oUFhYCAPz9/SWuhIiIiO5UYWEhlEplndtl4nbxyAzp9XpkZGTAyckJMpmsXvtoNBr4+/sjPT0dCoWimSsknu+WxfPdsni+WxbPd8tqzvMthEBhYSFUKhUsLOoe2cMrP7WwsLCAn59fg/ZVKBT8j6cF8Xy3LJ7vlsXz3bJ4vltWc53vW13xqcYBz0RERGRWGH6IiIjIrDD8NBG5XI758+dDLpdLXYpZ4PluWTzfLYvnu2XxfLcsUzjfHPBMREREZoVXfoiIiMisMPwQERGRWWH4ISIiIrPC8ENERERmheGniXz66ado3749bG1t0b9/fxw9elTqktqE/fv347777oNKpYJMJsOmTZuMtgsh8Oabb8LHxwd2dnaIiIhAcnKyNMW2ATExMejbty+cnJzg6emJqKgoJCUlGbUpKyvDrFmz4ObmBkdHR0ycOBFZWVkSVdy6LV++HGFhYYbJ3sLDw7F161bDdp7r5rNkyRLIZDLMmTPHsI7nu2ktWLAAMpnMaOncubNhu5Tnm+GnCXz//fd48cUXMX/+fJw8eRI9evTAmDFjkJ2dLXVprV5xcTF69OiBTz/9tNbty5Ytw0cffYQVK1bgyJEjcHBwwJgxY1BWVtbClbYN+/btw6xZs3D48GHs3LkTFRUVGD16NIqLiw1tXnjhBfz888/YsGED9u3bh4yMDEyYMEHCqlsvPz8/LFmyBCdOnMDx48cxYsQIjB8/HomJiQB4rpvLsWPH8NlnnyEsLMxoPc930+vatSsyMzMNy4EDBwzbJD3fghqtX79+YtasWYbXOp1OqFQqERMTI2FVbQ8AERsba3it1+uFt7e3eOeddwzr8vPzhVwuF999950EFbY92dnZAoDYt2+fEKLq/FpbW4sNGzYY2vzxxx8CgDh06JBUZbYpLi4u4ssvv+S5biaFhYWiY8eOYufOnWLYsGHi+eefF0Lwb7s5zJ8/X/To0aPWbVKfb175aaTy8nKcOHECERERhnUWFhaIiIjAoUOHJKys7bt8+TLUarXRuVcqlejfvz/PfRMpKCgAALi6ugIATpw4gYqKCqNz3rlzZ7Rr147nvJF0Oh3WrVuH4uJihIeH81w3k1mzZmHcuHFG5xXg33ZzSU5OhkqlQocOHTB16lSkpaUBkP5888GmjZSbmwudTgcvLy+j9V5eXjh//rxEVZkHtVoNALWe++pt1HB6vR5z5szBoEGD0K1bNwBV59zGxgbOzs5GbXnOGy4+Ph7h4eEoKyuDo6MjYmNjERoaitOnT/NcN7F169bh5MmTOHbsWI1t/Ntuev3798fq1asREhKCzMxMLFy4EEOGDEFCQoLk55vhh4hqNWvWLCQkJBj10VPTCwkJwenTp1FQUIAffvgB06ZNw759+6Quq81JT0/H888/j507d8LW1lbqcszC2LFjDd+HhYWhf//+CAgIwPr162FnZydhZRzw3Gju7u6wtLSsMUI9KysL3t7eElVlHqrPL89905s9eza2bNmCvXv3ws/Pz7De29sb5eXlyM/PN2rPc95wNjY2CA4ORu/evRETE4MePXrgww8/5LluYidOnEB2djbuuusuWFlZwcrKCvv27cNHH30EKysreHl58Xw3M2dnZ3Tq1AkpKSmS/30z/DSSjY0Nevfujd27dxvW6fV67N69G+Hh4RJW1vYFBgbC29vb6NxrNBocOXKE576BhBCYPXs2YmNjsWfPHgQGBhpt7927N6ytrY3OeVJSEtLS0njOm4her4dWq+W5bmIjR45EfHw8Tp8+bVj69OmDqVOnGr7n+W5eRUVFuHjxInx8fKT/+272IdVmYN26dUIul4vVq1eLc+fOiRkzZghnZ2ehVqulLq3VKywsFKdOnRKnTp0SAMT7778vTp06Ja5cuSKEEGLJkiXC2dlZbN68WZw9e1aMHz9eBAYGitLSUokrb51mzpwplEqliIuLE5mZmYalpKTE0OaZZ54R7dq1E3v27BHHjx8X4eHhIjw8XMKqW69XX31V7Nu3T1y+fFmcPXtWvPrqq0Imk4kdO3YIIXium9tf7/YSgue7qb300ksiLi5OXL58WRw8eFBEREQId3d3kZ2dLYSQ9nwz/DSRjz/+WLRr107Y2NiIfv36icOHD0tdUpuwd+9eAaDGMm3aNCFE1e3u8+bNE15eXkIul4uRI0eKpKQkaYtuxWo71wDEqlWrDG1KS0vFs88+K1xcXIS9vb144IEHRGZmpnRFt2KPP/64CAgIEDY2NsLDw0OMHDnSEHyE4Llubn8PPzzfTWvSpEnCx8dH2NjYCF9fXzFp0iSRkpJi2C7l+ZYJIUTzX18iIiIiMg0c80NERERmheGHiIiIzArDDxEREZkVhh8iIiIyKww/REREZFYYfoiIiMisMPwQERGRWWH4ISKqB5lMhk2bNkldBhE1AYYfIjJ506dPh0wmq7FERkZKXRoRtUJWUhdARFQfkZGRWLVqldE6uVwuUTVE1Jrxyg8RtQpyuRze3t5Gi4uLC4CqLqnly5dj7NixsLOzQ4cOHfDDDz8Y7R8fH48RI0bAzs4Obm5umDFjBoqKiozafPXVV+jatSvkcjl8fHwwe/Zso+25ubl44IEHYG9vj44dO+Knn35q3oMmombB8ENEbcK8efMwceJEnDlzBlOnTsXkyZPxxx9/AACKi4sxZswYuLi44NixY9iwYQN27dplFG6WL1+OWbNmYcaMGYiPj8dPP/2E4OBgo5+xcOFCPPzwwzh79izuueceTJ06FdevX2/R4ySiJtAij08lImqEadOmCUtLS+Hg4GC0LF68WAhR9TT6Z555xmif/v37i5kzZwohhPj888+Fi4uLKCoqMmz/5ZdfhIWFhVCr1UIIIVQqlXj99dfrrAGAeOONNwyvi4qKBACxdevWJjtOImoZHPNDRK3C3XffjeXLlxutc3V1NXwfHh5utC08PBynT58GAPzxxx/o0aMHHBwcDNsHDRoEvV6PpKQkyGQyZGRkYOTIkbesISwszPC9g4MDFAoFsrOzG3pIRCQRhh8iahUcHBxqdEM1FTs7u3q1s7a2Nnotk8mg1+uboyQiakYc80NEbcLhw4drvO7SpQsAoEuXLjhz5gyKi4sN2w8ePAgLCwuEhITAyckJ7du3x+7du1u0ZiKSBq/8EFGroNVqoVarjdZZWVnB3d0dALBhwwb06dMHgwcPxrfffoujR49i5cqVAICpU6di/vz5mDZtGhYsWICcnBw899xz+Mc//gEvLy8AwIIFC/DMM8/A09MTY8eORWFhIQ4ePIjnnnuuZQ+UiJodww8RtQrbtm2Dj4+P0bqQkBCcP38eQNWdWOvWrcOzzz4LHx8ffPfddwgNDQUA2NvbY/v27Xj++efRt29f2NvbY+LEiXj//fcN7zVt2jSUlZXhP//5D15++WW4u7vjwQcfbLkDJKIWIxNCCKmLICJqDJlMhtjYWERFRUldChG1AhzzQ0RERGaF4YeIiIjMCsf8EFGrx957IroTvPJDREREZoXhh4iIiMwKww8RERGZFYYfIiIiMisMP0RERGRWGH6IiIjIrDD8EBERkVlh+CEiIiKzwvBDREREZuX/Af6CPUoqTnddAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, epoch + 1, print_every), losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 存储模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model/model.pth')\n",
    "# model.load_state_dict(torch.load(\"./model/model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = tensor([[  2, 403, 235, 293]]), src_decode = 清明时\n",
      "tgt = tensor([[ 197,    9,  403,   17,   56,    9,   17,  382,  426,  618,  668,   15,\n",
      "          571,  312, 1098,  439,  585,   61,  934,    9,  571,   13,   13, 1122,\n",
      "          330,  350, 2320,   15,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1]]), tgt_decode = 节，清风动，风吹玉管弦。一曲江南望不见，一声声到此中央。\n",
      "完整诗句：清明时节，清风动，风吹玉管弦。一曲江南望不见，一声声到此中央。\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    word_ids = tokenizer.encode(\"清明时节\")\n",
    "    src = torch.tensor([word_ids[:-2]])\n",
    "    tgt = torch.tensor([word_ids[-2:-1]])\n",
    "    # 一个一个词预测，直到预测为<eos>，或者达到句子最大长度\n",
    "    for i in range(64):\n",
    "        out = model(src, tgt)\n",
    "        # 预测结果，只需最后一个词 \n",
    "        # out: (1, tgt_s, h) ---> (1, 1, h) # ---> predict: (1, 1, v) \n",
    "        # ---argmax---> (1, 1) 找出最大值的index\n",
    "        predict = model.predict(out[:,-1:,:])\n",
    "        # predict = model.predict(out)\n",
    "        # print(predict.size())\n",
    "        # predict[0,0,[1,3,9,15,61,514,115,158,17,0]] = 0\n",
    "        # predict[0,0,[1,15]] = 0\n",
    "        # predict[0,0,9] = 0\n",
    "        y = torch.argmax(predict, dim=-1)\n",
    "        # 和之前的预测结果拼接到一起\n",
    "        tgt = torch.cat([tgt, y], dim=1)\n",
    "        # if y == tokenizer.eos_id or tgt.size()[1] == 64:\n",
    "            # break\n",
    "        # break\n",
    "\n",
    "    src_decode = \"\".join([w for w in tokenizer.decode(src[0].tolist()) if w not in [Tokenizer.PAD, Tokenizer.UNKNOWN]])\n",
    "    print(f\"src = {src}, src_decode = {src_decode}\")\n",
    "    tgt_decode = \"\".join([w for w in tokenizer.decode(tgt[0].tolist()) if w not in [Tokenizer.PAD, Tokenizer.UNKNOWN]])\n",
    "    print(f\"tgt = {tgt}, tgt_decode = {tgt_decode}\")\n",
    "    print(f\"完整诗句：{src_decode + tgt_decode}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
