{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import random\n",
    "\n",
    "# 深度学习库pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "# 用于绘制损失函数下降曲线\n",
    "from matplotlib import pyplot as plt\n",
    "# %pdb off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建\n",
    "\n",
    "## 数据集导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单行诗最大长度\n",
    "MAX_LEN = 64\n",
    "MIN_LEN = 5\n",
    "# 禁用的字符，拥有以下符号的诗将被忽略\n",
    "DISALLOWED_WORDS = ['（', '）', '(', ')', '__', '《', '》', '【', '】', '[', ']', '？', '；']\n",
    "\n",
    "# 一首诗（一行）对应一个列表的元素\n",
    "poetry = []\n",
    "\n",
    "# 按行读取数据 poetry.txt\n",
    "with open('./data/poetry.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "# 遍历处理每一条数据    \n",
    "for line in lines:\n",
    "    # 利用正则表达式拆分 标题 和 内容\n",
    "    fields = line.split(\":\")\n",
    "    # 跳过异常数据\n",
    "    if len(fields) != 2:\n",
    "        continue\n",
    "    # 得到诗词内容（后面不需要标题）\n",
    "    content = fields[1]\n",
    "    # 过滤数据：跳过内容过长、过短、存在禁用符的诗词\n",
    "    if len(content) > MAX_LEN - 2 or len(content) < MIN_LEN:\n",
    "        continue\n",
    "    if any(word in content for word in DISALLOWED_WORDS):\n",
    "        continue\n",
    "        \n",
    "    poetry.append(content.replace('\\n', '')) # 最后要记得删除换行符\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寒随穷律变，春逐鸟声开。初风飘带柳，晚雪间花梅。碧林青旧竹，绿沼翠新苔。芝田初雁去，绮树巧莺来。\n",
      "晚霞聊自怡，初晴弥可喜。日晃百花色，风动千林翠。池鱼跃不同，园鸟声还异。寄言博通者，知予物外志。\n",
      "夏律昨留灰，秋箭今移晷。峨嵋岫初出，洞庭波渐起。桂白发幽岩，菊黄开灞涘。运流方可叹，含毫属微理。\n",
      "寒惊蓟门叶，秋发小山枝。松阴背日转，竹影避风移。提壶菊花岸，高兴芙蓉池。欲知凉气早，巢空燕不窥。\n",
      "山亭秋色满，岩牖凉风度。疏兰尚染烟，残菊犹承露。古石衣新苔，新巢封古树。历览情无极，咫尺轮光暮。\n",
      "慨然抚长剑，济世岂邀名。星旗纷电举，日羽肃天行。遍野屯万骑，临原驻五营。登山麾武节，背水纵神兵。在昔戎戈动，今来宇宙平。\n",
      "翠野驻戎轩，卢龙转征旆。遥山丽如绮，长流萦似带。海气百重楼，岩松千丈盖。兹焉可游赏，何必襄城外。\n",
      "玄兔月初明，澄辉照辽碣。映云光暂隐，隔树花如缀。魄满桂枝圆，轮亏镜彩缺。临城却影散，带晕重围结。驻跸俯九都，停观妖氛灭。\n",
      "碧原开雾隰，绮岭峻霞城。烟峰高下翠，日浪浅深明。斑红妆蕊树，圆青压溜荆。迹岩劳傅想，窥野访莘情。巨川何以济，舟楫伫时英。\n",
      "春蒐驰骏骨，总辔俯长河。霞处流萦锦，风前漾卷罗。水花翻照树，堤兰倒插波。岂必汾阴曲，秋云发棹歌。\n",
      "current_line_count = 24375\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(poetry[i])\n",
    "    \n",
    "print(f\"current_line_count = {len(poetry)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寒 -> 2612\n",
      "随 -> 1036\n",
      "穷 -> 482\n",
      "律 -> 118\n",
      "变 -> 286\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# 最小词频\n",
    "MIN_WORD_FREQUENCY = 8\n",
    "\n",
    "# 统计词频，利用Counter可以直接按单个字符进行统计词频\n",
    "counter = Counter()\n",
    "for line in poetry:\n",
    "    counter.update(line)\n",
    "# 过滤掉低词频的词\n",
    "tokens = [token for token, count in counter.items() if count >= MIN_WORD_FREQUENCY]\n",
    "# 打印一下出现次数前5的字\n",
    "for i, (token, count) in enumerate(counter.items()):\n",
    "    print(token, \"->\",count)\n",
    "    if i >= 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \"\"\"\n",
    "    词典编码器\n",
    "    \"\"\"\n",
    "    UNKNOWN = \"<unknown>\"\n",
    "    PAD = \"<pad>\"\n",
    "    BOS = \"<bos>\" \n",
    "    EOS = \"<eos>\" \n",
    "\n",
    "    def __init__(self, tokens):\n",
    "        # 补上特殊词标记：未知词标记、填充字符标记、开始标记、结束标记\n",
    "        tokens = [Tokenizer.UNKNOWN, Tokenizer.PAD, Tokenizer.BOS, Tokenizer.EOS] + tokens\n",
    "        # 词汇表大小\n",
    "        self.dict_size = len(tokens)\n",
    "        # 生成映射关系\n",
    "        self.token_id = {} # 映射: 词 -> 编号\n",
    "        self.id_token = {} # 映射: 编号 -> 词\n",
    "        for idx, word in enumerate(tokens):\n",
    "            self.token_id[word] = idx\n",
    "            self.id_token[idx] = word\n",
    "        \n",
    "        # 各个特殊标记的编号id，方便其他地方使用\n",
    "        self.unknown_id = self.token_id[Tokenizer.UNKNOWN]\n",
    "        self.pad_id = self.token_id[Tokenizer.PAD]\n",
    "        self.bos_id = self.token_id[Tokenizer.BOS]\n",
    "        self.eos_id = self.token_id[Tokenizer.EOS]\n",
    "    \n",
    "    def id_to_token(self, token_id):\n",
    "        \"\"\"\n",
    "        编号 -> 词\n",
    "        \"\"\"\n",
    "        return self.id_token.get(token_id)\n",
    "\n",
    "    def token_to_id(self, token):\n",
    "        \"\"\"\n",
    "        词 -> 编号，取不到时给 UNKNOWN\n",
    "        \"\"\"\n",
    "        return self.token_id.get(token, self.unknown_id)\n",
    "\n",
    "    def encode(self, tokens):\n",
    "        \"\"\"\n",
    "        词列表 -> <bos>编号 + 编号列表 + <eos>编号\n",
    "        \"\"\"\n",
    "        token_ids = [self.bos_id, ] # 起始标记\n",
    "        # 遍历，词转编号\n",
    "        for token in tokens:\n",
    "            token_ids.append(self.token_to_id(token))\n",
    "        token_ids.append(self.eos_id) # 结束标记\n",
    "        return token_ids\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        \"\"\"\n",
    "        编号列表 -> 词列表(去掉起始、结束标记)\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        for idx in token_ids:\n",
    "            # 跳过起始、结束标记\n",
    "            if idx != self.bos_id and idx != self.eos_id:\n",
    "                tokens.append(self.id_to_token(idx))\n",
    "        return tokens\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dict_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index和独热向量互化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2onehot(word_ids, vocab_size):\n",
    "    r\"\"\"\n",
    "    由索引转化为独热编码\n",
    "    Args:\n",
    "        word_ids (torch.Tensor): \n",
    "            A 1D or 2D tensor containing word indices. \n",
    "            (seq_len, ) or (batch_size, seq_len)\n",
    "\n",
    "        vocab_size (int): \n",
    "            The size of the vocabulary.\n",
    "\n",
    "    Returns: \n",
    "        torch.Tensor: \n",
    "            A tensor containing one-hot encoded vectors.\n",
    "            (seq_len, vocab_size) or (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `word_ids` is not a 1D or 2D tensor.\n",
    "    \"\"\"\n",
    "    if word_ids.dim() == 1:\n",
    "        # 一维情况：(seq_len,)\n",
    "        onehot_tensor = torch.zeros(len(word_ids), vocab_size)\n",
    "        for i, s in enumerate(word_ids): \n",
    "            onehot_tensor[i, s] = 1\n",
    "    elif word_ids.dim() == 2:\n",
    "        # 二维情况：(batch_size, seq_len)\n",
    "        batch_size, seq_len = word_ids.size()\n",
    "        onehot_tensor = torch.zeros(batch_size, seq_len, vocab_size, dtype=torch.float32)\n",
    "        onehot_tensor.scatter_(2, word_ids.unsqueeze(2), 1)\n",
    "    else:\n",
    "        raise ValueError(\"word_ids must be a 1D or 2D tensor\")\n",
    "    return onehot_tensor\n",
    "\n",
    "def onehot2index(word_ids):\n",
    "    \"\"\"\n",
    "    独热编码转化为索引 (*, vocab_size) ---> (*,)\n",
    "    \"\"\"\n",
    "    return torch.argmax(word_ids, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(TensorDataset):\n",
    "    \"\"\"\n",
    "    数据集定义\n",
    "    \"\"\"\n",
    "    def __init__(self, data, tokenizer, max_len=64):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len  # 每条数据的最大长度\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        将文本转化为索引并返回\n",
    "        \"\"\"\n",
    "        line = self.data[index]\n",
    "        word_ids = self.encode_pad_line(line)\n",
    "        return torch.tensor(word_ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def encode_pad_line(self, line):\n",
    "        \"\"\"\n",
    "        将文本转化为索引并返回，对齐序列长度为`max_len`\n",
    "        \"\"\"\n",
    "        word_ids = self.tokenizer.encode(line)\n",
    "        # 如果句子长度不足max_len，填充PAD；超过max_len，截断\n",
    "        if len(word_ids) <= self.max_len:\n",
    "            word_ids = word_ids + [self.tokenizer.pad_id] * (self.max_len - len(word_ids))\n",
    "        else:\n",
    "            word_ids = word_ids[:self.max_len - 1].append(self.tokenizer.eos_id)\n",
    "        return word_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 嵌入层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    \"\"\"\n",
    "    嵌入层 将索引转化为独热向量，并线性嵌入\n",
    "    \"\"\"\n",
    "    def __init__(self, v, h):\n",
    "        \"\"\"\n",
    "        v: 词汇表大小\n",
    "        h: 嵌入后维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(v, h)\n",
    "        self.h = h\n",
    "        self.v = v\n",
    "\n",
    "    def forward(self, src):\n",
    "        # print(src.size())\n",
    "        onehot_tensor = index2onehot(src, self.v)\n",
    "        # print(onehot_tensor.size())\n",
    "        return self.embedding(onehot_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 位置编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    位置编码\n",
    "    \"\"\"\n",
    "    def __init__(self, h, dropout=0.1, max_len=64):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, h)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, h, 2).float() * (-math.log(10000.0) / h))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size(), self.pe.size())\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False) \n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意力模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    注意力模块，提供 q = k = v 的自注意力模式和 k = v 的交叉注意力模式\n",
    "    \"\"\"\n",
    "    def __init__(self, h, a, dropout=0.1, type = 'self'):\n",
    "        '''\n",
    "        h: 嵌入层维度\n",
    "        a: 注意力头数\n",
    "        d_k: 每个注意力头的第二个维度 d_k = h//a\n",
    "\n",
    "        X: (s,h) ---Wq, Wk, Wv: (h, h//a) ---> Q,K,V: (s, h//a) \n",
    "\n",
    "            ---> softmax(Q * K.t / sqrt(d_k)) * V: (s, h//a)\n",
    "\n",
    "            ---> output: (s, h) ---out_proj: (h, h)---> output: (s, h)\n",
    "        '''\n",
    "        super().__init__()  # 注意这里的修正，使用super()而不是super.__init__()\n",
    "        self.h = h\n",
    "        self.a = a\n",
    "        self.d_k = h // a\n",
    "        self.types = type\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # 初始化Q, K, V的权重矩阵\n",
    "        # 每个权重矩阵的维数是(s, h//a) 这里是(h, h)，是将每个头的相应矩阵拼接到一起了\n",
    "        self.Wq = nn.Linear(h, h)\n",
    "        self.Wk = nn.Linear(h, h)\n",
    "        self.Wv = nn.Linear(h, h)\n",
    "        \n",
    "        # 缩放因子，用于缩放点积结果\n",
    "        self.scale = 1 / math.sqrt(self.d_k)\n",
    "\n",
    "        self.out_proj = nn.Linear(h, h)\n",
    "\n",
    "    def forward(self, x, y = None, padding_mask=None, tgt_sequence_mask = None):\n",
    "        \"\"\"\n",
    "        x: (batch_size, s = tgt_s, h), 自注意力的q k v\n",
    "        y: (batch_size, s = src_s, h), 交叉注意力的k v\n",
    "        tgt_sequence_mask: (tgt_s, tgt_s)\n",
    "        padding_mask : (batch_size, src_s)\n",
    "        padding_mask: 添加给key的掩码，用于掩盖pad的影响\n",
    "        tgt_sequence_mask: decoder自注意力添加给key的掩码，用于遮蔽未来信息\n",
    "\n",
    "        Step #1 通过线性变换得到Q, K, V\n",
    "        q,k,v: (batch_size, s, h) ---> (batch_size, s, a, d_k) ---> (batch_size, a, s, d_k)\n",
    "        crros attention时q的s=tgt_s, kv的s=src_s\n",
    "\n",
    "        Step#2 应用掩码，计算注意力分数\n",
    "        k: (batch_size, a, src_s, d_k) ---> (batch_size, a, d_k, src_s)\n",
    "        tgt_sequence_mask: (tgt_s, tgt_s) ---> (batch_size, a, tgt_s, tgt_s)\n",
    "        padding_mask : (batch_size, src_s) ---> (batch_size, a, tgt_s, src_s)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \"\"\"\n",
    "        Step #1 通过线性变换得到Q, K, V\n",
    "        q,k,v: (batch_size, s, h) ---> (batch_size, s, a, d_k) ---> (batch_size, a, s, d_k)\n",
    "        crros attention时q的s=tgt_s, kv的s=src_s\n",
    "        \"\"\"\n",
    "        if self.types == 'self':            # 自注意力机制，均来自输入x            \n",
    "            assert y is None, (\"Self Attention but different input for Q K V\")\n",
    "            q = k = v = x\n",
    "        elif self.types == 'cross':         # 交叉注意力机制，q来自x，k v来自y\n",
    "            assert y is not None, (\"Cross Attention but the same input for Q K V\")\n",
    "            q = x\n",
    "            k = v = y\n",
    "        else: raise ValueError(\"Undefined Attention Type\")\n",
    "\n",
    "        q = self.Wq(q).view(batch_size, -1, self.a, self.d_k).transpose(1, 2)\n",
    "        k = self.Wk(k).view(batch_size, -1, self.a, self.d_k).transpose(1, 2)\n",
    "        v = self.Wv(v).view(batch_size, -1, self.a, self.d_k).transpose(1, 2)\n",
    "\n",
    "        \"\"\"\n",
    "        Step#2 应用掩码，计算注意力分数\n",
    "        k: (batch_size, a, src_s, d_k) ---> (batch_size, a, d_k, src_s)\n",
    "        tgt_sequence_mask: (tgt_s, tgt_s) ---> (batch_size, a, tgt_s, tgt_s)\n",
    "        padding_mask : (batch_size, src_s) ---> (batch_size, a, tgt_s, src_s)\n",
    "        \"\"\"\n",
    "        k_len  = k.size()[2]\n",
    "        scores = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "        if padding_mask is not None:\n",
    "            # print(padding_mask)\n",
    "            mask = padding_mask.view(batch_size, 1, 1, k_len).expand(batch_size, self.a, q.size()[2], k_len)\n",
    "            if tgt_sequence_mask is not None: \n",
    "                assert self.types == 'self' , \\\n",
    "                        (f\"Only Self Attention in Decoder Needs Sequence Mask, but now {self.types} attetion!\")\n",
    "                s_mask = tgt_sequence_mask.view(1, 1, k_len, k_len).   \\\n",
    "                expand(batch_size, self.a, -1, -1)\n",
    "                mask = s_mask.logical_or(mask)\n",
    "            # print(mask.size(), scores.size())\n",
    "            # print(mask)\n",
    "            scores = scores.masked_fill(mask, -1e9)\n",
    "        \n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.h)\n",
    "        output = self.out_proj(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeedForward层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    FeedForward层，默认hiddenDim = 4 * h\n",
    "    \"\"\"\n",
    "    def __init__(self, h, hiddenDim = None, outDim = None, dropout = 0.1, type = 'relu'):\n",
    "        \"\"\"\n",
    "        h: 嵌入层维度\n",
    "        hiddenDim: 隐层维度，默认4*h\n",
    "        outDim: 输出维度，默认h\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.h = h\n",
    "        if hiddenDim is None: hiddenDim = 4 * h\n",
    "        if outDim is None: outDim = h\n",
    "        self.W1 = nn.Linear(h, hiddenDim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.W2 = nn.Linear(hiddenDim, outDim)\n",
    "        self.types = type\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        W1: (h, hiddenDim)\n",
    "        W2: (hiddenDim, outDim)\n",
    "        x: (h, h) ---> x * W_1: (h, hiddenDim) ---> relu/gelu: (h, hiddenDim) ---> A' * W2: (h, outDim)\n",
    "        \"\"\"\n",
    "        x = self.W1(x)\n",
    "        if self.types == 'relu': x = F.relu(x)\n",
    "        elif self.types == 'gelu': x = F.gelu(x)\n",
    "        else: raise ValueError(\"Unsupported activation type\")\n",
    "        x = self.dropout(x)\n",
    "        x = self.W2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    层归一化\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-5, elementwise_affine=True):\n",
    "        super().__init__()\n",
    "        self.normalized_shape = normalized_shape\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        层归一化，计算input最后一个维度均值和方差并标准化\n",
    "        input: (*, h) ---> (*, h)\n",
    "        \"\"\"\n",
    "        # 计算均值和方差\n",
    "        assert self.normalized_shape[0] == input.size()[-1], (\"Unmatched Shape.\")\n",
    "        mean = input.mean(dim=-1, keepdim=True)\n",
    "        var = input.var(dim=-1, unbiased=False, keepdim=True)\n",
    "        std = torch.sqrt(var + self.eps)\n",
    "        \n",
    "        # 应用层归一化公式\n",
    "        normalized_input = (input - mean) / std\n",
    "        normalized_input = normalized_input * self.weight + self.bias\n",
    "        \n",
    "        return normalized_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfomer主流程\n",
    "包含从嵌入层进入attention block之后的所有流程：encoder decoder feedforward add&norm\n",
    "- 对于encoder来讲，self-attention ---> add&norm ---> feedforward ---> add&norm\n",
    "- 对于decoder来讲，self-attention ---> add&norm ---> cross-attention ---> add&norm ---> feedforward ---> add&norm\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer中解码器和编码器架构\n",
    "    \"\"\"\n",
    "    def __init__(self, h, a, num_encoder_layers, num_decoder_layers, dim_feedforward=2048, dropout=0.1):\n",
    "        \"\"\"\n",
    "        h: 输入维度\n",
    "        a: 注意力头数\n",
    "        num_encoder_layers: 编码器层数\n",
    "        num_decoder_layers: 解码器层数\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoders = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                Attention(h, a, dropout),\n",
    "                LayerNorm((h,)),\n",
    "                FeedForward(h, dropout = dropout),\n",
    "                LayerNorm((h,))\n",
    "            ]) for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.decoders = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                Attention(h, a, dropout),\n",
    "                LayerNorm((h,)),\n",
    "                Attention(h, a, dropout, type='cross'),\n",
    "                LayerNorm((h,)),\n",
    "                FeedForward(h, dropout = dropout),\n",
    "                LayerNorm((h,))\n",
    "            ]) for _ in range(num_decoder_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, encoder_input, decoder_input, src_padding_mask=None, tgt_padding_mask = None, tgt_sequence_mask=None, norm_first = False):\n",
    "        \"\"\"\n",
    "        Transformer前向传播\n",
    "        encoder_input: 编码器输入\n",
    "        decoder_input: 解码器输入\n",
    "        src_padding_mask: 编码器pad掩码\n",
    "        tgt_padding_mask: 解码器pad掩码\n",
    "        tgt_sequence_mask: 解码器自注意力序列掩码，用于遮蔽未来信息\n",
    "        norm_first: 是否调整LN结构，如果为True，则先进行归一化和相应计算，再进行残差连接\n",
    "        \"\"\"\n",
    "        for enc in self.encoders:\n",
    "            attention, norm1, ff, norm2 = enc\n",
    "            if not norm_first:\n",
    "                encoder_input = norm1(attention(encoder_input, padding_mask=src_padding_mask) + encoder_input)\n",
    "                encoder_input = norm2(ff(encoder_input) + encoder_input)\n",
    "            else:\n",
    "                encoder_input = attention(norm1(encoder_input), padding_mask=src_padding_mask) + encoder_input\n",
    "                encoder_input = ff(norm2(encoder_input)) + encoder_input\n",
    "\n",
    "        for dec in self.decoders:\n",
    "            self_attention, norm1, cross_attention, norm2, ff, norm3 = dec\n",
    "            if not norm_first:\n",
    "                decoder_input = norm1(self_attention(decoder_input, padding_mask=tgt_padding_mask, \\\n",
    "                                                    tgt_sequence_mask = tgt_sequence_mask) + decoder_input)\n",
    "                decoder_input = norm2(cross_attention(decoder_input, encoder_input, \\\n",
    "                                                    padding_mask=src_padding_mask) + decoder_input)\n",
    "                decoder_input = norm3(ff(decoder_input) + decoder_input)\n",
    "            else:\n",
    "                decoder_input = self_attention(norm1(decoder_input), padding_mask=tgt_padding_mask, \\\n",
    "                                                    tgt_sequence_mask = tgt_sequence_mask) + decoder_input\n",
    "                decoder_input = cross_attention(norm2(decoder_input), encoder_input, \\\n",
    "                                                    padding_mask=src_padding_mask) + decoder_input\n",
    "                decoder_input = ff(norm3(decoder_input)) + decoder_input\n",
    "        return decoder_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(nn.Module):\n",
    "    \"\"\"\n",
    "    预测层\n",
    "    \"\"\"\n",
    "    def __init__(self, h, v):\n",
    "        super().__init__()\n",
    "        self.w = nn.Linear(h, v)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer架构\n",
    "    \"\"\"\n",
    "    def __init__(self, v, h, a, num_encoder_layers, num_decoder_layers, dimFF, dropout, max_len):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(v,h)\n",
    "        # self.embedding = nn.Embedding(v, h, padding_idx=1)\n",
    "        self.posEncoding = PositionalEncoding(h, 0, max_len)\n",
    "        self.transformer = TransformerEncoderDecoder(h, a, num_encoder_layers, num_decoder_layers, dimFF, dropout)\n",
    "        self.predict = Prediction(h, v)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, src, tgt, src_padding_mask = None, tgt_padding_mask = None, tgt_sequence_mask = None):\n",
    "        \"\"\"\n",
    "        src/tgt: 两段index序列，分别被嵌入层转化为编码器和解码器输入\n",
    "        src_padding_mask: 编码器pad掩码\n",
    "        tgt_padding_mask: 解码器pad掩码\n",
    "        tgt_sequence_mask: 解码器自注意力序列掩码，用于遮蔽未来信息\n",
    "        如果不手动提供上述掩码，会自动生成默认pad掩码和序列掩码\n",
    "        \"\"\"\n",
    "        if src_padding_mask is None: \n",
    "            src_padding_mask = self.get_key_padding_mask(src).to(DEVICE)\n",
    "        if tgt_padding_mask is None: \n",
    "            tgt_padding_mask = self.get_key_padding_mask(tgt).to(DEVICE)\n",
    "        if tgt_sequence_mask is None: \n",
    "            tgt_sequence_mask = self.get_sequence_mask(tgt).to(DEVICE)\n",
    "\n",
    "        src = self.embedding(src)\n",
    "        tgt = self.embedding(tgt)\n",
    "\n",
    "        src = self.posEncoding(src)\n",
    "        tgt = self.posEncoding(tgt)\n",
    "\n",
    "        output = self.transformer(src, tgt, src_padding_mask, tgt_padding_mask, tgt_sequence_mask)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sequence_mask(tgt):\n",
    "        \"\"\"\n",
    "        tgt: (s,) ---> (s,s)\n",
    "        生成序列掩码\n",
    "        \"\"\"\n",
    "        size = tgt.size()[-1]\n",
    "        sr = torch.triu(torch.full((size, size), True, device=DEVICE), diagonal=1)\n",
    "        # print(sr)\n",
    "        return sr\n",
    "\n",
    "    @staticmethod\n",
    "    def get_key_padding_mask(tokens):\n",
    "        \"\"\"\n",
    "        tokens: (s,) ---> (s,)\n",
    "        生成pad掩码\n",
    "        \"\"\"\n",
    "        key_padding_mask = torch.full(tokens.size(), False, dtype=bool)\n",
    "        key_padding_mask[tokens == 1] = True\n",
    "        return key_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练和预测\n",
    "\n",
    "### 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embedding): Embedding(3428, 128, padding_idx=1)\n",
      "  (posEncoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (transformer): TransformerEncoderDecoder(\n",
      "    (encoders): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (decoders): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "        (4): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): LayerNorm()\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "        (4): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): LayerNorm()\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "        (4): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predict): Prediction(\n",
      "    (w): Linear(in_features=128, out_features=3428, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(tokens)\n",
    "v = len(tokenizer)\n",
    "batch_size = 64\n",
    "max_len = 64\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "dataset = MyDataset(poetry, tokenizer,  max_len)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 初始化模型、优化器和损失函数\n",
    "h = 128\n",
    "a = 4\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dim_feedforward = 4 * h\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(v, h, a, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, max_len)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model.to(device)\n",
    "    # print(next(model.parameters()).device)  # 输出: cuda:0\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train... [epoch 1/50, loss 3.66960]: 100%|██████████| 381/381 [03:45<00:00,  1.69it/s]\n",
      "Train... [epoch 2/50, loss 3.28136]: 100%|██████████| 381/381 [03:36<00:00,  1.76it/s]\n",
      "Train... [epoch 3/50, loss 3.14845]: 100%|██████████| 381/381 [03:30<00:00,  1.81it/s]\n",
      "Train... [epoch 4/50, loss 3.02539]: 100%|██████████| 381/381 [03:28<00:00,  1.82it/s]\n",
      "Train... [epoch 5/50, loss 2.88930]: 100%|██████████| 381/381 [03:35<00:00,  1.77it/s]\n",
      "Train... [epoch 6/50, loss 2.86914]: 100%|██████████| 381/381 [03:40<00:00,  1.73it/s]\n",
      "Train... [epoch 7/50, loss 2.78042]: 100%|██████████| 381/381 [03:38<00:00,  1.75it/s]\n",
      "Train... [epoch 8/50, loss 2.70861]: 100%|██████████| 381/381 [03:41<00:00,  1.72it/s]\n",
      "Train... [epoch 9/50, loss 2.70174]: 100%|██████████| 381/381 [03:36<00:00,  1.76it/s]\n",
      "Train... [epoch 10/50, loss 2.64658]: 100%|██████████| 381/381 [03:36<00:00,  1.76it/s]\n",
      "Train... [epoch 11/50, loss 2.62543]: 100%|██████████| 381/381 [03:39<00:00,  1.74it/s]\n",
      "Train... [epoch 12/50, loss 2.56787]: 100%|██████████| 381/381 [03:37<00:00,  1.75it/s]\n",
      "Train... [epoch 13/50, loss 2.58452]: 100%|██████████| 381/381 [03:39<00:00,  1.74it/s]\n",
      "Train... [epoch 14/50, loss 2.54209]: 100%|██████████| 381/381 [03:39<00:00,  1.74it/s]\n",
      "Train... [epoch 15/50, loss 2.49608]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 16/50, loss 2.48693]: 100%|██████████| 381/381 [03:33<00:00,  1.79it/s]\n",
      "Train... [epoch 17/50, loss 2.46370]: 100%|██████████| 381/381 [03:32<00:00,  1.80it/s]\n",
      "Train... [epoch 18/50, loss 2.42376]: 100%|██████████| 381/381 [03:36<00:00,  1.76it/s]\n",
      "Train... [epoch 19/50, loss 2.39608]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 20/50, loss 2.39437]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 21/50, loss 2.38628]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 22/50, loss 2.34859]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 23/50, loss 2.34978]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 24/50, loss 2.33342]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 25/50, loss 2.32956]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 26/50, loss 2.31493]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 27/50, loss 2.29926]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 28/50, loss 2.28907]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 29/50, loss 2.25806]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 30/50, loss 2.26798]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 31/50, loss 2.23130]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 32/50, loss 2.22845]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 33/50, loss 2.21270]: 100%|██████████| 381/381 [03:32<00:00,  1.80it/s]\n",
      "Train... [epoch 34/50, loss 2.18993]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 35/50, loss 2.20399]: 100%|██████████| 381/381 [03:33<00:00,  1.78it/s]\n",
      "Train... [epoch 36/50, loss 2.20833]: 100%|██████████| 381/381 [03:34<00:00,  1.78it/s]\n",
      "Train... [epoch 37/50, loss 2.18427]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 38/50, loss 2.16265]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 39/50, loss 2.19014]: 100%|██████████| 381/381 [03:33<00:00,  1.78it/s]\n",
      "Train... [epoch 40/50, loss 2.13009]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 41/50, loss 2.13341]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 42/50, loss 2.15037]: 100%|██████████| 381/381 [03:32<00:00,  1.80it/s]\n",
      "Train... [epoch 43/50, loss 2.12957]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 44/50, loss 2.10275]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 45/50, loss 2.11451]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 46/50, loss 2.09422]: 100%|██████████| 381/381 [03:32<00:00,  1.80it/s]\n",
      "Train... [epoch 47/50, loss 2.08405]: 100%|██████████| 381/381 [03:33<00:00,  1.78it/s]\n",
      "Train... [epoch 48/50, loss 2.10847]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 49/50, loss 2.09687]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 50/50, loss 2.05075]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "import tqdm\n",
    "\n",
    "losses = []\n",
    "print_every = 1\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    data_progress = tqdm.tqdm(dataloader, desc=\"Train...\")\n",
    "    for step, data in enumerate(data_progress, 1):\n",
    "        data = data.to(DEVICE)\n",
    "        # data: (batch_size, seq_len) \n",
    "        # ---> src: (batch_size, src_s) + tgt: (batch_size, tgt_s)\n",
    "        # 随机选一个位置，拆分src和tgt\n",
    "        e = random.randint(1, 20)\n",
    "        src = data[:, :e]\n",
    "        # tgt不要最后一个token，tgt_y不要第一个的token\n",
    "        tgt, tgt_y = data[:, e:-1], data[:, e + 1:]\n",
    "        # 进行Transformer的计算和预测 \n",
    "        # out: (batch_size, tgt_s, h) ---> (batch_size, tgt_s, v) \n",
    "        #                           tgt_y: (batch_size, tgt_s)\n",
    "        out = model(src, tgt)\n",
    "        out = model.predict(out)\n",
    "        loss = criterion(out.view(-1, out.size(-1)), tgt_y.contiguous().view(-1))\n",
    "        # 监控nan\n",
    "        with torch.autograd.set_detect_anomaly(False):\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # 更新训练进度\n",
    "        data_progress.set_description(f\"Train... [epoch {epoch}/{num_epochs}, loss {(total_loss / step):.5f}]\")\n",
    "    losses.append(total_loss/step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYi0lEQVR4nO3deVxU5f4H8M+wDeuwiOwoCggqouaKW6a4lSZpV/NaaNm1FLvarV9lZS5luFQ3q5vapm3mVqi5ZLiAaW7gBqgoKqAsAiI7DDDz/P4gpohVHOYMw+f9ep1XzpnnzHznQM7H53nOc2RCCAEiIiIiA2EkdQFERERE2sRwQ0RERAaF4YaIiIgMCsMNERERGRSGGyIiIjIoDDdERERkUBhuiIiIyKAw3BAREZFBYbghIiIig8JwQ6QnZs6cCS8vr2Ydu2TJEshkMu0WRNSI6t+7nJwcqUshqoHhhqgRMpmsSVtUVJTUpUpi5syZsLa2lrqMJhFC4Ntvv8WwYcNgZ2cHS0tL9OjRA8uWLUNxcbHU5dVSHR7q2zIzM6UukUgvmUhdAJG++/bbb2s8/uabbxAZGVlrf9euXe/rfT7//HOo1epmHfvmm2/itddeu6/3N3QqlQr//Oc/sXXrVgwdOhRLliyBpaUlfvvtNyxduhTbtm3DgQMH4OzsLHWptaxdu7bOAGlnZ6f7YohaAYYbokY8+eSTNR6fOHECkZGRtfb/XUlJCSwtLZv8Pqamps2qDwBMTExgYsL/nRuyatUqbN26FS+//DJWr16t2T979mxMmTIFISEhmDlzJvbt26fTuprye/L444/D0dFRRxURtX4cliLSguHDhyMgIACxsbEYNmwYLC0t8frrrwMAdu7ciUceeQRubm6Qy+Xw9vbG22+/DZVKVeM1/j7nJjk5GTKZDO+99x4+++wzeHt7Qy6Xo1+/fjh9+nSNY+uacyOTyTBv3jzs2LEDAQEBkMvl6N69O3755Zda9UdFRaFv374wNzeHt7c31q9fr/V5PNu2bUOfPn1gYWEBR0dHPPnkk0hLS6vRJjMzE08//TQ8PDwgl8vh6uqKiRMnIjk5WdMmJiYGY8aMgaOjIywsLNCpUyc888wzDb53aWkpVq9ejS5duiA8PLzW8xMmTMCMGTPwyy+/4MSJEwCA8ePHo3PnznW+XlBQEPr27Vtj33fffaf5fA4ODnjiiSdw8+bNGm0a+j25H1FRUZDJZNiyZQtef/11uLi4wMrKCo8++mitGoCm/SwA4PLly5gyZQrat28PCwsL+Pn54Y033qjVLi8vDzNnzoSdnR1sbW3x9NNPo6SkpEabyMhIDBkyBHZ2drC2toafn59WPjtRXfhPPSItuXPnDsaNG4cnnngCTz75pGZ4Y+PGjbC2tsZ//vMfWFtb49ChQ3jrrbdQUFBQowehPps2bUJhYSGee+45yGQyrFq1CpMmTcL169cb7e05evQofvrpJ8ydOxc2Njb46KOPMHnyZKSmpqJdu3YAgLNnz2Ls2LFwdXXF0qVLoVKpsGzZMrRv3/7+T8ofNm7ciKeffhr9+vVDeHg4bt++jTVr1uDYsWM4e/asZnhl8uTJSEhIwAsvvAAvLy9kZWUhMjISqampmsejR49G+/bt8dprr8HOzg7Jycn46aefGj0Pd+/exfz58+vt4QoNDcWGDRuwe/duDBw4EFOnTkVoaChOnz6Nfv36adqlpKTgxIkTNX52y5cvx6JFizBlyhQ8++yzyM7Oxscff4xhw4bV+HxA/b8nDcnNza21z8TEpNaw1PLlyyGTyfDqq68iKysLH374IYKDg3Hu3DlYWFgAaPrP4sKFCxg6dChMTU0xe/ZseHl54dq1a/j555+xfPnyGu87ZcoUdOrUCeHh4Thz5gy++OILODk5YeXKlQCAhIQEjB8/HoGBgVi2bBnkcjmSkpJw7NixRj87UbMIIronYWFh4u//6zz44IMCgFi3bl2t9iUlJbX2Pffcc8LS0lKUlZVp9s2YMUN07NhR8/jGjRsCgGjXrp3Izc3V7N+5c6cAIH7++WfNvsWLF9eqCYAwMzMTSUlJmn3nz58XAMTHH3+s2TdhwgRhaWkp0tLSNPuuXr0qTExMar1mXWbMmCGsrKzqfb68vFw4OTmJgIAAUVpaqtm/e/duAUC89dZbQggh7t69KwCI1atX1/taERERAoA4ffp0o3X91YcffigAiIiIiHrb5ObmCgBi0qRJQggh8vPzhVwuFy+99FKNdqtWrRIymUykpKQIIYRITk4WxsbGYvny5TXaxcXFCRMTkxr7G/o9qUv1z7Wuzc/PT9Pu8OHDAoBwd3cXBQUFmv1bt24VAMSaNWuEEE3/WQghxLBhw4SNjY3mc1ZTq9W16nvmmWdqtHnsscdEu3btNI//+9//CgAiOzu7SZ+b6H5xWIpIS+RyOZ5++ula+6v/xQwAhYWFyMnJwdChQ1FSUoLLly83+rpTp06Fvb295vHQoUMBANevX2/02ODgYHh7e2seBwYGQqFQaI5VqVQ4cOAAQkJC4Obmpmnn4+ODcePGNfr6TRETE4OsrCzMnTsX5ubmmv2PPPII/P39sWfPHgBV58nMzAxRUVG4e/duna9V3auwe/duVFRUNLmGwsJCAICNjU29baqfKygoAAAoFAqMGzcOW7duhRBC027Lli0YOHAgOnToAAD46aefoFarMWXKFOTk5Gg2FxcX+Pr64vDhwzXep77fk4b8+OOPiIyMrLFt2LChVrvQ0NAan/Hxxx+Hq6sr9u7dC6DpP4vs7GwcOXIEzzzzjOZzVqtrqPL555+v8Xjo0KG4c+eO5lxW/9x27tzZ7EnzRPeC4YZIS9zd3WFmZlZrf0JCAh577DHY2tpCoVCgffv2msnI+fn5jb7u379cqoNOfQGgoWOrj68+NisrC6WlpfDx8anVrq59zZGSkgIA8PPzq/Wcv7+/5nm5XI6VK1di3759cHZ2xrBhw7Bq1aoalzs/+OCDmDx5MpYuXQpHR0dMnDgRGzZsgFKpbLCG6i/86pBTl7oC0NSpU3Hz5k0cP34cAHDt2jXExsZi6tSpmjZXr16FEAK+vr5o3759je3SpUvIysqq8T71/Z40ZNiwYQgODq6xBQUF1Wrn6+tb47FMJoOPj49mzlJTfxbV4TcgIKBJ9TX2Ozp16lQMHjwYzz77LJydnfHEE09g69atDDrUYhhuiLTkrz001fLy8vDggw/i/PnzWLZsGX7++WdERkZq5iI05S93Y2PjOvf/tTehJY6VwoIFC3DlyhWEh4fD3NwcixYtQteuXXH27FkAVV/W27dvx/HjxzFv3jykpaXhmWeeQZ8+fVBUVFTv61Zfpn/hwoV621Q/161bN82+CRMmwNLSElu3bgUAbN26FUZGRvjHP/6haaNWqyGTyfDLL7/U6l2JjIzE+vXra7xPXb8nrV1jv2cWFhY4cuQIDhw4gKeeegoXLlzA1KlTMWrUqFoT64m0geGGqAVFRUXhzp072LhxI+bPn4/x48cjODi4xjCTlJycnGBubo6kpKRaz9W1rzk6duwIAEhMTKz1XGJioub5at7e3njppZfw66+/Ij4+HuXl5Xj//fdrtBk4cCCWL1+OmJgYfP/990hISMDmzZvrraH6Kp1NmzbV+2X6zTffAKi6SqqalZUVxo8fj23btkGtVmPLli0YOnRojSE8b29vCCHQqVOnWr0rwcHBGDhwYCNnSHuuXr1a47EQAklJSZqr8Jr6s6i+Siw+Pl5rtRkZGWHkyJH44IMPcPHiRSxfvhyHDh2qNWxHpA0MN0QtqPpftH/tKSkvL8enn34qVUk1GBsbIzg4GDt27EB6erpmf1JSktbWe+nbty+cnJywbt26GsNH+/btw6VLl/DII48AqFrvpaysrMax3t7esLGx0Rx39+7dWr1OvXr1AoAGh6YsLS3x8ssvIzExsc5Lmffs2YONGzdizJgxtcLI1KlTkZ6eji+++ALnz5+vMSQFAJMmTYKxsTGWLl1aqzYhBO7cuVNvXdr2zTff1Bh62759OzIyMjTzp5r6s2jfvj2GDRuGr776CqmpqTXeozm9fnVd7dWUnxtRc/FScKIWNGjQINjb22PGjBn497//DZlMhm+//VavhoWWLFmCX3/9FYMHD8acOXOgUqnwySefICAgAOfOnWvSa1RUVOCdd96ptd/BwQFz587FypUr8fTTT+PBBx/EtGnTNJcfe3l54cUXXwQAXLlyBSNHjsSUKVPQrVs3mJiYICIiArdv38YTTzwBAPj666/x6aef4rHHHoO3tzcKCwvx+eefQ6FQ4OGHH26wxtdeew1nz57FypUrcfz4cUyePBkWFhY4evQovvvuO3Tt2hVff/11reMefvhh2NjY4OWXX4axsTEmT55c43lvb2+88847WLhwIZKTkxESEgIbGxvcuHEDERERmD17Nl5++eUmncf6bN++vc4VikeNGlXjUnIHBwcMGTIETz/9NG7fvo0PP/wQPj4++Ne//gWgaqHIpvwsAOCjjz7CkCFD8MADD2D27Nno1KkTkpOTsWfPnib/XlRbtmwZjhw5gkceeQQdO3ZEVlYWPv30U3h4eGDIkCHNOylEDZHkGi2iVqy+S8G7d+9eZ/tjx46JgQMHCgsLC+Hm5iZeeeUVsX//fgFAHD58WNOuvkvB67o0GoBYvHix5nF9l4KHhYXVOrZjx45ixowZNfYdPHhQ9O7dW5iZmQlvb2/xxRdfiJdeekmYm5vXcxb+NGPGjHovV/b29ta027Jli+jdu7eQy+XCwcFBTJ8+Xdy6dUvzfE5OjggLCxP+/v7CyspK2NraigEDBoitW7dq2pw5c0ZMmzZNdOjQQcjlcuHk5CTGjx8vYmJiGq1TCCFUKpXYsGGDGDx4sFAoFMLc3Fx0795dLF26VBQVFdV73PTp0wUAERwcXG+bH3/8UQwZMkRYWVkJKysr4e/vL8LCwkRiYqKmTUO/J3Vp6FLwv/7+VF8K/sMPP4iFCxcKJycnYWFhIR555JFal3IL0fjPolp8fLx47LHHhJ2dnTA3Nxd+fn5i0aJFter7+yXeGzZsEADEjRs3hBBVv18TJ04Ubm5uwszMTLi5uYlp06aJK1euNPlcEN0LmRB69E9IItIbISEhSEhIqDWPg/RPVFQUHnroIWzbtg2PP/641OUQSY5zbogIpaWlNR5fvXoVe/fuxfDhw6UpiIjoPnDODRGhc+fOmDlzJjp37oyUlBSsXbsWZmZmeOWVV6QujYjonjHcEBHGjh2LH374AZmZmZDL5QgKCsK7775ba1E4IqLWgHNuiIiIyKBwzg0REREZFIYbIiIiMihtbs6NWq1Geno6bGxs6ry7LREREekfIQQKCwvh5uYGI6OG+2baXLhJT0+Hp6en1GUQERFRM9y8eRMeHh4Ntmlz4cbGxgZA1clRKBQSV0NERERNUVBQAE9PT833eEPaXLipHopSKBQMN0RERK1MU6aUcEIxERERGRSGGyIiIjIoDDdERERkUBhuiIiIyKAw3BAREZFBYbghIiIig8JwQ0RERAaF4YaIiIgMCsMNERERGRSGGyIiIjIoDDdERERkUBhuiIiIyKAw3GiJWi2QVViGGznFUpdCRETUpjHcaMnRpBz0X34Qc76LlboUIiKiNo3hRkvc7MwBAOl5pRJXQkRE1LYx3GiJq60FAKCgrBJFykqJqyEiImq7GG60xEpuAoW5CQAgg703REREkmG40SI3u6rem/T8MokrISIiarsYbrSoOtyw54aIiEg6DDda5GrLScVERERSY7jRIg5LERERSY/hRouqe24y8tlzQ0REJBWGGy36c84Ne26IiIikwnCjRW5/rHWTllcKIYTE1RAREbVNkoabtWvXIjAwEAqFAgqFAkFBQdi3b1+Dx+Tl5SEsLAyurq6Qy+Xo0qUL9u7dq6OKG+ZsKwcAKCvVuFtSIXE1REREbZOJlG/u4eGBFStWwNfXF0IIfP3115g4cSLOnj2L7t2712pfXl6OUaNGwcnJCdu3b4e7uztSUlJgZ2en++LrIDcxhqO1HDlFSqTnlcLBykzqkoiIiNocScPNhAkTajxevnw51q5dixMnTtQZbr766ivk5ubi999/h6mpKQDAy8tLF6U2mbudOXKKlMjIL0OAu63U5RAREbU5ejPnRqVSYfPmzSguLkZQUFCdbXbt2oWgoCCEhYXB2dkZAQEBePfdd6FSqep9XaVSiYKCghpbS6q+xxTXuiEiIpKGpD03ABAXF4egoCCUlZXB2toaERER6NatW51tr1+/jkOHDmH69OnYu3cvkpKSMHfuXFRUVGDx4sV1HhMeHo6lS5e25EeowbX67uC8HJyIiEgSMiHxZT3l5eVITU1Ffn4+tm/fji+++ALR0dF1BpwuXbqgrKwMN27cgLGxMQDggw8+wOrVq5GRkVHn6yuVSiiVSs3jgoICeHp6Ij8/HwqFQuuf5/Mj17F87yU82tMNH03rrfXXJyIiaosKCgpga2vbpO9vyXtuzMzM4OPjAwDo06cPTp8+jTVr1mD9+vW12rq6usLU1FQTbACga9euyMzMRHl5OczMak/glcvlkMvlLfcB/kaz1g17boiIiCShN3NuqqnV6ho9LX81ePBgJCUlQa1Wa/ZduXIFrq6udQYbKWiGpbiQHxERkSQkDTcLFy7EkSNHkJycjLi4OCxcuBBRUVGYPn06ACA0NBQLFy7UtJ8zZw5yc3Mxf/58XLlyBXv27MG7776LsLAwqT5CLdUL+WUWlEGl5kJ+REREuibpsFRWVhZCQ0ORkZEBW1tbBAYGYv/+/Rg1ahQAIDU1FUZGf+YvT09P7N+/Hy+++CICAwPh7u6O+fPn49VXX5XqI9TS3kYOEyMZKtUC2YVKuPxxvykiIiLSDcknFOvavUxIaq7BKw4hLa8UP80dhAc62LfIexAREbUl9/L9rXdzbgyB2x/zbngDTSIiIt1juGkBXMiPiIhIOgw3LYAL+REREUmH4aYFVF8xxWEpIiIi3WO4aQFcyI+IiEg6DDctwPWPy7/T2HNDRESkcww3LaC65yanSAllZf13LCciIiLtY7hpAfaWppCbVJ3a2/l130qCiIiIWgbDTQuQyWRw/6P3hldMERER6RbDTQv58waaDDdERES6xHDTQqoX8svI56RiIiIiXWK4aSFutuy5ISIikgLDTQv5c60b9twQERHpEsNNC3G14/2liIiIpMBw00I4LEVERCQNhpsWUt1zU1BWiWJlpcTVEBERtR0MNy3EWm4ChbkJAN5jioiISJcYblqQm2beDScVExER6QrDTQty5bwbIiIinWO4aUGaK6Z4OTgREZHOMNy0oOorpjLYc0NERKQzDDctiAv5ERER6R7DTQuqvr8U59wQERHpDsNNC3KrvjN4fimEEBJXQ0RE1DYw3LQglz/m3JRVqJFXUiFxNURERG0Dw00LkpsYw9FaDqCq94aIiIhaHsNNC9MMTXEhPyIiIp1guGlh1Qv58RYMREREusFw08L+vGKKPTdERES6wHDTwtw1a92w54aIiEgXGG5amKsd7y9FRESkS5KGm7Vr1yIwMBAKhQIKhQJBQUHYt29fk47dvHkzZDIZQkJCWrbI+8RhKSIiIt2SNNx4eHhgxYoViI2NRUxMDEaMGIGJEyciISGhweOSk5Px8ssvY+jQoTqqtPmqr5a6XVAGlZoL+REREbU0ScPNhAkT8PDDD8PX1xddunTB8uXLYW1tjRMnTtR7jEqlwvTp07F06VJ07txZh9U2j5ONOYyNZKhUC+QUKaUuh4iIyODpzZwblUqFzZs3o7i4GEFBQfW2W7ZsGZycnDBr1qwmva5SqURBQUGNTZeMjWRwUXDeDRERka6YSF1AXFwcgoKCUFZWBmtra0RERKBbt251tj169Ci+/PJLnDt3rsmvHx4ejqVLl2qp2uZxtTVHWl4p0vPK0LuDpKUQEREZPMl7bvz8/HDu3DmcPHkSc+bMwYwZM3Dx4sVa7QoLC/HUU0/h888/h6OjY5Nff+HChcjPz9dsN2/e1Gb5TeLKy8GJiIh0RvKeGzMzM/j4+AAA+vTpg9OnT2PNmjVYv359jXbXrl1DcnIyJkyYoNmnVqsBACYmJkhMTIS3t3et15fL5ZDL5S34CRrnZstbMBAREemK5OHm79RqNZTK2hNv/f39ERcXV2Pfm2++icLCQqxZswaenp66KvGeubHnhoiISGckDTcLFy7EuHHj0KFDBxQWFmLTpk2IiorC/v37AQChoaFwd3dHeHg4zM3NERAQUON4Ozs7AKi1X9+42nJCMRERka5IGm6ysrIQGhqKjIwM2NraIjAwEPv378eoUaMAAKmpqTAyknxa0H2r7rlJz+ewFBERUUuTCSHa1MpyBQUFsLW1RX5+PhQKhU7e806REn3eOQCZDEh8exzMTFp/YCMiItKle/n+5resDjhYmUFuYgQhqlYqJiIiopbDcKMDMplMMzSVxnk3RERELYrhRkeqJxXziikiIqKWxXCjI7w7OBERkW4w3OiIux17boiIiHSB4UZHqm/BwJ4bIiKilsVwoyNcyI+IiEg3GG505M9bMLDnhoiIqCUx3OhIdc9NfmkFSsorJa6GiIjIcDHc6IiNuSlszKvudsF5N0RERC2H4UaH3DSXg3PeDRERUUthuNEhV14OTkRE1OIYbnSIC/kRERG1PIYbHeJCfkRERC2P4UaH2HNDRETU8hhudKh6zk06e26IiIhaDMONDlVfLZWRVwYhhMTVEBERGSaGGx1ysTWHkQworVDh1l323hAREbUEhhsdMjc1xoBO7QAA++IzJK6GiIjIMDHc6Ngjga4AgD0XGG6IiIhaAsONjo0NcIGRDDh/Kx83c0ukLoeIiMjgMNzomKO1nENTRERELYjhRgIcmiIiImo5DDcS4NAUERFRy2G4kcBfh6b2xrH3hoiISJsYbiRSPTTFcENERKRdDDcS4dAUERFRy2C4kYijtRwDO3NoioiISNsYbiT0cA8OTREREWkbw42EODRFRESkfZKGm7Vr1yIwMBAKhQIKhQJBQUHYt29fve0///xzDB06FPb29rC3t0dwcDBOnTqlw4q1i0NTRERE2idpuPHw8MCKFSsQGxuLmJgYjBgxAhMnTkRCQkKd7aOiojBt2jQcPnwYx48fh6enJ0aPHo20tDQdV649HJoiIiLSLpkQQkhdxF85ODhg9erVmDVrVqNtVSoV7O3t8cknnyA0NLRJr19QUABbW1vk5+dDoVDcb7n3LadIif7LD0AtgN9eeQieDpZSl0RERKR37uX7W2/m3KhUKmzevBnFxcUICgpq0jElJSWoqKiAg4NDvW2USiUKCgpqbPqEQ1NERETaJXm4iYuLg7W1NeRyOZ5//nlERESgW7duTTr21VdfhZubG4KDg+ttEx4eDltbW83m6emprdK1pnpoag/DDRER0X2TPNz4+fnh3LlzOHnyJObMmYMZM2bg4sWLjR63YsUKbN68GRERETA3N6+33cKFC5Gfn6/Zbt68qc3ytaL6qqkLvGqKiIjovkkebszMzODj44M+ffogPDwcPXv2xJo1axo85r333sOKFSvw66+/IjAwsMG2crlcczVW9aZv/jo0xd4bIiKi+yN5uPk7tVoNpVJZ7/OrVq3C22+/jV9++QV9+/bVYWUti1dNERERaYek4WbhwoU4cuQIkpOTERcXh4ULFyIqKgrTp08HAISGhmLhwoWa9itXrsSiRYvw1VdfwcvLC5mZmcjMzERRUZFUH0FrODRFRESkHZKGm6ysLISGhsLPzw8jR47E6dOnsX//fowaNQoAkJqaioyMP3sy1q5di/Lycjz++ONwdXXVbO+9955UH0FrODRFRESkHXq3zk1L07d1bv7quxMpeHNHPAI9bLFr3hCpyyEiItIbrXKdG6o5NJV6h0NTREREzcFwo0dqLOgXz6EpIiKi5mC40TO8aoqIiOj+MNzoGQ5NERER3R+GGz3jaC1HkHfV0NSu8633budERERSYbjRQyG93AEAEWfT0MYuZiMiIrpvDDd6aGyAC+QmRriWXYy4tHypyyEiImpVGG70kI25KUZ3dwFQ1XtDRERETcdwo6ce6+0GAPj5fDoqVWqJqyEiImo9GG701FDf9nCwMkNOUTmOJuVIXQ4REVGrwXCjp0yNjTAhsGrNmx0cmiIiImoyhhs99tgDHgCA/Qm3UayslLgaIiKi1oHhRo/19LBFJ0crlFaosD8hU+pyiIiIWgWGGz0mk8lqrHlDREREjWO40XMhf1w1dSwpB1kFZRJXQ0REpP8YbvRcx3ZW6NPRHmoB7DqfLnU5REREeo/hphUI6c2hKSIioqZiuGkFxvdwhYmRDAnpBbhyu1DqcoiIiPQaw00rYG9lhuF+TgC45g0REVFjGG5aiUkPVA1N7TyXDrWadwonIiKqD8NNKzHC3wk2chOk5ZXiVHKu1OUQERHpLYabVsLc1BgP9+DtGIiIiBrDcNOKVF81tScuA2UVKomrISIi0k8MN63IgE4OcLM1R2FZJQ5fzpK6HCIiIr3EcNOKGBnJMPGP3pufODRFRERUJ4abVuaxP8JNVGIW7haXS1wNERGR/mG4aWW6ONugm6sCFSqBPXEZUpdDRESkdxhuWqHqNW941RQREVFtDDet0ISebjCSATEpd5F6p0TqcoiIiPQKw00r5Kwwx2AfRwDArvPsvSEiIvorhptWanxg1YJ+++IzJa6EiIhIv0gabtauXYvAwEAoFAooFAoEBQVh3759DR6zbds2+Pv7w9zcHD169MDevXt1VK1+GdXNBcZ/3CmcQ1NERER/kjTceHh4YMWKFYiNjUVMTAxGjBiBiRMnIiEhoc72v//+O6ZNm4ZZs2bh7NmzCAkJQUhICOLj43VcufQcrMwwsLMDAGBfPK+aIiIiqiYTQujVLaYdHBywevVqzJo1q9ZzU6dORXFxMXbv3q3ZN3DgQPTq1Qvr1q1r0usXFBTA1tYW+fn5UCgUWqtbCt+dSMGbO+LR09MOO8MGS10OERFRi7mX72+9mXOjUqmwefNmFBcXIygoqM42x48fR3BwcI19Y8aMwfHjx+t9XaVSiYKCghqboRjd3RkyGXD+Zh7S8kqlLoeIiEgvSB5u4uLiYG1tDblcjueffx4RERHo1q1bnW0zMzPh7OxcY5+zszMyM+ufVBseHg5bW1vN5unpqdX6peRkY45+HauGpn7hxGIiIiIAehBu/Pz8cO7cOZw8eRJz5szBjBkzcPHiRa29/sKFC5Gfn6/Zbt68qbXX1gfjergAAH7hvBsiIiIAehBuzMzM4OPjgz59+iA8PBw9e/bEmjVr6mzr4uKC27dv19h3+/ZtuLi41Pv6crlcczVW9WZIxgZUffaYlLvIKiiTuBoiIiLpSR5u/k6tVkOpVNb5XFBQEA4ePFhjX2RkZL1zdNoCV1sL9O5gByGA/QkcmiIiIpI03CxcuBBHjhxBcnIy4uLisHDhQkRFRWH69OkAgNDQUCxcuFDTfv78+fjll1/w/vvv4/Lly1iyZAliYmIwb948qT6CXhj3R+8NF/QjIiKSONxkZWUhNDQUfn5+GDlyJE6fPo39+/dj1KhRAIDU1FRkZPw5l2TQoEHYtGkTPvvsM/Ts2RPbt2/Hjh07EBAQINVH0AvjAqpWKz5x/Q7uFNXd60VERNRW6N06Ny3NkNa5+avxH/+G+LQCrJjUA0/07yB1OURERFrVKte5oftT3XvDoSkiImrrGG4MRPVVU8eScpBfUiFxNURERNJhuDEQ3u2t4edsg0q1wIFLtxs/gIiIyEAx3BiQsZqrprigHxERtV0MNwbk4R5V826OXM1BYRmHpoiIqG1iuDEgXZyt0dnRCuWVahy6nCV1OURERJJguDEgMplMMzTFG2kSEVFbxXBjYKqHpqISs1FSXilxNURERLrHcGNgursp4GFvgdIKFaITs6Uuh4iISOcYbgyMTCbT9N5wQT8iImqLmhVubt68iVu3bmkenzp1CgsWLMBnn32mtcKo+arn3Ry8dBtlFSqJqyEiItKtZoWbf/7znzh8+DAAIDMzE6NGjcKpU6fwxhtvYNmyZVotkO5dLw87uCjMUVyuwtGrOVKXQ0REpFPNCjfx8fHo378/AGDr1q0ICAjA77//ju+//x4bN27UZn3UDEZGsr8s6MehKSIialuaFW4qKiogl8sBAAcOHMCjjz4KAPD390dGBlfH1Qfj/gg3kRczUV6plrgaIiIi3WlWuOnevTvWrVuH3377DZGRkRg7diwAID09He3atdNqgdQ8fb0c4GgtR0FZJY5fvyN1OURERDrTrHCzcuVKrF+/HsOHD8e0adPQs2dPAMCuXbs0w1UkLWMjGcZ0dwYAvP5THL7+PZnr3hARUZsgE0KI5hyoUqlQUFAAe3t7zb7k5GRYWlrCyclJawVqW0FBAWxtbZGfnw+FQiF1OS3qWnYRpq4/jpyicgCAnaUpnhrYEaFBXmhvI5e4OiIioqa7l+/vZoWb0tJSCCFgaWkJAEhJSUFERAS6du2KMWPGNK9qHWlL4QYASsor8WPsLXxx9AZS7pQAAMxMjDD5AXfMGtIZPk7WEldIRETUuBYPN6NHj8akSZPw/PPPIy8vD/7+/jA1NUVOTg4++OADzJkzp9nFt7S2Fm6qqdQCvyZkYv2R6zh3M0+zP7irM2YP64x+XvaQyWTSFUhERNSAe/n+btacmzNnzmDo0KEAgO3bt8PZ2RkpKSn45ptv8NFHHzXnJamFGRvJMK6HKyLmDsK254MwqpszZDLgwKXbmLL+OF7ZfkHqEomIiLSiWeGmpKQENjY2AIBff/0VkyZNgpGREQYOHIiUlBStFkjaJZPJ0M/LAZ+H9sWB/zyIaf07wNhIhm2xt3Am9a7U5REREd23ZoUbHx8f7NixAzdv3sT+/fsxevRoAEBWVlabGupp7bzbWyN8Ug9MfsAdALDmwFWJKyIiIrp/zQo3b731Fl5++WV4eXmhf//+CAoKAlDVi9O7d2+tFkgtb95DvjA2kiH6SjZ7b4iIqNVrVrh5/PHHkZqaipiYGOzfv1+zf+TIkfjvf/+rteJINzq0s2TvDRERGYxmhRsAcHFxQe/evZGenq65Q3j//v3h7++vteJId9h7Q0REhqJZ4UatVmPZsmWwtbVFx44d0bFjR9jZ2eHtt9+GWs37GLVG7L0hIiJDYdKcg9544w18+eWXWLFiBQYPHgwAOHr0KJYsWYKysjIsX75cq0WSbsx7yBc/nknT9N480MG+8YOIiIj0TLMW8XNzc8O6des0dwOvtnPnTsydOxdpaWlaK1Db2uoifk31yvbz2BpzCw92aY+vn+F9woiISD+0+CJ+ubm5dc6t8ff3R25ubnNekvQE594QEVFr16xw07NnT3zyySe19n/yyScIDAy876JIOh3aWWJSb869ISKi1qtZ4WbVqlX46quv0K1bN8yaNQuzZs1Ct27dsHHjRrz33ntNfp3w8HD069cPNjY2cHJyQkhICBITExs97sMPP4Sfnx8sLCzg6emJF198EWVlZc35KFSHeSN82HtDREStVrPCzYMPPogrV67gscceQ15eHvLy8jBp0iQkJCTg22+/bfLrREdHIywsDCdOnEBkZCQqKiowevRoFBcX13vMpk2b8Nprr2Hx4sW4dOkSvvzyS2zZsgWvv/56cz4K1aFjOyv23hARUavVrAnF9Tl//jweeOABqFSqZh2fnZ0NJycnREdHY9iwYXW2mTdvHi5duoSDBw9q9r300ks4efIkjh492uh7cEJx06TcKcaI96OhUgv8NHcQr5wiIiJJtfiE4paSn58PAHBwcKi3zaBBgxAbG4tTp04BAK5fv469e/fi4YcfrrO9UqlEQUFBjY0ax94bIiJqrfQm3KjVaixYsACDBw9GQEBAve3++c9/YtmyZRgyZAhMTU3h7e2N4cOH1zssFR4eDltbW83m6enZUh/B4HDuDRERtUZ6E27CwsIQHx+PzZs3N9guKioK7777Lj799FOcOXMGP/30E/bs2YO33367zvYLFy5Efn6+Zrt582ZLlG+Q2HtDRESt0T2tUDxp0qQGn8/Ly2tWEfPmzcPu3btx5MgReHh4NNh20aJFeOqpp/Dss88CAHr06IHi4mLMnj0bb7zxBoyMauY1uVwOuVzerLqoqvfmp7NctZiIiFqPe+q5+evwTl1bx44dERoa2uTXE0Jg3rx5iIiIwKFDh9CpU6dGjykpKakVYIyNjTWvR9rF3hsiImpt7qnnZsOGDVp987CwMGzatAk7d+6EjY0NMjMzAVSFKAsLCwBAaGgo3N3dER4eDgCYMGECPvjgA/Tu3RsDBgxAUlISFi1ahAkTJmhCDmnXX3tvoq9k48Eu7aUuiYiIqF7NunGmtqxduxYAMHz48Br7N2zYgJkzZwIAUlNTa/TUvPnmm5DJZHjzzTeRlpaG9u3bY8KECbxZZwvq2M4KM4K88NWxG3hrZzz2LxgGc1MGSSIi0k9aXeemNeA6N81TpKxE8PvRyCwow79H+OA/o/2kLomIiNqQVrvODekva7kJFk/oBgBYG30NSVlFEldERERUN4YbarKxAS54yK89KlQCi3bEcwI3ERHpJYYbajKZTIZlEwMgNzHC8et3sONcmtQlERER1cJwQ/fE08ES/x7pCwB4Z/cl5JdUSFwRERFRTQw3dM/+NbQzfJyscae4HCv3X5a6HCIiohoYbuiemZkYYXlI1f2/Np1MRWwK7ztFRET6g+GGmmVA53b4R5+qW2W8ERGHSpVa4oqIiIiqMNxQsy18uCvsLE1xObMQG39PlrocIiIiAAw3dB8crMzw+riuAIAPIq8gPa9U4oqIiIgYbug+Pd7HA/287FFSrsLSnxOkLoeIiIjhhu6PkZEM74T0gImRDPsTbuPAxdtSl0RERG0cww3dNz8XGzw7tDMA4M0d8fjk0FXsi8vAlduFUFaqJK6OiIjaGknvCk6G498jfbD7Qjpu3S3Fe79e0ew3klUt/NfZ0Qre7a3h7WSNbq4K9PS0k65YIiIyaLwrOGlNVkEZtsXewrXsIlzLLsb1rCIUKivrbDt3uDdeGeuv4wqJiKi1upfvb/bckNY4KcwR9pCP5rEQAtlFSlzLKsb1nCJcyyrG1axC/HY1B59GXUNXVwUm9HSTsGIiIjJEDDfUYmQyGZxszOFkY44g73aa/eH7LmF99HX83/bz8G5vjW5u7EEjIiLt4YRi0rlXxvhjqK8jyirUmP1tDO4Wl0tdEhERGRCGG9I5YyMZPp7WGx0cLHHrbinm/XCGt28gIiKtYbghSdhZmuGz0D6wNDPGsaQ7WLGPdxcnIiLtYLghyfi7KPD+P3oCAL44egM7zqZJXBERERkChhuS1Lgerpj3xxVWr/54AfFp+RJXRERErR3DDUnuxVFdMMLfCcpKNZ77NhZ3ipRSl0RERK0Yww1JzthIhv9O7YVOjlZIyytF2KYzqOAEYyIiaiaGG9ILtham+Dy0D6zlJjhxPRfL91ySuiQiImqlGG5Ib/g42eCDKVUTjDf+noyVv1xGfkmFxFUREVFrw3BDemV0dxcsCPYFAKyNuoZBKw4ifN8lZBWWSVwZERG1FrxxJukdIQT2xGXgk0NJuJxZCAAwMzHC1L6emD2sMzwdLCWukIiIdO1evr8ZbkhvCSFwODELnxxKwpnUPABVk48n9nLD3OHe8HGykbZAIiLSGYabBjDctD5CCJy8kYv/HU7Cb1dzAAAyGTCmmwteGt0Fvs4MOUREho7hpgEMN63bhVt5+N/hJOxPuA2g6iqr3S8M4VAVEZGBu5fvb04oplYl0MMO65/qi8gXhyHAXYH80gqEbToDZaVK6tKIiEhPSBpuwsPD0a9fP9jY2MDJyQkhISFITExs9Li8vDyEhYXB1dUVcrkcXbp0wd69e3VQMekLX2cbrHuyD+wsTXHhVj6W/XxR6pKIiEhPSBpuoqOjERYWhhMnTiAyMhIVFRUYPXo0iouL6z2mvLwco0aNQnJyMrZv347ExER8/vnncHd312HlpA887C3x4dRekMmA70+m4qczt6QuiYiI9IBezbnJzs6Gk5MToqOjMWzYsDrbrFu3DqtXr8bly5dhamp6z+/BOTeG54PIK/jo4FWYmxphR9hg+Lvw50pEZGha7Zyb/PyqO0I7ODjU22bXrl0ICgpCWFgYnJ2dERAQgHfffRcqVd1zLpRKJQoKCmpsZFjmj/TFUF9HlFWoMee7Mygs46rGRERtmd6EG7VajQULFmDw4MEICAiot93169exfft2qFQq7N27F4sWLcL777+Pd955p8724eHhsLW11Wyenp4t9RFIIsZGMqx5ojfcbM1xI6cYr2y/AD3qkCQiIh3Tm2GpOXPmYN++fTh69Cg8PDzqbdelSxeUlZXhxo0bMDY2BgB88MEHWL16NTIyMmq1VyqVUCqVmscFBQXw9PTksJQBOpt6F1PWH0eFSuDNR7ri2aGdpS6JiIi0pNUNS82bNw+7d+/G4cOHGww2AODq6oouXbpogg0AdO3aFZmZmSgvL6/VXi6XQ6FQ1NjIMPXuYI83H+kGAFix7zJiknMbbK+sVGFfXAZmbTyN8R//hovpHLIkIjIEkoYbIQTmzZuHiIgIHDp0CJ06dWr0mMGDByMpKQlqtVqz78qVK3B1dYWZmVlLlkutQGhQR0zo6YZKtUDYpjPILlTWeF4Igfi0fCzeGY8B7x7EnO/P4ODlLMSnFWDa5ydw7maeNIUTEZHWSBpuwsLC8N1332HTpk2wsbFBZmYmMjMzUVpaqmkTGhqKhQsXah7PmTMHubm5mD9/Pq5cuYI9e/bg3XffRVhYmBQfgfSMTCbDikk94ONkjdsFSvz7h7OoVKmRXajEF79dx7g1v2H8x0fx9fEU5JVUwFkhx5zh3niggx3ySyvw5BcncepGwz0+RESk3ySdcyOTyercv2HDBsycORMAMHz4cHh5eWHjxo2a548fP44XX3wR586dg7u7O2bNmoVXX321xlBVfXgpeNuQlFWIRz85hpJyFfxdbHA1qwgqddWvupmJEcZ0d8HjfTwwxMcRxkYyFCsr8ezXMTh+/Q7MTY3weWhfDPVtL/GnICKiary3VAMYbtqOn8+n44Ufzmoe9/K0w+N9PDAh0A22lrXXSCqrUGHOd7E4nJgNM2MjfDr9AQR3c9ZlyUREVA+GmwYw3LQtW0/fxK27JXi0lxt8nBq/e3h5pRr//uEsfknIhImRDP+d2gsTerrpoFIiImoIw00DGG6oMZUqNf5v+wVEnE2DkQxYOTkQ/+jL9ZGIiKTU6i4FJ9InJsZGeP8fPTGtvyfUAvi/7Rfw7fFkqcsiIqImYrghqoORkQzvPtYDTw/2AgAs2pmA9dHXpC2KiIiahOGGqB4ymQxvje+GsIe8AQDh+y7jf4eTJK6KiIgaw3BD1ACZTIb/G+OPl0d3AQCs3p+IL4/ekLgqIiJqCMMNURPMG+GLBcG+AIC3d1/EdydSJK6IiIjqw3BD1ETzR/riuQerbsb55o54bI+9JXFFRERUF4YboiaSyWR4baw/Zg7yAgC8sv08fj6fLm1RRERUC8MN0T2QyWRYPKGb5jLxBVvOYX9CptRlERHRXzDcEN0jmUyG5SE9MKm3O1RqgRc2nUVUYpbUZRER0R8YboiawchIhlWPB+KRHq4oV6nx3Lex+D0pR+qyiIgIDDdEzWZibIQPn+iF4K5OUFaq8ew3MYhJzpW6LCKiNo/hhug+mBob4ZN/PoChvo4oKVfh6Q2n8e3xZMSn5aNCpZa6PCKiNok3ziTSgtJyFWZuOIWTN/7suTEzMUI3VwV6etiih4cdenrYonN7axgbySSslIiodeJdwRvAcEMtpVhZiS9+u4HTybm4cCsPBWWVtdpYmRkjwN0Wo7o548mBHWFuaixBpURErQ/DTQMYbkgXhBBIvlOCC7fycOFWPi7cykN8WgFKK1SaNs4KOf490hdT+nrC1JgjxEREDWG4aQDDDUmlUqVGUnYRTl7PxWdHriMtrxQA0LGdJV4M7oIJPd04ZEVEVA+GmwYw3JA+UFaq8MPJVHxyOAk5ReUAAD9nG7w8xg/BXZ0gkzHkEBH9FcNNAxhuSJ8UKyux8fdkrI++ppmj08vTDq+M8cMgH0eJqyMi0h8MNw1guCF9lF9SgfVHrmHDsWTNvJzhfu2xZmpv2FqaSlwdEZH07uX7m7MYifSAraUpXhnrj+hXhmPmIC+YGssQlZiNf6z/HRn5pVKXR0TUqjDcEOkRJxtzLHm0O3bNGwJnhRxXbhdh8qe/4+rtQqlLIyJqNRhuiPRQV1cFfpwzCJ3bWyE9vwyPrzuO2BTe2oGIqCkYboj0lIe9JX58fhB6d7BDfmkF/vn5SURevC11WUREeo/hhkiP2VuZYdOzAzHSv+rmnM99G4PNp1KlLouISK8x3BDpOQszY6x/qg+m9PWAWgCv/RSHjw5eRRu70JGIqMkYbohaARNjI6ycHIh5D/kAAD6IvIJFO+OhUjPgEBH9HcMNUSshk8nw8hg/LH20O2Qy4LsTqQj7/gwKyiqkLo2ISK8w3BC1MjMGeeGTaQ/AzNgIvyRkIvj9aOyNy+AwFRHRHyQNN+Hh4ejXrx9sbGzg5OSEkJAQJCYmNvn4zZs3QyaTISQkpOWKJNJDjwS6YtO/BqCToxWyCpWY+/0ZzPo6BjdzS6QujYhIcpKGm+joaISFheHEiROIjIxERUUFRo8ejeLi4kaPTU5Oxssvv4yhQ4fqoFIi/dPXywH75g/Fv0f6wtRYhkOXszD6v0ewPvoaKlRqqcsjIpKMXt1bKjs7G05OToiOjsawYcPqbadSqTBs2DA888wz+O2335CXl4cdO3Y06T14bykyRElZRXg9Ig6nblQt9OfvYoN3J/XAAx3sJa6MiEg7Wu29pfLz8wEADg4ODbZbtmwZnJycMGvWrEZfU6lUoqCgoMZGZGh8nKyxZfZArHo8EHaWpricWYjJa3/Hoh3xnHBMRG2OidQFVFOr1ViwYAEGDx6MgICAetsdPXoUX375Jc6dO9ek1w0PD8fSpUu1VCWR/pLJZJjS1xMj/Z2wfO8l/HQmDd+eSMHeuAx4O1nD3NQYFqZGsDA1hoWZ8R+PjTWPOzhYoqurAh72FpDJZFJ/HCKiZtObYak5c+Zg3759OHr0KDw8POpsU1hYiMDAQHz66acYN24cAGDmzJkNDksplUoolUrN44KCAnh6enJYigze70k5eGNHPG7kND6H7a9szE3Q1UUBf1cbdHVVoKurAn7ONrAwM26hSomIGncvw1J6EW7mzZuHnTt34siRI+jUqVO97c6dO4fevXvD2PjPv2TV6qqJk0ZGRkhMTIS3t3eD78U5N9SWlFWocDo5F4VllSgtV6G0QoWyChVKy1Uoq1ShtFyN0goVCssqcC27GElZhahQ1f4rQSYDOrWzwqO93PDCCF8YG7Fnh4h0q9WEGyEEXnjhBURERCAqKgq+vr4Nti8rK0NSUlKNfW+++SYKCwuxZs0adOnSBWZmZg2+BsMNUf3KK9W4ll2ESxkFuJxZiEsZBbiUUYCconJNm+CuzljzRC9YyfVmVJuI2oB7+f6W9G+nsLAwbNq0CTt37oSNjQ0yMzMBALa2trCwsAAAhIaGwt3dHeHh4TA3N681H8fOzg4AGpynQ0RNY2ZipBmK+quswjIcvJSFxbsScODSbfxj3XF8ObMvXG0tJKqUiKh+kl4ttXbtWuTn52P48OFwdXXVbFu2bNG0SU1NRUZGhoRVEpGTjTmm9e+AH/41EO2szHAxowAh/zuG+LR8qUsjIqpFL+bc6BKHpYjuz83cEjyz8TSuZhXBwtQYa57ohdHdXaQui4gMXKtd54aI9J+ngyV+nDsIQ30dUVqhwnPfxeLzI9d5bysi0hsMN0R0zxTmpvhqZj9MH9ABQgDL917C6xFxvO0DEekFXu5ARM1iamyEd0IC0Lm9Nd7ZcxE/nLqJ1NwSfDq9D2wtTKFWC5Sr1FBWqlGhUqO88o9NpYaFqTE8HSyl/ghEZKA454aI7tuBi7fx781nUVKugqmxDEIAleqG/2oJcFdgUm8PPNrLDY7Wch1VSkStVatZ50YKDDdELSMhPR//+joG6flldT5vZmwEM5OqraC0QhN+TIxkGO7XHpMe8MDIrk6Qm3AlZCKqjeGmAQw3RC2nQqVGRl6ZJsSYGsuq/mxsVON+VbnF5dh9IR0/xt7C+Vt/Xk5ua2GK8YGumNzHA7097XiPKyLSYLhpAMMNkX5JyirEj2fSEHEmDZkFf/b6dGxnic6OVmhnLYejtRyO1mZoZ20GR2s52llVPba3MoOpMa+LIGoLGG4awHBDpJ9UaoHj1+7gpzO3sC8+E6UVqkaPkcmA3p52eLiHK8b1cIW7HVdMJjJUDDcNYLgh0n9FykqcvpGLrMIy5BSV405ROXKKlLhTrNT8Obe4HH+fs9zL0w4P93DBuABXXo1FZGAYbhrAcENkGFRqgYz8Uhy8lIU9cRk4nZyLv/5tFuhhi4d7uOLhAFd0aMegQ9TaMdw0gOGGyDBlFZZhf3wm9sZl4uSNOzV6dXq422JiLzdM6OkGZ4W5dEUSUbMx3DSA4YbI8GUXKvHrxUzsjcvA8Wt/Bh2ZDAjq3A4hvdwxtocLFOam0hZKRE3GcNMAhhuituVOkRJ74zKw41w6YlPuavabmRhhhJ8TJvZyw0P+TjA35fo6RPqM4aYBDDdEbdfN3BLsOp+OHWfTcDWrSLPfRm6CkV2d0K+TA/p0tEcXJxsYGXGNHSJ9wnDTAIYbIhJC4HJmIXacS8PP59JrrapsY26CBzrYo29He/TxskcvTztYmvFWfERSYrhpAMMNEf2VWi0Qk3IXR69mIyblLs7dzENJec01doyNZOjmqsAg73aYM9wbdpZmElVL1HYx3DSA4YaIGlKpUuNSRiFiU3IRk3IXsSl3kfGXnh1nhRzv/6MXhvg6SlglUdvDcNMAhhsiulfpeaU4nZyLNQev4np2MQDg6cFeeHWsPyciE+nIvXx/86YsRESNcLOzwMRe7tjzwlCEBnUEAGw4lowJHx9FfFp+I0cTka4x3BARNZGFmTGWTQzAxqf7ob2NHFezivDYp8fwaVQSVH+/F0Q9KlVq3MwtgbqJ7Yno3nFYioioGXKLy/H6T3H4JSETANDfywHvT+lZ655WucXlOJt6F2dSq+bvXLiVj5JyFbq7KfB5aF+48WafRE3COTcNYLghIm0RQmBb7C0s3ZWA4nIVrOUmeHWcP4xkQGzKXZxNzcONnOJ6j3e0lmP9U33Qp6O9Dqsmap0YbhrAcENE2pZ6pwT/2XoOMX9ZAfmvvNtb4YEO9ujT0R4PdLSHhakx/vVNDC5nFsLM2Ajhk3pgch8PHVdN1Low3DSA4YaIWoJKLbAu+hq2x96Cm505HuhQFWR6e9rVuS5OsbISL245h18v3gYAPPdgZ7wyxh/GXBmZqE4MNw1guCEifaFWC3wQeQWfHE4CAIzwd8KaJ3rBhjf0JKqFl4ITEbUCRkYyvDzGD2ue6AW5iREOXc7CpE9/R+qdEqlLI2rVGG6IiCQ2sZc7tj4XBKc/Li+f+L+jOH7tjtRlEbVaHJYiItITtwvKMPubGJy/lQ8TIxmm9POEk40cthamUJibVv3XwhQKCxPNPkszY8hknKdDho9zbhrAcENE+qysQoVXtl/ArvPpTWrvaC3H+EBXTOzlhl6edgw6ZLAYbhrAcENE+k4IgZ8vZOBiegEKyiqQX1qBguqtrFLzuPJvqxx7tbPEo73cEdLLDZ3bW0tUPVHLYLhpAMMNERkCIQSKy1U4fSMXO86l4deE2yitUGmeD/SwxcRe7pjQ0xVONuYSVkqkHa3maqnw8HD069cPNjY2cHJyQkhICBITExs85vPPP8fQoUNhb28Pe3t7BAcH49SpUzqqmIhIP8hkMljLTfCQvxPWPNEbMW8G48OpvTDcrz2MjWS4cCsfb+++iIHvHkToV6dw8jonKFPbIWnPzdixY/HEE0+gX79+qKysxOuvv474+HhcvHgRVlZWdR4zffp0DB48GIMGDYK5uTlWrlyJiIgIJCQkwN3dvdH3ZM8NERm6nCIl9lzIwI5zaTibmqfZP8THEf8Z3QUPdGj+7R4qVGpkFyqRVahEVkFZ1X8LlcguLEN2oRLZReXwdbLG/JG+te6zRXQ/Wu2wVHZ2NpycnBAdHY1hw4Y16RiVSgV7e3t88sknCA0NbbQ9ww0RtSUpd4rxxW83sPl0KipUVX/dj/B3wn9GdUGAu22jxysrVTh+7Q72J9xGVGIWMvLLmvS+psYyPDmwI14Y4QsHq9orNBPdq3v5/jbRUU1Nkp+fDwBwcHBo8jElJSWoqKio9xilUgmlUql5XFBQcH9FEhG1Ih3bWeHtkADMHtYZHx+6ih/PpOHQ5SwcupyFMd2d8eKoLvB3qflFUaysRFRiNvYnZOLw5SwUKitrPG9iJEN7GzmcbORob2MOJ0X1n6suW99y+iZ+u5qDDceSsT3mFp4f7o1nBneChZmxLj86tWF603OjVqvx6KOPIi8vD0ePHm3ycXPnzsX+/fuRkJAAc/Pak+aWLFmCpUuX1trPnhsiaotu5BRjzYEr2Hk+HUIAMhkwPtANzw7phMTMQuxPyMRvSTkor1RrjnGykWN0d2eM7uaC7m4K2FuawaiRe2D9djUb4Xsv42JGgeY1XhzVBf/o4wETY+1N9xRC8PL3NqJVDkvNmTMH+/btw9GjR+Hh0bS7465YsQKrVq1CVFQUAgMD62xTV8+Np6cnww0RtWlXbhfiwwNXsDcus87nvdpZYkx3F4zu7oLennaNhpm6qNUCu86nY/X+RKTllQIAfJys8coYP4zq5nxfoSS3uBwr9l3Cz+cz8Ob4rpg+oGOzX4tah1YXbubNm4edO3fiyJEj6NSpU5OOee+99/DOO+/gwIED6Nu3b5Pfi3NuiIj+lJCej/9GXsWhy7fh76LAmO4uGBvggi7O1lrrEVFWqvDt8RR8cjgJeSUVAIA+He0xf6Qvhvo63tP7CCGwPfYW3t17CXf/eC1TYxl+nDMIgR52WqmX9FOrCTdCCLzwwguIiIhAVFQUfH19m3TcqlWrsHz5cuzfvx8DBw68p/dkuCEiqk2tFs3qnbkX+aUVWBd9DV8dvQHlH8NePT3t8O8RPhjh79RoyEnKKsTrEfE4dSMXAODnbIP2NnIcTcpBBwdL7P73ECh4R3WD1WrCzdy5c7Fp0ybs3LkTfn5+mv22trawsLAAAISGhsLd3R3h4eEAgJUrV+Ktt97Cpk2bMHjwYM0x1tbWsLZufEVOhhsiImll5pdh/ZFr2HQyVRNyursp8MIIH4zu5lIrZJVVqPDJoSSsP3INFSoBc1MjLAjugllDOqGkXIWH1/yGtLxSjA90xcfTenMOjoFqNeGmvl/ADRs2YObMmQCA4cOHw8vLCxs3bgQAeHl5ISUlpdYxixcvxpIlSxp9T4YbIiL9kF2oxBe/Xce3J1JQUl61unIXZ2uEPeSD8YFuMDaS4ciVbCzaGY+UOyUAqi5jX/po9xpr6JxJvYsp646jUi0QPqkHpvXvIMnnoZbVasKNFBhuiIj0S25xOb46egNf/56suey8s6MVvJ2sEXnxNgDARWGOJY92w5juLnX+w3hd9DWs2HcZchMj7Jo3BH4uNjr9DNTyGG4awHBDRKSf8ksr8PXvyfjy6A3kl1ZNFjaSATMGeeGl0X6wlte/NJtaLTBz42kcuZINXydr7Jo3hOvqGBiGmwYw3BAR6bciZSW+O5GCuLR8zHnQu0krKQNVt514eM1vyCpUYmpfT6x8vO4lQqh1YrhpAMMNEZHh+j0pB9O/PAkhgDVP9MLEXo3fc7AxarXAiRt38GNsGsoqVZjevwOCvNtx4rKOtdrbLxAREd2PQT6OeOEhH3x0KAmv/xSHnh528HKs+0bMjUnLK8WPsbewLfYmbuaWavbvuZCBnh62mDPcu86ru0h67LkhIiKDUqlS45+fn8Sp5FwEuCvw45xBkJs0bf5NWYUKkRdvY2vMTRxNykH1N6SN3AQTernBxEiGLadvai5h79zeCs8/6I2QXu4wM9HebSWoNg5LNYDhhojI8GXkl+LhNb/hbkkFnh7shcUTutdqo6xUIa+kAndLypFTWI7Ii5nYcS5dM5kZAAZ5t8OUvp4Y091FM0E5p0iJjceS8c3xZBSUVV3d5aIwx7NDO2Fa/w6wamDiMzUfw00DGG6IiNqGg5duY9bXMQCAMd2dUVKuwt2SctwtrkBeSTmK/1hb5+/cbM3xeF9P/KOPR431dP6usKwCP5xKxRe/3UBWYdU9DO0sTTEjyAv/Gta5wau76N4x3DSA4YaIqO14e/dFfHn0Rr3PGxvJYGdhCjtLU3R3s8U/+npgkLcjjO9hHo2yUoWfzqRhffQ1JP+x2KCLwhxvju+KR3q4cuKxljDcNIDhhoio7ahQqbH5VCrKVQL2lqawtzSD3R//tbc0g425idYmBKvUAvviM7Dql0Sk5laFnCE+jlg6sTu82zd+eyBqGMNNAxhuiIioJZVVqLA26hrWRl9DeaUapsYy/GtoZ7wwwrfJCwveLS7H+Vt58HW2gbudRQtX3Dow3DSA4YaIiHQh5U4xluxKwOHEbACAu50F3prQDaO7OdcaqiotV+F0ci6OXcvBsaQcJKQXQIiqYbPxga6YPawzurs1bTHD5lJWqpp8VZkUGG4awHBDRES6IoTArxdvY9nPF5GWV7VWzkN+7bFofDcUlFXiWFIOjl7NQWzKXZSr1DWOdbez0BwDVA1xzR7WGUN9HbU6j+fk9Tt4d99lnL+ZB18nawz2ccQg73YY6N0OCnNTrb3P/WK4aQDDDRER6VpJeSX+dzgJnx25jgpV3V+7rrbmGOzjiCF/hAsnhTni0/Lx2ZHr2BOXAZW66riurgo8N6wzHgl0halx89fWScoqxIp9l3HgUladzxvJgB4edhjs3Q5DfBzxQEd7mJtK17PDcNMAhhsiIpLKtewiLN6ZgKNJObAxN8GgP4LDIB9HdHa0qrdH5mZuCb48egNbTt9EaUXVJezudhZ4erAXpvTzvKceluxCJT48cAWbT9+ESi1gbCTDtP6eeHpwJ1zJLMSxazn4PekOrucU1zjOzMQI/b0c8No4/ybf70ubGG4awHBDRERSEkLgTnE57CxMYXKPPS95JeX47kQKNv6ejJyicgBVPSz+Lgr09bJHn45Vm7udRa2gVFJeiS9+u4H10dc0a/yM6uaMV8f6w8ep9tVc6XmlOJaUg9+v3cGxpBzNWj4KcxP8MHtgi88B+juGmwYw3BARUWtXVqFCxNk0fHX0Bq5mFdV63kVhrgk6fTra43JmAd7/9YomoPT0tMMbD3dF/04OTXo/IQSuZRfh1R/jEJtyFw5WZtgyeyB8nW20+rkawnDTAIYbIiIyJLcLyhCbchcxyXcRm5KLhPQCVKrr/mr3dLDAK2P8MT6weYsLFpRV4MkvTuLCrXy0t5Fj63NB6NTMG5Pe83sz3NSP4YaIiAxZabkK52/l/RF4chGbchemxkaYM9wbTwV1vO/LvfNKyvHEZydwObMQbrbm2Pp8EDzs679NhbYw3DSA4YaIiNqS6q95bV4+nlOkxNT1x3EtuxgdHCyx9bkguNiaa+3163Iv39+8PzsREZEBk8lkWr+/laO1HN8/OxAdHCyRmluC6V+cQE6RUqvvcT8YboiIiOieudia4/tnB8DN1hzXsovx5BcnkVdSLnVZABhuiIiIqJk8HSzx/b8Gor2NHJczCxH61SkUlFVIXRbDDRERETVfJ0crbHp2AByszHDhVj6e3nAaxcpKSWtiuCEiIqL74utsg2+e6Q+FuQliU+7i2a9jUPbHSspSYLghIiKi+xbgbouvn+kPKzNjuNlZ3Nd9r+6XiWTvTERERAaldwd77HphCDq1s4KRkXav0LoXDDdERESkNd7ta9+nStc4LEVEREQGheGGiIiIDArDDRERERkUScNNeHg4+vXrBxsbGzg5OSEkJASJiYmNHrdt2zb4+/vD3NwcPXr0wN69e3VQLREREbUGkoab6OhohIWF4cSJE4iMjERFRQVGjx6N4uLieo/5/fffMW3aNMyaNQtnz55FSEgIQkJCEB8fr8PKiYiISF/p1V3Bs7Oz4eTkhOjoaAwbNqzONlOnTkVxcTF2796t2Tdw4ED06tUL69ata/Q9eFdwIiKi1qfV3hU8Pz8fAODg4FBvm+PHjyM4OLjGvjFjxuD48eN1tlcqlSgoKKixERERkeHSm3CjVquxYMECDB48GAEBAfW2y8zMhLOzc419zs7OyMzMrLN9eHg4bG1tNZunp6dW6yYiIiL9ojfhJiwsDPHx8di8ebNWX3fhwoXIz8/XbDdv3tTq6xMREZF+0YsViufNm4fdu3fjyJEj8PDwaLCti4sLbt++XWPf7du34eLiUmd7uVwOuVyutVqJiIhIv0nacyOEwLx58xAREYFDhw6hU6dOjR4TFBSEgwcP1tgXGRmJoKCgliqTiIiIWhFJe27CwsKwadMm7Ny5EzY2Npp5M7a2trCwsAAAhIaGwt3dHeHh4QCA+fPn48EHH8T777+PRx55BJs3b0ZMTAw+++wzyT4HERER6Q9Je27Wrl2L/Px8DB8+HK6urppty5YtmjapqanIyMjQPB40aBA2bdqEzz77DD179sT27duxY8eOBichExERUduhV+vc6EJ+fj7s7Oxw8+ZNrnNDRETUShQUFMDT0xN5eXmwtbVtsK1eTCjWpcLCQgDgJeFEREStUGFhYaPhps313KjVaqSnp8PGxgYymazJx1UnRvb46AbPt27xfOsWz7du8XzrVkudbyEECgsL4ebmBiOjhmfVtLmeGyMjo0YvN2+IQqHg/xw6xPOtWzzfusXzrVs837rVEue7sR6banqziB8RERGRNjDcEBERkUFhuGkiuVyOxYsXc7VjHeH51i2eb93i+dYtnm/d0ofz3eYmFBMREZFhY88NERERGRSGGyIiIjIoDDdERERkUBhuiIiIyKAw3DTB//73P3h5ecHc3BwDBgzAqVOnpC7JIBw5cgQTJkyAm5sbZDIZduzYUeN5IQTeeustuLq6wsLCAsHBwbh69ao0xRqA8PBw9OvXDzY2NnByckJISAgSExNrtCkrK0NYWBjatWsHa2trTJ48Gbdv35ao4tZt7dq1CAwM1CxkFhQUhH379mme57luWStWrIBMJsOCBQs0+3jOtWfJkiWQyWQ1Nn9/f83zUp9rhptGbNmyBf/5z3+wePFinDlzBj179sSYMWOQlZUldWmtXnFxMXr27In//e9/dT6/atUqfPTRR1i3bh1OnjwJKysrjBkzBmVlZTqu1DBER0cjLCwMJ06cQGRkJCoqKjB69GgUFxdr2rz44ov4+eefsW3bNkRHRyM9PR2TJk2SsOrWy8PDAytWrEBsbCxiYmIwYsQITJw4EQkJCQB4rlvS6dOnsX79egQGBtbYz3OuXd27d0dGRoZmO3r0qOY5yc+1oAb1799fhIWFaR6rVCrh5uYmwsPDJazK8AAQERERmsdqtVq4uLiI1atXa/bl5eUJuVwufvjhBwkqNDxZWVkCgIiOjhZCVJ1fU1NTsW3bNk2bS5cuCQDi+PHjUpVpUOzt7cUXX3zBc92CCgsLha+vr4iMjBQPPvigmD9/vhCCv9/atnjxYtGzZ886n9OHc82emwaUl5cjNjYWwcHBmn1GRkYIDg7G8ePHJazM8N24cQOZmZk1zr2trS0GDBjAc68l+fn5AAAHBwcAQGxsLCoqKmqcc39/f3To0IHn/D6pVCps3rwZxcXFCAoK4rluQWFhYXjkkUdqnFuAv98t4erVq3Bzc0Pnzp0xffp0pKamAtCPc93mbpx5L3JycqBSqeDs7Fxjv7OzMy5fvixRVW1DZmYmANR57qufo+ZTq9VYsGABBg8ejICAAABV59zMzAx2dnY12vKcN19cXByCgoJQVlYGa2trREREoFu3bjh37hzPdQvYvHkzzpw5g9OnT9d6jr/f2jVgwABs3LgRfn5+yMjIwNKlSzF06FDEx8frxblmuCFqg8LCwhAfH19jjJy0z8/PD+fOnUN+fj62b9+OGTNmIDo6WuqyDNLNmzcxf/58REZGwtzcXOpyDN64ceM0fw4MDMSAAQPQsWNHbN26FRYWFhJWVoXDUg1wdHSEsbFxrRnet2/fhouLi0RVtQ3V55fnXvvmzZuH3bt34/Dhw/Dw8NDsd3FxQXl5OfLy8mq05zlvPjMzM/j4+KBPnz4IDw9Hz549sWbNGp7rFhAbG4usrCw88MADMDExgYmJCaKjo/HRRx/BxMQEzs7OPOctyM7ODl26dEFSUpJe/H4z3DTAzMwMffr0wcGDBzX71Go1Dh48iKCgIAkrM3ydOnWCi4tLjXNfUFCAkydP8tw3kxAC8+bNQ0REBA4dOoROnTrVeL5Pnz4wNTWtcc4TExORmprKc64larUaSqWS57oFjBw5EnFxcTh37pxm69u3L6ZPn675M895yykqKsK1a9fg6uqqH7/fOpm23Ipt3rxZyOVysXHjRnHx4kUxe/ZsYWdnJzIzM6UurdUrLCwUZ8+eFWfPnhUAxAcffCDOnj0rUlJShBBCrFixQtjZ2YmdO3eKCxcuiIkTJ4pOnTqJ0tJSiStvnebMmSNsbW1FVFSUyMjI0GwlJSWaNs8//7zo0KGDOHTokIiJiRFBQUEiKChIwqpbr9dee01ER0eLGzduiAsXLojXXntNyGQy8euvvwoheK514a9XSwnBc65NL730koiKihI3btwQx44dE8HBwcLR0VFkZWUJIaQ/1ww3TfDxxx+LDh06CDMzM9G/f39x4sQJqUsyCIcPHxYAam0zZswQQlRdDr5o0SLh7Ows5HK5GDlypEhMTJS26FasrnMNQGzYsEHTprS0VMydO1fY29sLS0tL8dhjj4mMjAzpim7FnnnmGdGxY0dhZmYm2rdvL0aOHKkJNkLwXOvC38MNz7n2TJ06Vbi6ugozMzPh7u4upk6dKpKSkjTPS32uZUIIoZs+IiIiIqKWxzk3REREZFAYboiIiMigMNwQERGRQWG4ISIiIoPCcENEREQGheGGiIiIDArDDRERERkUhhsiavNkMhl27NghdRlEpCUMN0QkqZkzZ0Imk9Xaxo4dK3VpRNRKmUhdABHR2LFjsWHDhhr75HK5RNUQUWvHnhsikpxcLoeLi0uNzd7eHkDVkNHatWsxbtw4WFhYoHPnzti+fXuN4+Pi4jBixAhYWFigXbt2mD17NoqKimq0+eqrr9C9e3fI5XK4urpi3rx5NZ7PycnBY489BktLS/j6+mLXrl0t+6GJqMUw3BCR3lu0aBEmT56M8+fPY/r06XjiiSdw6dIlAEBxcTHGjBkDe3t7nD59Gtu2bcOBAwdqhJe1a9ciLCwMs2fPRlxcHHbt2gUfH58a77F06VJMmTIFFy5cwMMPP4zp06cjNzdXp5+TiLREZ7foJCKqw4wZM4SxsbGwsrKqsS1fvlwIUXU38+eff77GMQMGDBBz5swRQgjx2WefCXt7e1FUVKR5fs+ePcLIyEhkZmYKIYRwc3MTb7zxRr01ABBvvvmm5nFRUZEAIPbt26e1z0lEusM5N0QkuYceeghr166tsc/BwUHz56CgoBrPBQUF4dy5cwCAS5cuoWfPnrCystI8P3jwYKjVaiQmJkImkyE9PR0jR45ssIbAwEDNn62srKBQKJCVldXcj0REEmK4ISLJWVlZ1Rom0hYLC4smtTM1Na3xWCaTQa1Wt0RJRNTCOOeGiPTeiRMnaj3u2rUrAKBr1644f/48iouLNc8fO3YMRkZG8PPzg42NDby8vHDw4EGd1kxE0mHPDRFJTqlUIjMzs8Y+ExMTODo6AgC2bduGvn37YsiQIfj+++9x6tQpfPnllwCA6dOnY/HixZgxYwaWLFmC7OxsvPDCC3jqqafg7OwMAFiyZAmef/55ODk5Ydy4cSgsLMSxY8fwwgsv6PaDEpFOMNwQkeR++eUXuLq61tjn5+eHy5cvA6i6kmnz5s2YO3cuXF1d8cMPP6Bbt24AAEtLS+zfvx/z589Hv379YGlpicmTJ+ODDz7QvNaMGTNQVlaG//73v3j55Zfh6OiIxx9/XHcfkIh0SiaEEFIXQURUH5lMhoiICISEhEhdChG1EpxzQ0RERAaF4YaIiIgMCufcEJFe48g5Ed0r9twQERGRQWG4ISIiIoPCcENEREQGheGGiIiIDArDDRERERkUhhsiIiIyKAw3REREZFAYboiIiMigMNwQERGRQfl/Oz7gJitC16UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, epoch + 1, print_every), losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 存储模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "model.load_state_dict(torch.load(\"./model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = tensor([[  2, 403, 235, 293]]), src_decode = 清明时\n",
      "tgt = tensor([[197,   9,  10,  55,  61, 216,  10,  15,  61, 934,  24, 116, 486,   9,\n",
      "         148, 327, 234,  55, 350,  15,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1]]), tgt_decode = 节，春色不如春。不见花枝上，犹疑月色中。\n",
      "完整诗句：清明时节，春色不如春。不见花枝上，犹疑月色中。\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    word_ids = tokenizer.encode(\"清明时节\")\n",
    "    src = torch.tensor([word_ids[:-2]]).to(DEVICE)\n",
    "    tgt = torch.tensor([word_ids[-2:-1]]).to(DEVICE)\n",
    "    # 一个一个词预测，直到预测为<eos>，或者达到句子最大长度\n",
    "    for i in range(64):\n",
    "        out = model(src, tgt)\n",
    "        # 预测结果，只需最后一个词 \n",
    "        # out: (1, tgt_s, h) ---> (1, 1, h) # ---> predict: (1, 1, v) \n",
    "        # ---argmax---> (1, 1) 找出最大值的index\n",
    "        predict = model.predict(out[:,-1:,:])\n",
    "        # predict = model.predict(out)\n",
    "        # print(predict.size())\n",
    "        # predict[0,0,[1,3,9,15,61,514,115,158,17,0]] = 0\n",
    "        # predict[0,0,[1,15]] = 0\n",
    "        # predict[0,0,9] = 0\n",
    "        y = torch.argmax(predict, dim=-1)\n",
    "        # 和之前的预测结果拼接到一起\n",
    "        tgt = torch.cat([tgt, y], dim=1)\n",
    "        # if y == tokenizer.eos_id or tgt.size()[1] == 64:\n",
    "            # break\n",
    "        # break\n",
    "\n",
    "    src_decode = \"\".join([w for w in tokenizer.decode(src[0].tolist()) if w not in [Tokenizer.PAD, Tokenizer.UNKNOWN]])\n",
    "    print(f\"src = {src}, src_decode = {src_decode}\")\n",
    "    tgt_decode = \"\".join([w for w in tokenizer.decode(tgt[0].tolist()) if w not in [Tokenizer.PAD, Tokenizer.UNKNOWN]])\n",
    "    print(f\"tgt = {tgt}, tgt_decode = {tgt_decode}\")\n",
    "    print(f\"完整诗句：{src_decode + tgt_decode}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
