{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import random\n",
    "\n",
    "# 深度学习库pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 用于绘制损失函数下降曲线\n",
    "from matplotlib import pyplot as plt\n",
    "%pdb off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建\n",
    "\n",
    "## 数据集选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单行诗最大长度\n",
    "MAX_LEN = 64\n",
    "MIN_LEN = 5\n",
    "# 禁用的字符，拥有以下符号的诗将被忽略\n",
    "DISALLOWED_WORDS = ['（', '）', '(', ')', '__', '《', '》', '【', '】', '[', ']', '？', '；']\n",
    "\n",
    "# 一首诗（一行）对应一个列表的元素\n",
    "poetry = []\n",
    "\n",
    "# 按行读取数据 poetry.txt\n",
    "with open('./poetry.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "# 遍历处理每一条数据    \n",
    "for line in lines:\n",
    "    # 利用正则表达式拆分 标题 和 内容\n",
    "    fields = line.split(\":\")\n",
    "    # 跳过异常数据\n",
    "    if len(fields) != 2:\n",
    "        continue\n",
    "    # 得到诗词内容（后面不需要标题）\n",
    "    content = fields[1]\n",
    "    # 过滤数据：跳过内容过长、过短、存在禁用符的诗词\n",
    "    if len(content) > MAX_LEN - 2 or len(content) < MIN_LEN:\n",
    "        continue\n",
    "    if any(word in content for word in DISALLOWED_WORDS):\n",
    "        continue\n",
    "        \n",
    "    poetry.append(content.replace('\\n', '')) # 最后要记得删除换行符\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寒随穷律变，春逐鸟声开。初风飘带柳，晚雪间花梅。碧林青旧竹，绿沼翠新苔。芝田初雁去，绮树巧莺来。\n",
      "晚霞聊自怡，初晴弥可喜。日晃百花色，风动千林翠。池鱼跃不同，园鸟声还异。寄言博通者，知予物外志。\n",
      "夏律昨留灰，秋箭今移晷。峨嵋岫初出，洞庭波渐起。桂白发幽岩，菊黄开灞涘。运流方可叹，含毫属微理。\n",
      "寒惊蓟门叶，秋发小山枝。松阴背日转，竹影避风移。提壶菊花岸，高兴芙蓉池。欲知凉气早，巢空燕不窥。\n",
      "山亭秋色满，岩牖凉风度。疏兰尚染烟，残菊犹承露。古石衣新苔，新巢封古树。历览情无极，咫尺轮光暮。\n",
      "慨然抚长剑，济世岂邀名。星旗纷电举，日羽肃天行。遍野屯万骑，临原驻五营。登山麾武节，背水纵神兵。在昔戎戈动，今来宇宙平。\n",
      "翠野驻戎轩，卢龙转征旆。遥山丽如绮，长流萦似带。海气百重楼，岩松千丈盖。兹焉可游赏，何必襄城外。\n",
      "玄兔月初明，澄辉照辽碣。映云光暂隐，隔树花如缀。魄满桂枝圆，轮亏镜彩缺。临城却影散，带晕重围结。驻跸俯九都，停观妖氛灭。\n",
      "碧原开雾隰，绮岭峻霞城。烟峰高下翠，日浪浅深明。斑红妆蕊树，圆青压溜荆。迹岩劳傅想，窥野访莘情。巨川何以济，舟楫伫时英。\n",
      "春蒐驰骏骨，总辔俯长河。霞处流萦锦，风前漾卷罗。水花翻照树，堤兰倒插波。岂必汾阴曲，秋云发棹歌。\n",
      "current_line_count = 24375\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(poetry[i])\n",
    "    \n",
    "print(f\"current_line_count = {len(poetry)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寒 -> 2612\n",
      "随 -> 1036\n",
      "穷 -> 482\n",
      "律 -> 118\n",
      "变 -> 286\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# 最小词频\n",
    "MIN_WORD_FREQUENCY = 8\n",
    "\n",
    "# 统计词频，利用Counter可以直接按单个字符进行统计词频\n",
    "counter = Counter()\n",
    "for line in poetry:\n",
    "    counter.update(line)\n",
    "# 过滤掉低词频的词\n",
    "tokens = [token for token, count in counter.items() if count >= MIN_WORD_FREQUENCY]\n",
    "# 打印一下出现次数前5的字\n",
    "for i, (token, count) in enumerate(counter.items()):\n",
    "    print(token, \"->\",count)\n",
    "    if i >= 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \"\"\"\n",
    "    词典编码器\n",
    "    \"\"\"\n",
    "    UNKNOWN = \"<unknown>\"\n",
    "    PAD = \"<pad>\"\n",
    "    BOS = \"<bos>\" \n",
    "    EOS = \"<eos>\" \n",
    "\n",
    "    def __init__(self, tokens):\n",
    "        # 补上特殊词标记：未知词标记、填充字符标记、开始标记、结束标记\n",
    "        tokens = [Tokenizer.UNKNOWN, Tokenizer.PAD, Tokenizer.BOS, Tokenizer.EOS] + tokens\n",
    "        # 词汇表大小\n",
    "        self.dict_size = len(tokens)\n",
    "        # 生成映射关系\n",
    "        self.token_id = {} # 映射: 词 -> 编号\n",
    "        self.id_token = {} # 映射: 编号 -> 词\n",
    "        for idx, word in enumerate(tokens):\n",
    "            self.token_id[word] = idx\n",
    "            self.id_token[idx] = word\n",
    "        \n",
    "        # 各个特殊标记的编号id，方便其他地方使用\n",
    "        self.unknown_id = self.token_id[Tokenizer.UNKNOWN]\n",
    "        self.pad_id = self.token_id[Tokenizer.PAD]\n",
    "        self.bos_id = self.token_id[Tokenizer.BOS]\n",
    "        self.eos_id = self.token_id[Tokenizer.EOS]\n",
    "    \n",
    "    def id_to_token(self, token_id):\n",
    "        \"\"\"\n",
    "        编号 -> 词\n",
    "        \"\"\"\n",
    "        return self.id_token.get(token_id)\n",
    "\n",
    "    def token_to_id(self, token):\n",
    "        \"\"\"\n",
    "        词 -> 编号，取不到时给 UNKNOWN\n",
    "        \"\"\"\n",
    "        return self.token_id.get(token, self.unknown_id)\n",
    "\n",
    "    def encode(self, tokens):\n",
    "        \"\"\"\n",
    "        词列表 -> <bos>编号 + 编号列表 + <eos>编号\n",
    "        \"\"\"\n",
    "        token_ids = [self.bos_id, ] # 起始标记\n",
    "        # 遍历，词转编号\n",
    "        for token in tokens:\n",
    "            token_ids.append(self.token_to_id(token))\n",
    "        token_ids.append(self.eos_id) # 结束标记\n",
    "        return token_ids\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        \"\"\"\n",
    "        编号列表 -> 词列表(去掉起始、结束标记)\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        for idx in token_ids:\n",
    "            # 跳过起始、结束标记\n",
    "            if idx != self.bos_id and idx != self.eos_id:\n",
    "                tokens.append(self.id_to_token(idx))\n",
    "        return tokens\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dict_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2onehot(word_ids, vocab_size):\n",
    "    if word_ids.dim() == 1:\n",
    "        # 一维情况：(seq_len,)\n",
    "        onehot_tensor = torch.zeros(len(word_ids), vocab_size)\n",
    "        for i, s in enumerate(word_ids): \n",
    "            onehot_tensor[i, s] = 1\n",
    "    elif word_ids.dim() == 2:\n",
    "        # 二维情况：(batch_size, seq_len)\n",
    "        batch_size, seq_len = word_ids.size()\n",
    "        onehot_tensor = torch.zeros(batch_size, seq_len, vocab_size, dtype=torch.float32)\n",
    "        onehot_tensor.scatter_(2, word_ids.unsqueeze(2), 1)\n",
    "    else:\n",
    "        raise ValueError(\"word_ids must be a 1D or 2D tensor\")\n",
    "    return onehot_tensor\n",
    "\n",
    "def onehot2index(word_ids):\n",
    "    return torch.argmax(word_ids, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "class MyDataset(TensorDataset):\n",
    "    \n",
    "    def __init__(self, data, tokenizer, max_len=64):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len  # 每条数据的最大长度\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        line = self.data[index]\n",
    "        word_ids = self.encode_pad_line(line)\n",
    "        return torch.tensor(word_ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def encode_pad_line(self, line):\n",
    "        word_ids = self.tokenizer.encode(line)\n",
    "        # 如果句子长度不足max_len，填充PAD；超过max_len，截断\n",
    "        if len(word_ids) <= self.max_len:\n",
    "            word_ids = word_ids + [self.tokenizer.pad_id] * (self.max_len - len(word_ids))\n",
    "        else:\n",
    "            word_ids = word_ids[:self.max_len - 1].append(self.tokenizer.eos_id)\n",
    "        return word_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型类定义\n",
    "\n",
    "### 嵌入层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, v, h):\n",
    "        # 调用父类的初始化方法，所有子类均需要该操作\n",
    "        super().__init__()\n",
    "        # 在子类初始化声明中需要定义其包含哪些基本层\n",
    "        self.embedding = nn.Linear(v, h)\n",
    "        self.h = h\n",
    "        self.v = v\n",
    "\n",
    "    def forward(self, src):\n",
    "        # print(src.size())\n",
    "        onehot_tensor = index2onehot(src, self.v)\n",
    "        # print(onehot_tensor.size())\n",
    "        # 在forward方法中，我们声明输入张量如何经过这些基本层得到输出张量。\n",
    "        return self.embedding(onehot_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, h, dropout=0.1, max_len=64):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, h)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, h, 2).float() * (-math.log(10000.0) / h))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size(), self.pe.size())\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False) \n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意力模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, h, a, dropout=0.1, type = 'self'):\n",
    "        '''\n",
    "        h: 嵌入层维度\n",
    "        a: 注意力头数\n",
    "        d_k: 每个注意力头的第二个维度\n",
    "\n",
    "        X: (s,h) ---Wq, Wk, Wv: (h, h//a) ---> Q,K,V: (s, h//a) \n",
    "            ---> softmax(Q * K.t / sqrt(d_k)) * V: (s, h//a)\n",
    "            ---> output: (s, h) ---out_proj: (h, h)---> output: (s, h)\n",
    "        '''\n",
    "        super().__init__()  # 注意这里的修正，使用super()而不是super.__init__()\n",
    "        self.h = h\n",
    "        self.a = a\n",
    "        self.d_k = h // a\n",
    "        self.types = type\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # 初始化Q, K, V的权重矩阵\n",
    "        # 每个权重矩阵的维数是(s, h//a) 这里是(h, h)，是将每个头的相应矩阵拼接到一起了\n",
    "        self.Wq = nn.Linear(h, h)\n",
    "        self.Wk = nn.Linear(h, h)\n",
    "        self.Wv = nn.Linear(h, h)\n",
    "        \n",
    "        # 缩放因子，用于缩放点积结果\n",
    "        self.scale = 1 / math.sqrt(self.d_k)\n",
    "\n",
    "        self.out_proj = nn.Linear(h, h)\n",
    "\n",
    "    def forward(self, x, y = None, padding_mask=None, tgt_sequence_mask = None):\n",
    "        \"\"\"\n",
    "        x: (batch_size, s = tgt_s, h)\n",
    "        y: (batch_size, s = src_s, h)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \"\"\"\n",
    "        Step #1 通过线性变换得到Q, K, V\n",
    "        q,k,v: (batch_size, s, h) ---> (batch_size, s, a, d_k) ---> (batch_size, a, s, d_k)\n",
    "        crros attention时q的s=tgt_s, kv的s=src_s\n",
    "        \"\"\"\n",
    "        if self.types == 'self':            # 自注意力机制，均来自输入x            \n",
    "            assert y is None, (\"Self Attention but different input for Q K V\")\n",
    "            q = k = v = x\n",
    "        elif self.types == 'cross':         # 交叉注意力机制，q来自x，k v来自y\n",
    "            assert y is not None, (\"Cross Attention but the same input for Q K V\")\n",
    "            q = x\n",
    "            k = v = y\n",
    "        else: raise ValueError(\"Undefined Attention Type\")\n",
    "\n",
    "        q = self.Wq(q).view(batch_size, -1, self.a, self.d_k).transpose(1, 2)\n",
    "        k = self.Wk(k).view(batch_size, -1, self.a, self.d_k).transpose(1, 2)\n",
    "        v = self.Wv(v).view(batch_size, -1, self.a, self.d_k).transpose(1, 2)\n",
    "\n",
    "        \"\"\"\n",
    "        Step#2 计算注意力分数\n",
    "        x: (batch_size, s, h)\n",
    "        k: (batch_size, a, src_s, d_k) ---> (batch_size, a, d_k, src_s)\n",
    "        tgt_sequence_mask: (tgt_s, tgt_s) ---> (batch_size, a, tgt_s, tgt_s)\n",
    "        padding_mask : (batch_size, src_s) ---> (batch_size, a, tgt_s, src_s)\n",
    "        \"\"\"\n",
    "        k_len  = k.size()[2]\n",
    "        scores = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "        if padding_mask is not None:\n",
    "            # print(padding_mask)\n",
    "            mask = padding_mask.view(batch_size, 1, 1, k_len).expand(batch_size, self.a, q.size()[2], k_len)\n",
    "            if tgt_sequence_mask is not None: \n",
    "                assert self.types == 'self' , \\\n",
    "                        (f\"Only Self Attention in Decoder Needs Sequence Mask, but now {self.types} attetion!\")\n",
    "                s_mask = tgt_sequence_mask.view(1, 1, k_len, k_len).   \\\n",
    "                expand(batch_size, self.a, -1, -1)\n",
    "                mask = s_mask.logical_or(mask)\n",
    "            # print(mask.size(), scores.size())\n",
    "            # print(mask)\n",
    "            scores = scores.masked_fill(mask, -1e9)\n",
    "        \n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.h)\n",
    "        output = self.out_proj(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, h, hiddenDim = None, outDim = None, dropout = 0.1, type = 'relu'):\n",
    "        \"\"\"\n",
    "        x: (h, h) ---> x * W_1: (h, hiddenDim) ---> relu/gelu: (h, hiddenDim) ---> A' * W2: (h, outDim)\n",
    "        W1: (h, hiddenDim)\n",
    "        W2: (hiddenDim, outDim)\n",
    "        默认hiddenDim = 4 * h, outDim = h\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.h = h\n",
    "        if hiddenDim is None: hiddenDim = 4 * h\n",
    "        if outDim is None: outDim = h\n",
    "        self.W1 = nn.Linear(h, hiddenDim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.W2 = nn.Linear(hiddenDim, outDim)\n",
    "        self.types = type\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.W1(x)\n",
    "        if self.types == 'relu': x = F.relu(x)\n",
    "        elif self.types == 'gelu': x = F.gelu(x)\n",
    "        else: raise ValueError(\"Unsupported activation type\")\n",
    "        x = self.dropout(x)\n",
    "        x = self.W2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5, elementwise_affine=True):\n",
    "        super().__init__()\n",
    "        self.normalized_shape = normalized_shape\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "    def forward(self, input):\n",
    "        # 计算均值和方差\n",
    "        assert self.normalized_shape[0] == input.size()[-1], (\"Unmatched Shape.\")\n",
    "        mean = input.mean(dim=-1, keepdim=True)\n",
    "        var = input.var(dim=-1, unbiased=False, keepdim=True)\n",
    "        std = torch.sqrt(var + self.eps)\n",
    "        \n",
    "        # 应用层归一化公式\n",
    "        normalized_input = (input - mean) / std\n",
    "        normalized_input = normalized_input * self.weight + self.bias\n",
    "        \n",
    "        return normalized_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Encoder和Decoder\n",
    "\n",
    "包含从嵌入层进入attention block之后的所有流程：encoder decoder feedforward add&norm\n",
    "对于encoder来讲，self-attention ---> add&norm ---> feedforward ---> add&norm\n",
    "对于decoder来讲, self-attention ---> add&norm ---> cross-attention ---> add&norm ---> feedforward ---> add&norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderDecoder(nn.Module):\n",
    "    def __init__(self, h, a, num_encoder_layers, num_decoder_layers, dim_feedforward=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoders = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                Attention(h, a, dropout),\n",
    "                LayerNorm((h,)),\n",
    "                FeedForward(h, dropout = dropout),\n",
    "                LayerNorm((h,))\n",
    "            ]) for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.decoders = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                Attention(h, a, dropout),\n",
    "                LayerNorm((h,)),\n",
    "                Attention(h, a, dropout, type='cross'),\n",
    "                LayerNorm((h,)),\n",
    "                FeedForward(h, dropout = dropout),\n",
    "                LayerNorm((h,))\n",
    "            ]) for _ in range(num_decoder_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, encoder_input, decoder_input, src_padding_mask=None, tgt_padding_mask = None, tgt_sequence_mask=None):\n",
    "\n",
    "        for enc in self.encoders:\n",
    "            attention, norm1, ff, norm2 = enc\n",
    "            encoder_input = norm1(attention(encoder_input, padding_mask=src_padding_mask) + encoder_input)\n",
    "            encoder_input = norm2(ff(encoder_input) + encoder_input)\n",
    "\n",
    "        for dec in self.decoders:\n",
    "            self_attention, norm1, cross_attention, norm2, ff, norm3 = dec\n",
    "            decoder_input = norm1(self_attention(decoder_input, padding_mask=tgt_padding_mask, \\\n",
    "                                                 tgt_sequence_mask = tgt_sequence_mask) + decoder_input)\n",
    "            decoder_input = norm2(cross_attention(decoder_input, encoder_input, \\\n",
    "                                                  padding_mask=src_padding_mask) + decoder_input)\n",
    "            decoder_input = norm3(ff(decoder_input) + decoder_input)\n",
    "        return decoder_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction(nn.Module):\n",
    "    def __init__(self, h, v):\n",
    "        super().__init__()\n",
    "        self.w = nn.Linear(h, v)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Transformer模型\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, v, h, a, num_encoder_layers, num_decoder_layers, dimFF, dropout, max_len):\n",
    "        super().__init__()\n",
    "        # self.embedding = Embedding(v,h)\n",
    "        self.embedding = nn.Embedding(v, h, padding_idx=1)\n",
    "        self.posEncoding = PositionalEncoding(h, 0, max_len)\n",
    "        self.transformer = TransformerEncoderDecoder(h, a, num_encoder_layers, num_decoder_layers, dimFF, dropout)\n",
    "        # self.transformer = nn.Transformer(h,a,num_encoder_layers, num_decoder_layers, dimFF, dropout, batch_first=True)\n",
    "        self.predict = Prediction(h, v)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, src, tgt, src_padding_mask = None, tgt_padding_mask = None, tgt_sequence_mask = None):\n",
    "\n",
    "        if src_padding_mask is None: \n",
    "            src_padding_mask = self.get_key_padding_mask(src).to(DEVICE)\n",
    "        if tgt_padding_mask is None: \n",
    "            tgt_padding_mask = self.get_key_padding_mask(tgt).to(DEVICE)\n",
    "        if tgt_sequence_mask is None: \n",
    "            tgt_sequence_mask = self.get_sequence_mask(tgt).to(DEVICE)\n",
    "\n",
    "        src = self.embedding(src)\n",
    "        tgt = self.embedding(tgt)\n",
    "\n",
    "        src = self.posEncoding(src)\n",
    "        tgt = self.posEncoding(tgt)\n",
    "        output = self.transformer(src, tgt, src_padding_mask, tgt_padding_mask, tgt_sequence_mask)\n",
    "        # output = self.transformer(src, tgt, tgt_mask = tgt_sequence_mask, \n",
    "                                #   src_key_padding_mask = src_padding_mask,\n",
    "                                #  tgt_key_padding_mask = tgt_padding_mask)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sequence_mask(tgt):\n",
    "        size = tgt.size()[-1]\n",
    "        sr = torch.triu(torch.full((size, size), True, device=DEVICE), diagonal=1)\n",
    "        # print(sr)\n",
    "        return sr\n",
    "\n",
    "    @staticmethod\n",
    "    def get_key_padding_mask(tokens):\n",
    "        key_padding_mask = torch.full(tokens.size(), False, dtype=bool)\n",
    "        # key_padding_mask[tokens == 1] = True\n",
    "        return key_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练和预测\n",
    "\n",
    "### 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embedding): Embedding(3428, 128, padding_idx=1)\n",
      "  (posEncoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "  )\n",
      "  (transformer): TransformerEncoderDecoder(\n",
      "    (encoders): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "    (decoders): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "        (4): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): LayerNorm()\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "        (4): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): LayerNorm()\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): LayerNorm()\n",
      "        (2): Attention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (3): LayerNorm()\n",
      "        (4): FeedForward(\n",
      "          (W1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (W2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): LayerNorm()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predict): Prediction(\n",
      "    (w): Linear(in_features=128, out_features=3428, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(tokens)\n",
    "v = len(tokenizer)\n",
    "batch_size = 64\n",
    "max_len = 64\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "dataset = MyDataset(poetry, tokenizer,  max_len)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 初始化模型、优化器和损失函数\n",
    "h = 128\n",
    "a = 4\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dim_feedforward = 4 * h\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(v, h, a, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, max_len)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train... [epoch 1/50, loss 3.66960]: 100%|██████████| 381/381 [03:45<00:00,  1.69it/s]\n",
      "Train... [epoch 2/50, loss 3.28136]: 100%|██████████| 381/381 [03:36<00:00,  1.76it/s]\n",
      "Train... [epoch 3/50, loss 3.14845]: 100%|██████████| 381/381 [03:30<00:00,  1.81it/s]\n",
      "Train... [epoch 4/50, loss 3.02539]: 100%|██████████| 381/381 [03:28<00:00,  1.82it/s]\n",
      "Train... [epoch 5/50, loss 2.88930]: 100%|██████████| 381/381 [03:35<00:00,  1.77it/s]\n",
      "Train... [epoch 6/50, loss 2.86914]: 100%|██████████| 381/381 [03:40<00:00,  1.73it/s]\n",
      "Train... [epoch 7/50, loss 2.78042]: 100%|██████████| 381/381 [03:38<00:00,  1.75it/s]\n",
      "Train... [epoch 8/50, loss 2.70861]: 100%|██████████| 381/381 [03:41<00:00,  1.72it/s]\n",
      "Train... [epoch 9/50, loss 2.70174]: 100%|██████████| 381/381 [03:36<00:00,  1.76it/s]\n",
      "Train... [epoch 10/50, loss 2.64658]: 100%|██████████| 381/381 [03:36<00:00,  1.76it/s]\n",
      "Train... [epoch 11/50, loss 2.62543]: 100%|██████████| 381/381 [03:39<00:00,  1.74it/s]\n",
      "Train... [epoch 12/50, loss 2.56787]: 100%|██████████| 381/381 [03:37<00:00,  1.75it/s]\n",
      "Train... [epoch 13/50, loss 2.58452]: 100%|██████████| 381/381 [03:39<00:00,  1.74it/s]\n",
      "Train... [epoch 14/50, loss 2.54209]: 100%|██████████| 381/381 [03:39<00:00,  1.74it/s]\n",
      "Train... [epoch 15/50, loss 2.49608]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 16/50, loss 2.48693]: 100%|██████████| 381/381 [03:33<00:00,  1.79it/s]\n",
      "Train... [epoch 17/50, loss 2.46370]: 100%|██████████| 381/381 [03:32<00:00,  1.80it/s]\n",
      "Train... [epoch 18/50, loss 2.42376]: 100%|██████████| 381/381 [03:36<00:00,  1.76it/s]\n",
      "Train... [epoch 19/50, loss 2.39608]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 20/50, loss 2.39437]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 21/50, loss 2.38628]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 22/50, loss 2.34859]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 23/50, loss 2.34978]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 24/50, loss 2.33342]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 25/50, loss 2.32956]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 26/50, loss 2.31493]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 27/50, loss 2.29926]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 28/50, loss 2.28907]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 29/50, loss 2.25806]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 30/50, loss 2.26798]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 31/50, loss 2.23130]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 32/50, loss 2.22845]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 33/50, loss 2.21270]: 100%|██████████| 381/381 [03:32<00:00,  1.80it/s]\n",
      "Train... [epoch 34/50, loss 2.18993]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 35/50, loss 2.20399]: 100%|██████████| 381/381 [03:33<00:00,  1.78it/s]\n",
      "Train... [epoch 36/50, loss 2.20833]: 100%|██████████| 381/381 [03:34<00:00,  1.78it/s]\n",
      "Train... [epoch 37/50, loss 2.18427]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 38/50, loss 2.16265]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 39/50, loss 2.19014]: 100%|██████████| 381/381 [03:33<00:00,  1.78it/s]\n",
      "Train... [epoch 40/50, loss 2.13009]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 41/50, loss 2.13341]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 42/50, loss 2.15037]: 100%|██████████| 381/381 [03:32<00:00,  1.80it/s]\n",
      "Train... [epoch 43/50, loss 2.12957]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 44/50, loss 2.10275]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 45/50, loss 2.11451]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 46/50, loss 2.09422]: 100%|██████████| 381/381 [03:32<00:00,  1.80it/s]\n",
      "Train... [epoch 47/50, loss 2.08405]: 100%|██████████| 381/381 [03:33<00:00,  1.78it/s]\n",
      "Train... [epoch 48/50, loss 2.10847]: 100%|██████████| 381/381 [03:32<00:00,  1.79it/s]\n",
      "Train... [epoch 49/50, loss 2.09687]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n",
      "Train... [epoch 50/50, loss 2.05075]: 100%|██████████| 381/381 [03:31<00:00,  1.80it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "import tqdm\n",
    "\n",
    "losses = []\n",
    "print_every = 1\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    data_progress = tqdm.tqdm(dataloader, desc=\"Train...\")\n",
    "    for step, data in enumerate(data_progress, 1):\n",
    "        data = data.to(DEVICE)\n",
    "        # data: (batch_size, seq_len) \n",
    "        # ---> src: (batch_size, src_s) + tgt: (batch_size, tgt_s)\n",
    "        # 随机选一个位置，拆分src和tgt\n",
    "        e = random.randint(1, 20)\n",
    "        src = data[:, :e]\n",
    "        # tgt不要最后一个token，tgt_y不要第一个的token\n",
    "        tgt, tgt_y = data[:, e:-1], data[:, e + 1:]\n",
    "        # 进行Transformer的计算和预测 \n",
    "        # out: (batch_size, tgt_s, h) ---> (batch_size, tgt_s, v) \n",
    "        #                           tgt_y: (batch_size, tgt_s)\n",
    "        out = model(src, tgt)\n",
    "        out = model.predict(out)\n",
    "        loss = criterion(out.view(-1, out.size(-1)), tgt_y.contiguous().view(-1))\n",
    "        # 监控nan\n",
    "        with torch.autograd.set_detect_anomaly(False):\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # 更新训练进度\n",
    "        data_progress.set_description(f\"Train... [epoch {epoch}/{num_epochs}, loss {(total_loss / step):.5f}]\")\n",
    "    losses.append(total_loss/step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bc9f3da1f0>]"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, epoch + 1, print_every), losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 存储模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "model.load_state_dict(torch.load(\"./model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = tensor([[  2, 403, 235, 293]]), src_decode = 清明时\n",
      "tgt = tensor([[197,   9,  10,  55,  61, 216,  10,  15,  61, 934,  24, 116, 486,   9,\n",
      "         148, 327, 234,  55, 350,  15,   3,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1]]), tgt_decode = 节，春色不如春。不见花枝上，犹疑月色中。\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    word_ids = tokenizer.encode(\"清明时节\")\n",
    "    src = torch.tensor([word_ids[:-2]]).to(DEVICE)\n",
    "    tgt = torch.tensor([word_ids[-2:-1]]).to(DEVICE)\n",
    "    # 一个一个词预测，直到预测为<eos>，或者达到句子最大长度\n",
    "    for i in range(64):\n",
    "        out = model(src, tgt)\n",
    "        # 预测结果，只需最后一个词 \n",
    "        # out: (1, tgt_s, h) ---> (1, 1, h) # ---> predict: (1, 1, v) \n",
    "        # ---argmax---> (1, 1) 找出最大值的index\n",
    "        predict = model.predict(out[:,-1:,:])\n",
    "        # predict = model.predict(out)\n",
    "        # print(predict.size())\n",
    "        # predict[0,0,[1,3,9,15,61,514,115,158,17,0]] = 0\n",
    "        # predict[0,0,[1,15]] = 0\n",
    "        # predict[0,0,9] = 0\n",
    "        y = torch.argmax(predict, dim=-1)\n",
    "        # 和之前的预测结果拼接到一起\n",
    "        tgt = torch.cat([tgt, y], dim=1)\n",
    "        # if y == tokenizer.eos_id or tgt.size()[1] == 64:\n",
    "            # break\n",
    "        # break\n",
    "\n",
    "    src_decode = \"\".join([w for w in tokenizer.decode(src[0].tolist()) if w not in [Tokenizer.PAD, Tokenizer.UNKNOWN]])\n",
    "    print(f\"src = {src}, src_decode = {src_decode}\")\n",
    "    tgt_decode = \"\".join([w for w in tokenizer.decode(tgt[0].tolist()) if w not in [Tokenizer.PAD, Tokenizer.UNKNOWN]])\n",
    "    print(f\"tgt = {tgt}, tgt_decode = {tgt_decode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逗号、句号\n",
    "comma = tokenizer.token_to_id('，')\n",
    "period = tokenizer.token_to_id('。')\n",
    "\n",
    "# def choice(values, indices):\n",
    "#     target_index = torch.multinomial(values, 1, replacement=True)\n",
    "#     y = indices[target_index]\n",
    "#     if y == comma or y == period:\n",
    "#         return choice(values, indices)\n",
    "#     else:\n",
    "#         return y\n",
    "\n",
    "# def predict(model, src, tgt):\n",
    "#     out = model(src, tgt)\n",
    "#     # 预测结果，只需最后一个词\n",
    "#     # 取3:，表示预测结果不要UNKNOWN、PAD、BOS\n",
    "#     _probas = model.predict(out[-1:])[0, 0, 3:]\n",
    "#     _probas = torch.exp(_probas) / torch.exp(_probas).sum()  # softmax，让概率高的变得更高，便于待会儿按概率抽取时更容易抽取到概率高的\n",
    "\n",
    "#     # 取前10\n",
    "#     values, indices = torch.topk(_probas, 10, dim=0)\n",
    "#     y = indices[0]\n",
    "#     if y != comma and y != period:\n",
    "#         # 再按概率分布抽取1个（提高诗词随机性）\n",
    "#         y = choice(values, indices)\n",
    "#     # +3，因为之前移除掉了UNKNOWN、PAD、BOS\n",
    "#     return y + 3\n",
    "\n",
    "def predict(model, src, tgt):\n",
    "    out = model(src, tgt)\n",
    "    # 预测结果，只需最后一个词\n",
    "    # 取3:，表示预测结果不要UNKNOWN、PAD、BOS\n",
    "    _probas = model.predict(out[-1:])[0, 0, 3:]\n",
    "    _probas = torch.exp(_probas) / torch.exp(_probas).sum()  # softmax，让概率高的变得更高，便于待会儿按概率抽取时更容易抽取到概率高的\n",
    "\n",
    "    # 取前10，再按概率分布抽取1个（提高诗词随机性）\n",
    "    values, indices = torch.topk(_probas, 10, dim=0)\n",
    "    target_index = torch.multinomial(values, 1, replacement=True)\n",
    "    y = indices[target_index]\n",
    "    # +3，因为之前移除掉了UNKNOWN、PAD、BOS\n",
    "    return y + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清明时节，候不，动日上候，已，，候，候，，，不，，不上不，，起，起不日，，，，罢，，，，候，，，，动不，，，，日，，，，上在日，，动，上\n",
      "清明时节，，，日，已，，，起，，，，已，，候候，，不，罢日，，，，日罢，，，，，，，，不，，，，，动上，已，，，动，，，，日，上上，，日\n",
      "清明时节，候，不，候上罢不，，在，日不，候，不在起日在候，上在不，，，，上在动，，罢上，，，，，日不，，，日罢，，，，，，罢，，，，日候\n",
      "清明时节起，已已，候，，，，，，，罢，不，，，，，不，候，，，，，，候，，，，候，，，日，，，，起，候，日，，，候，，，，上，，，，不候\n",
      "清明时节，，，，，，，不，候，在，，日上在候不，罢，罢，候候日，，，罢不，，候上，，在，，，，候，，，，，罢已，候候，起，候，候起，起，\n"
     ]
    }
   ],
   "source": [
    "def generate_random_poem(tokenizer, model, text):\n",
    "    if text == None or text == \"\":\n",
    "        text = tokenizer.id_to_token(random.randint(4, len(tokenizer)))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        word_ids = tokenizer.encode(text)\n",
    "        src = torch.LongTensor([word_ids[:-2]]).to(DEVICE)\n",
    "        tgt = torch.LongTensor([word_ids[-2:-1]]).to(DEVICE)\n",
    "        # 一个一个词预测，直到预测为<eos>，或者达到句子最大长度\n",
    "        for i in range(64):\n",
    "            y = predict(model, src, tgt)\n",
    "            # 和之前的预测结果拼接到一起\n",
    "            tgt = torch.cat([tgt, y.view(1, 1)], dim=1)\n",
    "\n",
    "            # 如果为<eos>\n",
    "            if y == tokenizer.eos_id:\n",
    "                break\n",
    "\n",
    "        # src_decode = \"\".join([w for w in tokenizer.decode(src[0].tolist()) if w != Tokenizer.PAD])\n",
    "        # print(f\"src = {src}, src_decode = {src_decode}\")\n",
    "        # tgt_decode = \"\".join([w for w in tokenizer.decode(tgt[0].tolist()) if w != Tokenizer.PAD])\n",
    "        # print(f\"tgt = {tgt}， tgt_decode = {tgt_decode}\")\n",
    "        result = torch.cat([src, tgt], dim=1)\n",
    "        result_decode = \"\".join([w for w in tokenizer.decode(result[0].tolist()) if w != Tokenizer.PAD])\n",
    "        return result_decode\n",
    "\n",
    "for i in range(0, 5):\n",
    "    poetry_line = generate_random_poem(tokenizer, model, \"清明时节\")\n",
    "    print(poetry_line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
